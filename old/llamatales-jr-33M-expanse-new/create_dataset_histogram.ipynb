{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4f8eba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0, -0.9921875, -0.984375, -0.9765625, -0.96875, -0.9609375, -0.953125, -0.9453125, -0.9375, -0.9296875, -0.921875, -0.9140625, -0.90625, -0.8984375, -0.890625, -0.8828125, -0.875, -0.8671875, -0.859375, -0.8515625, -0.84375, -0.8359375, -0.828125, -0.8203125, -0.8125, -0.8046875, -0.796875, -0.7890625, -0.78125, -0.7734375, -0.765625, -0.7578125, -0.75, -0.7421875, -0.734375, -0.7265625, -0.71875, -0.7109375, -0.703125, -0.6953125, -0.6875, -0.6796875, -0.671875, -0.6640625, -0.65625, -0.6484375, -0.640625, -0.6328125, -0.625, -0.6171875, -0.609375, -0.6015625, -0.59375, -0.5859375, -0.578125, -0.5703125, -0.5625, -0.5546875, -0.546875, -0.5390625, -0.53125, -0.5234375, -0.515625, -0.5078125, -0.5, -0.4921875, -0.484375, -0.4765625, -0.46875, -0.4609375, -0.453125, -0.4453125, -0.4375, -0.4296875, -0.421875, -0.4140625, -0.40625, -0.3984375, -0.390625, -0.3828125, -0.375, -0.3671875, -0.359375, -0.3515625, -0.34375, -0.3359375, -0.328125, -0.3203125, -0.3125, -0.3046875, -0.296875, -0.2890625, -0.28125, -0.2734375, -0.265625, -0.2578125, -0.25, -0.2421875, -0.234375, -0.2265625, -0.21875, -0.2109375, -0.203125, -0.1953125, -0.1875, -0.1796875, -0.171875, -0.1640625, -0.15625, -0.1484375, -0.140625, -0.1328125, -0.125, -0.1171875, -0.109375, -0.1015625, -0.09375, -0.0859375, -0.078125, -0.0703125, -0.0625, -0.0546875, -0.046875, -0.0390625, -0.03125, -0.0234375, -0.015625, -0.0078125, 0.0, 0.0078125, 0.015625, 0.0234375, 0.03125, 0.0390625, 0.046875, 0.0546875, 0.0625, 0.0703125, 0.078125, 0.0859375, 0.09375, 0.1015625, 0.109375, 0.1171875, 0.125, 0.1328125, 0.140625, 0.1484375, 0.15625, 0.1640625, 0.171875, 0.1796875, 0.1875, 0.1953125, 0.203125, 0.2109375, 0.21875, 0.2265625, 0.234375, 0.2421875, 0.25, 0.2578125, 0.265625, 0.2734375, 0.28125, 0.2890625, 0.296875, 0.3046875, 0.3125, 0.3203125, 0.328125, 0.3359375, 0.34375, 0.3515625, 0.359375, 0.3671875, 0.375, 0.3828125, 0.390625, 0.3984375, 0.40625, 0.4140625, 0.421875, 0.4296875, 0.4375, 0.4453125, 0.453125, 0.4609375, 0.46875, 0.4765625, 0.484375, 0.4921875, 0.5, 0.5078125, 0.515625, 0.5234375, 0.53125, 0.5390625, 0.546875, 0.5546875, 0.5625, 0.5703125, 0.578125, 0.5859375, 0.59375, 0.6015625, 0.609375, 0.6171875, 0.625, 0.6328125, 0.640625, 0.6484375, 0.65625, 0.6640625, 0.671875, 0.6796875, 0.6875, 0.6953125, 0.703125, 0.7109375, 0.71875, 0.7265625, 0.734375, 0.7421875, 0.75, 0.7578125, 0.765625, 0.7734375, 0.78125, 0.7890625, 0.796875, 0.8046875, 0.8125, 0.8203125, 0.828125, 0.8359375, 0.84375, 0.8515625, 0.859375, 0.8671875, 0.875, 0.8828125, 0.890625, 0.8984375, 0.90625, 0.9140625, 0.921875, 0.9296875, 0.9375, 0.9453125, 0.953125, 0.9609375, 0.96875, 0.9765625, 0.984375, 0.9921875, 1.0]\n"
     ]
    }
   ],
   "source": [
    "#128 bins below 0\n",
    "#128 bins above 0\n",
    "#1 bin below -1\n",
    "#1 bin above 1\n",
    "bins = [i / 128 for i in range(-128, 129)]\n",
    "print(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26503e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins.insert(0, float(-inf))\n",
    "# bins.append(float(inf))\n",
    "# print(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7d6e834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-1.0, -0.9921875), (-0.9921875, -0.984375), (-0.984375, -0.9765625), (-0.9765625, -0.96875), (-0.96875, -0.9609375), (-0.9609375, -0.953125), (-0.953125, -0.9453125), (-0.9453125, -0.9375), (-0.9375, -0.9296875), (-0.9296875, -0.921875), (-0.921875, -0.9140625), (-0.9140625, -0.90625), (-0.90625, -0.8984375), (-0.8984375, -0.890625), (-0.890625, -0.8828125), (-0.8828125, -0.875), (-0.875, -0.8671875), (-0.8671875, -0.859375), (-0.859375, -0.8515625), (-0.8515625, -0.84375), (-0.84375, -0.8359375), (-0.8359375, -0.828125), (-0.828125, -0.8203125), (-0.8203125, -0.8125), (-0.8125, -0.8046875), (-0.8046875, -0.796875), (-0.796875, -0.7890625), (-0.7890625, -0.78125), (-0.78125, -0.7734375), (-0.7734375, -0.765625), (-0.765625, -0.7578125), (-0.7578125, -0.75), (-0.75, -0.7421875), (-0.7421875, -0.734375), (-0.734375, -0.7265625), (-0.7265625, -0.71875), (-0.71875, -0.7109375), (-0.7109375, -0.703125), (-0.703125, -0.6953125), (-0.6953125, -0.6875), (-0.6875, -0.6796875), (-0.6796875, -0.671875), (-0.671875, -0.6640625), (-0.6640625, -0.65625), (-0.65625, -0.6484375), (-0.6484375, -0.640625), (-0.640625, -0.6328125), (-0.6328125, -0.625), (-0.625, -0.6171875), (-0.6171875, -0.609375), (-0.609375, -0.6015625), (-0.6015625, -0.59375), (-0.59375, -0.5859375), (-0.5859375, -0.578125), (-0.578125, -0.5703125), (-0.5703125, -0.5625), (-0.5625, -0.5546875), (-0.5546875, -0.546875), (-0.546875, -0.5390625), (-0.5390625, -0.53125), (-0.53125, -0.5234375), (-0.5234375, -0.515625), (-0.515625, -0.5078125), (-0.5078125, -0.5), (-0.5, -0.4921875), (-0.4921875, -0.484375), (-0.484375, -0.4765625), (-0.4765625, -0.46875), (-0.46875, -0.4609375), (-0.4609375, -0.453125), (-0.453125, -0.4453125), (-0.4453125, -0.4375), (-0.4375, -0.4296875), (-0.4296875, -0.421875), (-0.421875, -0.4140625), (-0.4140625, -0.40625), (-0.40625, -0.3984375), (-0.3984375, -0.390625), (-0.390625, -0.3828125), (-0.3828125, -0.375), (-0.375, -0.3671875), (-0.3671875, -0.359375), (-0.359375, -0.3515625), (-0.3515625, -0.34375), (-0.34375, -0.3359375), (-0.3359375, -0.328125), (-0.328125, -0.3203125), (-0.3203125, -0.3125), (-0.3125, -0.3046875), (-0.3046875, -0.296875), (-0.296875, -0.2890625), (-0.2890625, -0.28125), (-0.28125, -0.2734375), (-0.2734375, -0.265625), (-0.265625, -0.2578125), (-0.2578125, -0.25), (-0.25, -0.2421875), (-0.2421875, -0.234375), (-0.234375, -0.2265625), (-0.2265625, -0.21875), (-0.21875, -0.2109375), (-0.2109375, -0.203125), (-0.203125, -0.1953125), (-0.1953125, -0.1875), (-0.1875, -0.1796875), (-0.1796875, -0.171875), (-0.171875, -0.1640625), (-0.1640625, -0.15625), (-0.15625, -0.1484375), (-0.1484375, -0.140625), (-0.140625, -0.1328125), (-0.1328125, -0.125), (-0.125, -0.1171875), (-0.1171875, -0.109375), (-0.109375, -0.1015625), (-0.1015625, -0.09375), (-0.09375, -0.0859375), (-0.0859375, -0.078125), (-0.078125, -0.0703125), (-0.0703125, -0.0625), (-0.0625, -0.0546875), (-0.0546875, -0.046875), (-0.046875, -0.0390625), (-0.0390625, -0.03125), (-0.03125, -0.0234375), (-0.0234375, -0.015625), (-0.015625, -0.0078125), (-0.0078125, 0.0), (0.0, 0.0078125), (0.0078125, 0.015625), (0.015625, 0.0234375), (0.0234375, 0.03125), (0.03125, 0.0390625), (0.0390625, 0.046875), (0.046875, 0.0546875), (0.0546875, 0.0625), (0.0625, 0.0703125), (0.0703125, 0.078125), (0.078125, 0.0859375), (0.0859375, 0.09375), (0.09375, 0.1015625), (0.1015625, 0.109375), (0.109375, 0.1171875), (0.1171875, 0.125), (0.125, 0.1328125), (0.1328125, 0.140625), (0.140625, 0.1484375), (0.1484375, 0.15625), (0.15625, 0.1640625), (0.1640625, 0.171875), (0.171875, 0.1796875), (0.1796875, 0.1875), (0.1875, 0.1953125), (0.1953125, 0.203125), (0.203125, 0.2109375), (0.2109375, 0.21875), (0.21875, 0.2265625), (0.2265625, 0.234375), (0.234375, 0.2421875), (0.2421875, 0.25), (0.25, 0.2578125), (0.2578125, 0.265625), (0.265625, 0.2734375), (0.2734375, 0.28125), (0.28125, 0.2890625), (0.2890625, 0.296875), (0.296875, 0.3046875), (0.3046875, 0.3125), (0.3125, 0.3203125), (0.3203125, 0.328125), (0.328125, 0.3359375), (0.3359375, 0.34375), (0.34375, 0.3515625), (0.3515625, 0.359375), (0.359375, 0.3671875), (0.3671875, 0.375), (0.375, 0.3828125), (0.3828125, 0.390625), (0.390625, 0.3984375), (0.3984375, 0.40625), (0.40625, 0.4140625), (0.4140625, 0.421875), (0.421875, 0.4296875), (0.4296875, 0.4375), (0.4375, 0.4453125), (0.4453125, 0.453125), (0.453125, 0.4609375), (0.4609375, 0.46875), (0.46875, 0.4765625), (0.4765625, 0.484375), (0.484375, 0.4921875), (0.4921875, 0.5), (0.5, 0.5078125), (0.5078125, 0.515625), (0.515625, 0.5234375), (0.5234375, 0.53125), (0.53125, 0.5390625), (0.5390625, 0.546875), (0.546875, 0.5546875), (0.5546875, 0.5625), (0.5625, 0.5703125), (0.5703125, 0.578125), (0.578125, 0.5859375), (0.5859375, 0.59375), (0.59375, 0.6015625), (0.6015625, 0.609375), (0.609375, 0.6171875), (0.6171875, 0.625), (0.625, 0.6328125), (0.6328125, 0.640625), (0.640625, 0.6484375), (0.6484375, 0.65625), (0.65625, 0.6640625), (0.6640625, 0.671875), (0.671875, 0.6796875), (0.6796875, 0.6875), (0.6875, 0.6953125), (0.6953125, 0.703125), (0.703125, 0.7109375), (0.7109375, 0.71875), (0.71875, 0.7265625), (0.7265625, 0.734375), (0.734375, 0.7421875), (0.7421875, 0.75), (0.75, 0.7578125), (0.7578125, 0.765625), (0.765625, 0.7734375), (0.7734375, 0.78125), (0.78125, 0.7890625), (0.7890625, 0.796875), (0.796875, 0.8046875), (0.8046875, 0.8125), (0.8125, 0.8203125), (0.8203125, 0.828125), (0.828125, 0.8359375), (0.8359375, 0.84375), (0.84375, 0.8515625), (0.8515625, 0.859375), (0.859375, 0.8671875), (0.8671875, 0.875), (0.875, 0.8828125), (0.8828125, 0.890625), (0.890625, 0.8984375), (0.8984375, 0.90625), (0.90625, 0.9140625), (0.9140625, 0.921875), (0.921875, 0.9296875), (0.9296875, 0.9375), (0.9375, 0.9453125), (0.9453125, 0.953125), (0.953125, 0.9609375), (0.9609375, 0.96875), (0.96875, 0.9765625), (0.9765625, 0.984375), (0.984375, 0.9921875), (0.9921875, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "bin_ranges = []\n",
    "for i in range(len(bins) - 1):\n",
    "    bin_ranges.append((bins[i], bins[i + 1]))\n",
    "\n",
    "print(bin_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dbdafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/a3murali/.cache/huggingface/token\n",
      "Login successful\n",
      "PyTorch Version: 1.13.0a0+d321be6\n",
      "Transformers Version: 4.35.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there was a dragon named Sam. Sam was a big, friendly dragon. He loved to play with the children in the village. But one day, the villagers asked Sam to help them. A big flood was coming and their homes were going to get wet.\n",
      "\n",
      "Sam said, \"Don't worry, I will help.\" He flew high above the water and saw a long bridge. He flew over the bridge and landed on the other side. But, oh no! A mean old bear was also on the other side of the bridge.\n",
      "\n",
      "The bear was very big and scary. Sam was worried that the bear might eat him. But, to Sam's surprise, the bear said, \"Hello, little dragon. I'm not going to eat you. I need your help.\" The bear told Sam that he was lost too. He had flown over the river and couldn't find his way home.\n",
      "\n",
      "Sam and the bear became friends. Sam helped the bear to find his way home. The villagers saw this and were happy. They said, \"We should be nice to everyone, even if they look different.\" Sam and the bear said together, \"We are friends now.\" The dragon, Sam, and the bear played together and had fun in the village that day.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/scratch/a3murali/job_36208149/ipykernel_2855319/174019619.py:65: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  convert_hidden_states = np.append(convert_hidden_states, np.array([j.detach().cpu().numpy() for i in outputs.hidden_states for j in i]))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (258,512) into shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(inputs\u001b[38;5;241m.\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39minputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m], do_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, top_k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, num_return_sequences \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, max_new_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m, eos_token_id \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39meos_token_id, pad_token_id \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mpad_token_id, return_dict_in_generate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     63\u001b[0m convert_hidden_states \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[0;32m---> 65\u001b[0m convert_hidden_states \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(convert_hidden_states, \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (258,512) into shape (1,)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/expanse/lustre/projects/csd819/a3murali/cache/'\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token = \"<hf_token>\")\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Transformers Version: {transformers.__version__}\")\n",
    "\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer, AutoModelForCausalLM, pipeline, LlamaForCausalLM\n",
    "\n",
    "model = \"ivnle/llamatales_jr_8b-lay8-hs512-hd8-33M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "\n",
    "llamatales_pipeline = pipeline(\"text-generation\", model = model, device = \"cuda\")\n",
    "\n",
    "# prompts = {\n",
    "#     1: \"Once upon a time there was a dragon\", \n",
    "#     2: \"Once upon a time there was a princess\", \n",
    "#     3: \"Once upon a time there were two children\",\n",
    "#     4: \"Once upon a time there was a prince\",\n",
    "#     5: \"Once upon a time there was a frog\",\n",
    "#     6: \"Once upon a time there was a king\",\n",
    "#     7: \"Once upon a time there was a queen\",\n",
    "#     8: \"Once upon a time there was a wolf\",\n",
    "#     9: \"Once upon a time there was a genie\",\n",
    "#     10: \"Once upon a time there was a poor boy\"\n",
    "# }\n",
    "prompts = {1: \"Once upon a time there was a dragon\"}\n",
    "#generation - generate stories for each prompt\n",
    "sequences = llamatales_pipeline(\n",
    "    prompts[1],\n",
    "    do_sample = True,\n",
    "    top_k = 10,\n",
    "    num_return_sequences = 1,\n",
    "    max_new_tokens = 512\n",
    ")\n",
    "generated_story = sequences[0]['generated_text']\n",
    "print(generated_story)\n",
    "\n",
    "num_tokens_generated_story = len(tokenizer.encode(generated_story))\n",
    "\n",
    "#test - collect hidden states\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"/expanse/lustre/projects/csd819/a3murali/cache/models--ivnle--llamatales_jr_8b-lay8-hs512-hd8-33M/snapshots/461f50f0024efb46b94dc68cc850d12d75ecb325\", output_hidden_states = True)\n",
    "model = AutoModelForCausalLM.from_config(config).to('cuda')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/expanse/lustre/projects/csd819/a3murali/cache/models--ivnle--llamatales_jr_8b-lay8-hs512-hd8-33M/snapshots/461f50f0024efb46b94dc68cc850d12d75ecb325/\", config = config)\n",
    "\n",
    "inputs = tokenizer(generated_story, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(inputs.input_ids, attention_mask=inputs[\"attention_mask\"], do_sample = True, top_k = 10, num_return_sequences = 1, max_new_tokens = 512, eos_token_id = tokenizer.eos_token_id, pad_token_id = tokenizer.pad_token_id, return_dict_in_generate=True)\n",
    "\n",
    "convert_hidden_states = np.array([])\n",
    "\n",
    "convert_hidden_states = np.append(convert_hidden_states, np.array([j.detach().cpu().numpy() for i in outputs.hidden_states for j in i]))\n",
    "\n",
    "# print(\"Min Value: \", np.min(np.array(convert_hidden_states)))\n",
    "# print(\"Max Value: \", np.max(convert_hidden_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "559432bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(3635712,)\n",
      "(3635712,)\n",
      "[ 0.00562103 -0.00115525  0.0048254  ...  0.9034965  -0.09795559\n",
      "  0.28680092]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m hidden_vals:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(bin_ranges)):\n\u001b[0;32m---> 11\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m(\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbin_ranges\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m<\u001b[39m bin_ranges[j][\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m     12\u001b[0m             bin_counts[j \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(type(convert_hidden_states))\n",
    "print(convert_hidden_states.shape)\n",
    "hidden_vals = convert_hidden_states.flatten()\n",
    "print(hidden_vals.shape)\n",
    "bin_counts = [0 for i in range(len(bin_ranges) + 2)]\n",
    "# bin_counts.append(0)\n",
    "# bin_counts.append(0)\n",
    "print(hidden_vals)\n",
    "for i in hidden_vals:\n",
    "    for j in range(len(bin_ranges)):\n",
    "        if(i >= bin_ranges[j][0] and i < bin_ranges[j][1]):\n",
    "            bin_counts[j + 1] += 1\n",
    "    if(i < -1):\n",
    "        bin_counts[0] += 1\n",
    "    elif(i >= 1):\n",
    "        bin_counts[len(bin_counts) - 1] += 1\n",
    "\n",
    "\n",
    "# plt.hist(bin_counts, bins = 258)\n",
    "# plt.show()\n",
    "print(bin_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e396f532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
