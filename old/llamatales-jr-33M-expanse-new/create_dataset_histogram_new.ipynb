{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c32e967e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0, -0.9921875, -0.984375, -0.9765625, -0.96875, -0.9609375, -0.953125, -0.9453125, -0.9375, -0.9296875, -0.921875, -0.9140625, -0.90625, -0.8984375, -0.890625, -0.8828125, -0.875, -0.8671875, -0.859375, -0.8515625, -0.84375, -0.8359375, -0.828125, -0.8203125, -0.8125, -0.8046875, -0.796875, -0.7890625, -0.78125, -0.7734375, -0.765625, -0.7578125, -0.75, -0.7421875, -0.734375, -0.7265625, -0.71875, -0.7109375, -0.703125, -0.6953125, -0.6875, -0.6796875, -0.671875, -0.6640625, -0.65625, -0.6484375, -0.640625, -0.6328125, -0.625, -0.6171875, -0.609375, -0.6015625, -0.59375, -0.5859375, -0.578125, -0.5703125, -0.5625, -0.5546875, -0.546875, -0.5390625, -0.53125, -0.5234375, -0.515625, -0.5078125, -0.5, -0.4921875, -0.484375, -0.4765625, -0.46875, -0.4609375, -0.453125, -0.4453125, -0.4375, -0.4296875, -0.421875, -0.4140625, -0.40625, -0.3984375, -0.390625, -0.3828125, -0.375, -0.3671875, -0.359375, -0.3515625, -0.34375, -0.3359375, -0.328125, -0.3203125, -0.3125, -0.3046875, -0.296875, -0.2890625, -0.28125, -0.2734375, -0.265625, -0.2578125, -0.25, -0.2421875, -0.234375, -0.2265625, -0.21875, -0.2109375, -0.203125, -0.1953125, -0.1875, -0.1796875, -0.171875, -0.1640625, -0.15625, -0.1484375, -0.140625, -0.1328125, -0.125, -0.1171875, -0.109375, -0.1015625, -0.09375, -0.0859375, -0.078125, -0.0703125, -0.0625, -0.0546875, -0.046875, -0.0390625, -0.03125, -0.0234375, -0.015625, -0.0078125, 0.0, 0.0078125, 0.015625, 0.0234375, 0.03125, 0.0390625, 0.046875, 0.0546875, 0.0625, 0.0703125, 0.078125, 0.0859375, 0.09375, 0.1015625, 0.109375, 0.1171875, 0.125, 0.1328125, 0.140625, 0.1484375, 0.15625, 0.1640625, 0.171875, 0.1796875, 0.1875, 0.1953125, 0.203125, 0.2109375, 0.21875, 0.2265625, 0.234375, 0.2421875, 0.25, 0.2578125, 0.265625, 0.2734375, 0.28125, 0.2890625, 0.296875, 0.3046875, 0.3125, 0.3203125, 0.328125, 0.3359375, 0.34375, 0.3515625, 0.359375, 0.3671875, 0.375, 0.3828125, 0.390625, 0.3984375, 0.40625, 0.4140625, 0.421875, 0.4296875, 0.4375, 0.4453125, 0.453125, 0.4609375, 0.46875, 0.4765625, 0.484375, 0.4921875, 0.5, 0.5078125, 0.515625, 0.5234375, 0.53125, 0.5390625, 0.546875, 0.5546875, 0.5625, 0.5703125, 0.578125, 0.5859375, 0.59375, 0.6015625, 0.609375, 0.6171875, 0.625, 0.6328125, 0.640625, 0.6484375, 0.65625, 0.6640625, 0.671875, 0.6796875, 0.6875, 0.6953125, 0.703125, 0.7109375, 0.71875, 0.7265625, 0.734375, 0.7421875, 0.75, 0.7578125, 0.765625, 0.7734375, 0.78125, 0.7890625, 0.796875, 0.8046875, 0.8125, 0.8203125, 0.828125, 0.8359375, 0.84375, 0.8515625, 0.859375, 0.8671875, 0.875, 0.8828125, 0.890625, 0.8984375, 0.90625, 0.9140625, 0.921875, 0.9296875, 0.9375, 0.9453125, 0.953125, 0.9609375, 0.96875, 0.9765625, 0.984375, 0.9921875, 1.0]\n"
     ]
    }
   ],
   "source": [
    "#128 bins below 0\n",
    "#128 bins above 0\n",
    "#1 bin below -1\n",
    "#1 bin above 1\n",
    "bins = [i / 128 for i in range(-128, 129)]\n",
    "print(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dcf1e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins.insert(0, float(-inf))\n",
    "# bins.append(float(inf))\n",
    "# print(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ecdfc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-1.0, -0.9921875), (-0.9921875, -0.984375), (-0.984375, -0.9765625), (-0.9765625, -0.96875), (-0.96875, -0.9609375), (-0.9609375, -0.953125), (-0.953125, -0.9453125), (-0.9453125, -0.9375), (-0.9375, -0.9296875), (-0.9296875, -0.921875), (-0.921875, -0.9140625), (-0.9140625, -0.90625), (-0.90625, -0.8984375), (-0.8984375, -0.890625), (-0.890625, -0.8828125), (-0.8828125, -0.875), (-0.875, -0.8671875), (-0.8671875, -0.859375), (-0.859375, -0.8515625), (-0.8515625, -0.84375), (-0.84375, -0.8359375), (-0.8359375, -0.828125), (-0.828125, -0.8203125), (-0.8203125, -0.8125), (-0.8125, -0.8046875), (-0.8046875, -0.796875), (-0.796875, -0.7890625), (-0.7890625, -0.78125), (-0.78125, -0.7734375), (-0.7734375, -0.765625), (-0.765625, -0.7578125), (-0.7578125, -0.75), (-0.75, -0.7421875), (-0.7421875, -0.734375), (-0.734375, -0.7265625), (-0.7265625, -0.71875), (-0.71875, -0.7109375), (-0.7109375, -0.703125), (-0.703125, -0.6953125), (-0.6953125, -0.6875), (-0.6875, -0.6796875), (-0.6796875, -0.671875), (-0.671875, -0.6640625), (-0.6640625, -0.65625), (-0.65625, -0.6484375), (-0.6484375, -0.640625), (-0.640625, -0.6328125), (-0.6328125, -0.625), (-0.625, -0.6171875), (-0.6171875, -0.609375), (-0.609375, -0.6015625), (-0.6015625, -0.59375), (-0.59375, -0.5859375), (-0.5859375, -0.578125), (-0.578125, -0.5703125), (-0.5703125, -0.5625), (-0.5625, -0.5546875), (-0.5546875, -0.546875), (-0.546875, -0.5390625), (-0.5390625, -0.53125), (-0.53125, -0.5234375), (-0.5234375, -0.515625), (-0.515625, -0.5078125), (-0.5078125, -0.5), (-0.5, -0.4921875), (-0.4921875, -0.484375), (-0.484375, -0.4765625), (-0.4765625, -0.46875), (-0.46875, -0.4609375), (-0.4609375, -0.453125), (-0.453125, -0.4453125), (-0.4453125, -0.4375), (-0.4375, -0.4296875), (-0.4296875, -0.421875), (-0.421875, -0.4140625), (-0.4140625, -0.40625), (-0.40625, -0.3984375), (-0.3984375, -0.390625), (-0.390625, -0.3828125), (-0.3828125, -0.375), (-0.375, -0.3671875), (-0.3671875, -0.359375), (-0.359375, -0.3515625), (-0.3515625, -0.34375), (-0.34375, -0.3359375), (-0.3359375, -0.328125), (-0.328125, -0.3203125), (-0.3203125, -0.3125), (-0.3125, -0.3046875), (-0.3046875, -0.296875), (-0.296875, -0.2890625), (-0.2890625, -0.28125), (-0.28125, -0.2734375), (-0.2734375, -0.265625), (-0.265625, -0.2578125), (-0.2578125, -0.25), (-0.25, -0.2421875), (-0.2421875, -0.234375), (-0.234375, -0.2265625), (-0.2265625, -0.21875), (-0.21875, -0.2109375), (-0.2109375, -0.203125), (-0.203125, -0.1953125), (-0.1953125, -0.1875), (-0.1875, -0.1796875), (-0.1796875, -0.171875), (-0.171875, -0.1640625), (-0.1640625, -0.15625), (-0.15625, -0.1484375), (-0.1484375, -0.140625), (-0.140625, -0.1328125), (-0.1328125, -0.125), (-0.125, -0.1171875), (-0.1171875, -0.109375), (-0.109375, -0.1015625), (-0.1015625, -0.09375), (-0.09375, -0.0859375), (-0.0859375, -0.078125), (-0.078125, -0.0703125), (-0.0703125, -0.0625), (-0.0625, -0.0546875), (-0.0546875, -0.046875), (-0.046875, -0.0390625), (-0.0390625, -0.03125), (-0.03125, -0.0234375), (-0.0234375, -0.015625), (-0.015625, -0.0078125), (-0.0078125, 0.0), (0.0, 0.0078125), (0.0078125, 0.015625), (0.015625, 0.0234375), (0.0234375, 0.03125), (0.03125, 0.0390625), (0.0390625, 0.046875), (0.046875, 0.0546875), (0.0546875, 0.0625), (0.0625, 0.0703125), (0.0703125, 0.078125), (0.078125, 0.0859375), (0.0859375, 0.09375), (0.09375, 0.1015625), (0.1015625, 0.109375), (0.109375, 0.1171875), (0.1171875, 0.125), (0.125, 0.1328125), (0.1328125, 0.140625), (0.140625, 0.1484375), (0.1484375, 0.15625), (0.15625, 0.1640625), (0.1640625, 0.171875), (0.171875, 0.1796875), (0.1796875, 0.1875), (0.1875, 0.1953125), (0.1953125, 0.203125), (0.203125, 0.2109375), (0.2109375, 0.21875), (0.21875, 0.2265625), (0.2265625, 0.234375), (0.234375, 0.2421875), (0.2421875, 0.25), (0.25, 0.2578125), (0.2578125, 0.265625), (0.265625, 0.2734375), (0.2734375, 0.28125), (0.28125, 0.2890625), (0.2890625, 0.296875), (0.296875, 0.3046875), (0.3046875, 0.3125), (0.3125, 0.3203125), (0.3203125, 0.328125), (0.328125, 0.3359375), (0.3359375, 0.34375), (0.34375, 0.3515625), (0.3515625, 0.359375), (0.359375, 0.3671875), (0.3671875, 0.375), (0.375, 0.3828125), (0.3828125, 0.390625), (0.390625, 0.3984375), (0.3984375, 0.40625), (0.40625, 0.4140625), (0.4140625, 0.421875), (0.421875, 0.4296875), (0.4296875, 0.4375), (0.4375, 0.4453125), (0.4453125, 0.453125), (0.453125, 0.4609375), (0.4609375, 0.46875), (0.46875, 0.4765625), (0.4765625, 0.484375), (0.484375, 0.4921875), (0.4921875, 0.5), (0.5, 0.5078125), (0.5078125, 0.515625), (0.515625, 0.5234375), (0.5234375, 0.53125), (0.53125, 0.5390625), (0.5390625, 0.546875), (0.546875, 0.5546875), (0.5546875, 0.5625), (0.5625, 0.5703125), (0.5703125, 0.578125), (0.578125, 0.5859375), (0.5859375, 0.59375), (0.59375, 0.6015625), (0.6015625, 0.609375), (0.609375, 0.6171875), (0.6171875, 0.625), (0.625, 0.6328125), (0.6328125, 0.640625), (0.640625, 0.6484375), (0.6484375, 0.65625), (0.65625, 0.6640625), (0.6640625, 0.671875), (0.671875, 0.6796875), (0.6796875, 0.6875), (0.6875, 0.6953125), (0.6953125, 0.703125), (0.703125, 0.7109375), (0.7109375, 0.71875), (0.71875, 0.7265625), (0.7265625, 0.734375), (0.734375, 0.7421875), (0.7421875, 0.75), (0.75, 0.7578125), (0.7578125, 0.765625), (0.765625, 0.7734375), (0.7734375, 0.78125), (0.78125, 0.7890625), (0.7890625, 0.796875), (0.796875, 0.8046875), (0.8046875, 0.8125), (0.8125, 0.8203125), (0.8203125, 0.828125), (0.828125, 0.8359375), (0.8359375, 0.84375), (0.84375, 0.8515625), (0.8515625, 0.859375), (0.859375, 0.8671875), (0.8671875, 0.875), (0.875, 0.8828125), (0.8828125, 0.890625), (0.890625, 0.8984375), (0.8984375, 0.90625), (0.90625, 0.9140625), (0.9140625, 0.921875), (0.921875, 0.9296875), (0.9296875, 0.9375), (0.9375, 0.9453125), (0.9453125, 0.953125), (0.953125, 0.9609375), (0.9609375, 0.96875), (0.96875, 0.9765625), (0.9765625, 0.984375), (0.984375, 0.9921875), (0.9921875, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "bin_ranges = []\n",
    "for i in range(len(bins) - 1):\n",
    "    bin_ranges.append((bins[i], bins[i + 1]))\n",
    "\n",
    "print(bin_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8592eb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/a3murali/.cache/huggingface/token\n",
      "Login successful\n",
      "PyTorch Version: 1.13.0a0+d321be6\n",
      "Transformers Version: 4.35.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there was a dragon. The dragon's name was Max. Max loved to play. He would run fast and roar loudly. His roar was very loud, and it scared the other animals. They did not like Max's roar.\n",
      "\n",
      "Every day, Max would roar even louder. He thought it was the best noise in the world. The other animals would get scared and hide in their houses. Max didn't care. He just wanted to play. He thought he was the biggest and strongest dragon in the land. His favorite thing to do was to roar. Max's roar was so loud that it woke up the other animals in the houses.\n",
      "\n",
      "One sunny day, the animals were playing together outside. But Max was very noisy. He roared so loud, it made the houses shake. The birds got scared and flew away. They did not like it when Max roared. The people in the houses tried to calm Max. They said, \"Please, Max, be quiet. We like playing here.\"\n",
      "\n",
      "Max did not listen. He kept roaring. The animals ran away from him. They were sad. Max was sorry. He realized that loud noises made everyone unhappy. He decided to be quiet. But it was too late. The people in the houses were too scared to come out. They were afraid of Max's roar. Max was very sad. He realized that his loud roar hurt everyone.\n",
      "\n",
      "Max learned a big lesson. He learned that being loud can hurt others. He should play gently and be kind to his friends. He promised himself to be quiet and gentle from now on. Max went to sleep with a sad heart. He knew he had to be a good friend to all his friends.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (512). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/expanse/lustre/projects/csd819/a3murali/cache/'\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token = \"<hf_token>\")\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Transformers Version: {transformers.__version__}\")\n",
    "\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer, AutoModelForCausalLM, pipeline, LlamaForCausalLM\n",
    "\n",
    "model = \"ivnle/llamatales_jr_8b-lay8-hs512-hd8-33M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "\n",
    "llamatales_pipeline = pipeline(\"text-generation\", model = model, device = \"cuda\")\n",
    "\n",
    "# prompts = {\n",
    "#     1: \"Once upon a time there was a dragon\", \n",
    "#     2: \"Once upon a time there was a princess\", \n",
    "#     3: \"Once upon a time there were two children\",\n",
    "#     4: \"Once upon a time there was a prince\",\n",
    "#     5: \"Once upon a time there was a frog\",\n",
    "#     6: \"Once upon a time there was a king\",\n",
    "#     7: \"Once upon a time there was a queen\",\n",
    "#     8: \"Once upon a time there was a wolf\",\n",
    "#     9: \"Once upon a time there was a genie\",\n",
    "#     10: \"Once upon a time there was a poor boy\"\n",
    "# }\n",
    "prompts = {1: \"Once upon a time there was a dragon\"}\n",
    "#generation - generate stories for each prompt\n",
    "sequences = llamatales_pipeline(\n",
    "    prompts[1],\n",
    "    do_sample = True,\n",
    "    top_k = 10,\n",
    "    num_return_sequences = 1,\n",
    "    max_new_tokens = 512\n",
    ")\n",
    "generated_story = sequences[0]['generated_text']\n",
    "print(generated_story)\n",
    "\n",
    "num_tokens_generated_story = len(tokenizer.encode(generated_story))\n",
    "\n",
    "#test - collect hidden states\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"/expanse/lustre/projects/csd819/a3murali/cache/models--ivnle--llamatales_jr_8b-lay8-hs512-hd8-33M/snapshots/461f50f0024efb46b94dc68cc850d12d75ecb325\", output_hidden_states = True)\n",
    "model = AutoModelForCausalLM.from_config(config).to('cuda')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/expanse/lustre/projects/csd819/a3murali/cache/models--ivnle--llamatales_jr_8b-lay8-hs512-hd8-33M/snapshots/461f50f0024efb46b94dc68cc850d12d75ecb325/\", config = config)\n",
    "\n",
    "inputs = tokenizer(generated_story, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(inputs.input_ids, attention_mask=inputs[\"attention_mask\"], do_sample = True, top_k = 10, num_return_sequences = 1, \n",
    "                         max_new_tokens = 512, eos_token_id = tokenizer.eos_token_id, pad_token_id = tokenizer.pad_token_id, \n",
    "                         return_dict_in_generate=True)\n",
    "\n",
    "#print(outputs.hidden_states[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f6c7b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "9\n",
      "1\n",
      "346\n",
      "512\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "816316416\n",
      "(3949056,)\n",
      "3949056\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# convert_hidden_states = []\n",
    "\n",
    "# for i in outputs.hidden_states:\n",
    "#     convert_hidden_states.append([j.detach().cpu().numpy() for j in i])\n",
    "\n",
    "# print(len(convert_hidden_states))\n",
    "# print(len(convert_hidden_states[0]))\n",
    "# print(len(convert_hidden_states[0][0]))\n",
    "# print(len(convert_hidden_states[0][0][0]))\n",
    "# print(len(convert_hidden_states[0][0][0][0]))\n",
    "\n",
    "# print(type(convert_hidden_states))\n",
    "# print(type(convert_hidden_states[0]))\n",
    "# print(type(convert_hidden_states[0][0]))\n",
    "# print(type(convert_hidden_states[0][0][0]))\n",
    "# print(type(convert_hidden_states[0][0][0][0]))\n",
    "\n",
    "# print(len(convert_hidden_states) * len(convert_hidden_states[0]) * len(convert_hidden_states[0][0]) * len(convert_hidden_states[0][0][0]) * len(convert_hidden_states[0][0][0][0]))\n",
    "\n",
    "# convert_hidden_states = np.array(convert_hidden_states)\n",
    "\n",
    "convert_hidden_states = []\n",
    "\n",
    "for i in outputs.hidden_states:\n",
    "    convert_hidden_states.append(np.array([j.detach().cpu().numpy() for j in i]))\n",
    "\n",
    "print(len(convert_hidden_states))\n",
    "print(len(convert_hidden_states[0]))\n",
    "print(len(convert_hidden_states[0][0]))\n",
    "print(len(convert_hidden_states[0][0][0]))\n",
    "print(len(convert_hidden_states[0][0][0][0]))\n",
    "\n",
    "print(type(convert_hidden_states))\n",
    "print(type(convert_hidden_states[0]))\n",
    "print(type(convert_hidden_states[0][0]))\n",
    "print(type(convert_hidden_states[0][0][0]))\n",
    "print(type(convert_hidden_states[0][0][0][0]))\n",
    "\n",
    "print(convert_hidden_states[0].shape())\n",
    "\n",
    "print(len(convert_hidden_states) * len(convert_hidden_states[0]) * len(convert_hidden_states[0][0]) * len(convert_hidden_states[0][0][0]) * len(convert_hidden_states[0][0][0][0]))\n",
    "\n",
    "final = np.concatenate(convert_hidden_states, axis = None).ravel()\n",
    "\n",
    "print(final.shape)\n",
    "\n",
    "convert_hidden_states = np.array([])\n",
    "\n",
    "for i in outputs.hidden_states:\n",
    "    for j in i:\n",
    "        convert_hidden_states = np.append(convert_hidden_states, j.detach().cpu().numpy())\n",
    "\n",
    "        \n",
    "print(len(convert_hidden_states))\n",
    "\n",
    "print(type(convert_hidden_states))\n",
    "\n",
    "# print(\"Min Value: \", np.min(np.array(convert_hidden_states)))\n",
    "# print(\"Max Value: \", np.max(convert_hidden_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b1b4598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(3746304,)\n",
      "(3746304,)\n",
      "[ 0.00466169 -0.00197834 -0.00923175 ... -0.39045998  1.03380108\n",
      "  0.52178204]\n",
      "[91001, 1673, 1673, 1648, 1761, 1780, 1828, 1859, 1957, 1998, 2088, 2048, 2172, 2221, 2292, 2361, 2350, 2491, 2428, 2640, 2581, 2634, 2742, 2696, 2881, 3017, 3109, 3120, 3260, 3396, 3541, 3593, 3524, 3658, 3828, 3802, 4064, 4218, 4255, 4176, 4474, 4525, 4622, 4677, 4761, 5016, 5224, 5331, 5507, 5598, 5772, 5964, 5969, 6199, 6323, 6559, 6867, 7054, 7174, 7275, 7495, 7702, 7919, 8200, 8445, 8527, 8677, 9129, 9219, 9525, 9483, 9781, 10130, 10341, 10455, 10897, 11008, 11222, 11511, 11742, 12213, 12380, 12770, 13109, 13162, 13723, 13923, 14068, 14327, 14785, 15253, 15607, 16086, 16377, 16789, 17339, 17651, 18200, 18863, 19200, 19560, 20386, 20815, 21445, 22077, 22881, 22981, 24050, 24923, 25513, 26231, 27053, 28249, 28790, 29764, 30773, 31492, 32504, 33369, 33906, 35028, 36048, 38365, 42500, 50946, 62829, 78076, 91829, 99168, 101746, 90935, 76741, 63552, 50427, 42545, 37992, 35954, 34501, 34436, 33139, 32416, 31831, 30849, 30276, 28810, 28496, 27408, 26891, 26068, 25489, 24908, 24203, 23571, 22713, 22437, 21757, 21142, 20661, 19854, 19397, 18855, 18715, 17968, 17543, 17223, 16749, 15921, 15726, 15637, 14970, 14612, 14379, 14561, 13909, 13435, 13124, 12593, 12616, 12116, 11992, 11390, 11179, 10940, 10645, 10355, 9954, 9776, 9364, 9285, 8877, 8790, 8423, 8596, 7995, 7940, 7644, 7560, 7222, 6836, 6834, 6637, 6348, 6377, 6180, 6032, 5791, 5507, 5391, 5311, 5174, 5098, 4948, 4795, 4737, 4473, 4385, 4223, 4186, 4019, 4107, 3827, 3635, 3628, 3504, 3485, 3501, 3353, 3366, 3278, 3117, 3021, 2949, 2826, 2736, 2716, 2690, 2600, 2532, 2529, 2339, 2362, 2322, 2210, 2205, 2119, 2151, 2120, 2001, 2090, 1974, 1850, 1750, 1689, 1741, 1742, 1722, 1671, 81801]\n"
     ]
    }
   ],
   "source": [
    "print(type(convert_hidden_states))\n",
    "print(convert_hidden_states.shape)\n",
    "hidden_vals = convert_hidden_states.flatten()\n",
    "print(hidden_vals.shape)\n",
    "bin_counts = [0 for i in range(len(bin_ranges) + 2)]\n",
    "# bin_counts.append(0)\n",
    "# bin_counts.append(0)\n",
    "print(hidden_vals)\n",
    "for i in hidden_vals:\n",
    "    for j in range(len(bin_ranges)):\n",
    "        if(i >= bin_ranges[j][0] and i < bin_ranges[j][1]):\n",
    "            bin_counts[j + 1] += 1\n",
    "    if(i < -1):\n",
    "        bin_counts[0] += 1\n",
    "    elif(i >= 1):\n",
    "        bin_counts[len(bin_counts) - 1] += 1\n",
    "\n",
    "\n",
    "print(bin_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81f73643",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bins = bins.copy()\n",
    "new_bins.insert(0, -1.25)\n",
    "new_bins.append(1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "235706c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the histogram\n",
    "plt.hist(new_bins[:-1], new_bins, weights=bin_counts)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28781593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(bin_counts, bins = 258)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
