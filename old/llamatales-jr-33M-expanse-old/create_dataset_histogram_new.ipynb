{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e6628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#128 bins below 0\n",
    "#128 bins above 0\n",
    "#1 bin below -1\n",
    "#1 bin above 1\n",
    "bins = [i / 128 for i in range(-128, 129)]\n",
    "print(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65473553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins.insert(0, float(-inf))\n",
    "# bins.append(float(inf))\n",
    "# print(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6bc05fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-1.0, -0.9921875), (-0.9921875, -0.984375), (-0.984375, -0.9765625), (-0.9765625, -0.96875), (-0.96875, -0.9609375), (-0.9609375, -0.953125), (-0.953125, -0.9453125), (-0.9453125, -0.9375), (-0.9375, -0.9296875), (-0.9296875, -0.921875), (-0.921875, -0.9140625), (-0.9140625, -0.90625), (-0.90625, -0.8984375), (-0.8984375, -0.890625), (-0.890625, -0.8828125), (-0.8828125, -0.875), (-0.875, -0.8671875), (-0.8671875, -0.859375), (-0.859375, -0.8515625), (-0.8515625, -0.84375), (-0.84375, -0.8359375), (-0.8359375, -0.828125), (-0.828125, -0.8203125), (-0.8203125, -0.8125), (-0.8125, -0.8046875), (-0.8046875, -0.796875), (-0.796875, -0.7890625), (-0.7890625, -0.78125), (-0.78125, -0.7734375), (-0.7734375, -0.765625), (-0.765625, -0.7578125), (-0.7578125, -0.75), (-0.75, -0.7421875), (-0.7421875, -0.734375), (-0.734375, -0.7265625), (-0.7265625, -0.71875), (-0.71875, -0.7109375), (-0.7109375, -0.703125), (-0.703125, -0.6953125), (-0.6953125, -0.6875), (-0.6875, -0.6796875), (-0.6796875, -0.671875), (-0.671875, -0.6640625), (-0.6640625, -0.65625), (-0.65625, -0.6484375), (-0.6484375, -0.640625), (-0.640625, -0.6328125), (-0.6328125, -0.625), (-0.625, -0.6171875), (-0.6171875, -0.609375), (-0.609375, -0.6015625), (-0.6015625, -0.59375), (-0.59375, -0.5859375), (-0.5859375, -0.578125), (-0.578125, -0.5703125), (-0.5703125, -0.5625), (-0.5625, -0.5546875), (-0.5546875, -0.546875), (-0.546875, -0.5390625), (-0.5390625, -0.53125), (-0.53125, -0.5234375), (-0.5234375, -0.515625), (-0.515625, -0.5078125), (-0.5078125, -0.5), (-0.5, -0.4921875), (-0.4921875, -0.484375), (-0.484375, -0.4765625), (-0.4765625, -0.46875), (-0.46875, -0.4609375), (-0.4609375, -0.453125), (-0.453125, -0.4453125), (-0.4453125, -0.4375), (-0.4375, -0.4296875), (-0.4296875, -0.421875), (-0.421875, -0.4140625), (-0.4140625, -0.40625), (-0.40625, -0.3984375), (-0.3984375, -0.390625), (-0.390625, -0.3828125), (-0.3828125, -0.375), (-0.375, -0.3671875), (-0.3671875, -0.359375), (-0.359375, -0.3515625), (-0.3515625, -0.34375), (-0.34375, -0.3359375), (-0.3359375, -0.328125), (-0.328125, -0.3203125), (-0.3203125, -0.3125), (-0.3125, -0.3046875), (-0.3046875, -0.296875), (-0.296875, -0.2890625), (-0.2890625, -0.28125), (-0.28125, -0.2734375), (-0.2734375, -0.265625), (-0.265625, -0.2578125), (-0.2578125, -0.25), (-0.25, -0.2421875), (-0.2421875, -0.234375), (-0.234375, -0.2265625), (-0.2265625, -0.21875), (-0.21875, -0.2109375), (-0.2109375, -0.203125), (-0.203125, -0.1953125), (-0.1953125, -0.1875), (-0.1875, -0.1796875), (-0.1796875, -0.171875), (-0.171875, -0.1640625), (-0.1640625, -0.15625), (-0.15625, -0.1484375), (-0.1484375, -0.140625), (-0.140625, -0.1328125), (-0.1328125, -0.125), (-0.125, -0.1171875), (-0.1171875, -0.109375), (-0.109375, -0.1015625), (-0.1015625, -0.09375), (-0.09375, -0.0859375), (-0.0859375, -0.078125), (-0.078125, -0.0703125), (-0.0703125, -0.0625), (-0.0625, -0.0546875), (-0.0546875, -0.046875), (-0.046875, -0.0390625), (-0.0390625, -0.03125), (-0.03125, -0.0234375), (-0.0234375, -0.015625), (-0.015625, -0.0078125), (-0.0078125, 0.0), (0.0, 0.0078125), (0.0078125, 0.015625), (0.015625, 0.0234375), (0.0234375, 0.03125), (0.03125, 0.0390625), (0.0390625, 0.046875), (0.046875, 0.0546875), (0.0546875, 0.0625), (0.0625, 0.0703125), (0.0703125, 0.078125), (0.078125, 0.0859375), (0.0859375, 0.09375), (0.09375, 0.1015625), (0.1015625, 0.109375), (0.109375, 0.1171875), (0.1171875, 0.125), (0.125, 0.1328125), (0.1328125, 0.140625), (0.140625, 0.1484375), (0.1484375, 0.15625), (0.15625, 0.1640625), (0.1640625, 0.171875), (0.171875, 0.1796875), (0.1796875, 0.1875), (0.1875, 0.1953125), (0.1953125, 0.203125), (0.203125, 0.2109375), (0.2109375, 0.21875), (0.21875, 0.2265625), (0.2265625, 0.234375), (0.234375, 0.2421875), (0.2421875, 0.25), (0.25, 0.2578125), (0.2578125, 0.265625), (0.265625, 0.2734375), (0.2734375, 0.28125), (0.28125, 0.2890625), (0.2890625, 0.296875), (0.296875, 0.3046875), (0.3046875, 0.3125), (0.3125, 0.3203125), (0.3203125, 0.328125), (0.328125, 0.3359375), (0.3359375, 0.34375), (0.34375, 0.3515625), (0.3515625, 0.359375), (0.359375, 0.3671875), (0.3671875, 0.375), (0.375, 0.3828125), (0.3828125, 0.390625), (0.390625, 0.3984375), (0.3984375, 0.40625), (0.40625, 0.4140625), (0.4140625, 0.421875), (0.421875, 0.4296875), (0.4296875, 0.4375), (0.4375, 0.4453125), (0.4453125, 0.453125), (0.453125, 0.4609375), (0.4609375, 0.46875), (0.46875, 0.4765625), (0.4765625, 0.484375), (0.484375, 0.4921875), (0.4921875, 0.5), (0.5, 0.5078125), (0.5078125, 0.515625), (0.515625, 0.5234375), (0.5234375, 0.53125), (0.53125, 0.5390625), (0.5390625, 0.546875), (0.546875, 0.5546875), (0.5546875, 0.5625), (0.5625, 0.5703125), (0.5703125, 0.578125), (0.578125, 0.5859375), (0.5859375, 0.59375), (0.59375, 0.6015625), (0.6015625, 0.609375), (0.609375, 0.6171875), (0.6171875, 0.625), (0.625, 0.6328125), (0.6328125, 0.640625), (0.640625, 0.6484375), (0.6484375, 0.65625), (0.65625, 0.6640625), (0.6640625, 0.671875), (0.671875, 0.6796875), (0.6796875, 0.6875), (0.6875, 0.6953125), (0.6953125, 0.703125), (0.703125, 0.7109375), (0.7109375, 0.71875), (0.71875, 0.7265625), (0.7265625, 0.734375), (0.734375, 0.7421875), (0.7421875, 0.75), (0.75, 0.7578125), (0.7578125, 0.765625), (0.765625, 0.7734375), (0.7734375, 0.78125), (0.78125, 0.7890625), (0.7890625, 0.796875), (0.796875, 0.8046875), (0.8046875, 0.8125), (0.8125, 0.8203125), (0.8203125, 0.828125), (0.828125, 0.8359375), (0.8359375, 0.84375), (0.84375, 0.8515625), (0.8515625, 0.859375), (0.859375, 0.8671875), (0.8671875, 0.875), (0.875, 0.8828125), (0.8828125, 0.890625), (0.890625, 0.8984375), (0.8984375, 0.90625), (0.90625, 0.9140625), (0.9140625, 0.921875), (0.921875, 0.9296875), (0.9296875, 0.9375), (0.9375, 0.9453125), (0.9453125, 0.953125), (0.953125, 0.9609375), (0.9609375, 0.96875), (0.96875, 0.9765625), (0.9765625, 0.984375), (0.984375, 0.9921875), (0.9921875, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "bin_ranges = []\n",
    "for i in range(len(bins) - 1):\n",
    "    bin_ranges.append((bins[i], bins[i + 1]))\n",
    "\n",
    "print(bin_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d385971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/a3murali/.cache/huggingface/token\n",
      "Login successful\n",
      "PyTorch Version: 1.13.0a0+d321be6\n",
      "Transformers Version: 4.35.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there was a dragon. The dragon was very big and scary. He lived in a cave. One day, the dragon said, \"I will be the strongest creature in the land.\" He was mean and breathed fire.\n",
      "\n",
      "The dragon wanted the kingdom's treasure. The king said, \"The dragon is not here to help us. He's not a friendly dragon.\" But the queen said, \"No, I don't think that's a good idea. The kingdom needs a kind friend.\" So they went to the dragon to ask him how much he wanted to help them. The dragon said, \"I can do a better job. I'll give you a special task.\"\n",
      "\n",
      "The kingdom was sad and said, \"We need someone to help us.\" But the dragon just laughed and said, \"I don't need to help. I will do it myself.\" The dragon used his fire to light a big fire and made the kingdom go dark. Then, the kingdom started to disappear. The people of the kingdom were trapped, and the dragon was left alone in the dark. The people said, \"We miss our kind friend, the king.\"\n",
      "\n",
      "The king and queen were sad. They wanted their kingdom back. But it was too late. The kingdom was gone, and the dragon was all alone in a dark, spooky world. \"I wish we had helped each other more,\" the dragon said. But it was too late now. The dragon was all alone in the dark cave.\n",
      "\n",
      "The king and queen were left all alone in the dark. They had lost their home, and the kingdom was gone. They were all very sad. The end.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (512). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((tensor([[[-0.0113, -0.0261,  0.0201,  ...,  0.0018,  0.0341, -0.0012],\n",
      "         [ 0.0033, -0.0344,  0.0053,  ..., -0.0281,  0.0047, -0.0484],\n",
      "         [-0.0171,  0.0029,  0.0054,  ..., -0.0119, -0.0021, -0.0067],\n",
      "         ...,\n",
      "         [-0.0328,  0.0076,  0.0059,  ...,  0.0085,  0.0026, -0.0034],\n",
      "         [-0.0136, -0.0042, -0.0017,  ...,  0.0433,  0.0067,  0.0043],\n",
      "         [-0.0075, -0.0111, -0.0146,  ..., -0.0316,  0.0212, -0.0185]]],\n",
      "       device='cuda:0'), tensor([[[ 0.2622, -0.0271, -0.1572,  ..., -0.4707,  0.6736, -0.4506],\n",
      "         [ 0.2784, -0.0843, -0.0334,  ..., -0.4175,  0.5123, -0.3506],\n",
      "         [ 0.2110,  0.0941, -0.0591,  ..., -0.1643,  0.2500, -0.2256],\n",
      "         ...,\n",
      "         [ 0.1558,  0.1417,  0.0469,  ...,  0.2122,  0.0154, -0.1033],\n",
      "         [-0.0196,  0.0330, -0.0048,  ...,  0.1516,  0.0030,  0.0158],\n",
      "         [-0.0184,  0.0482, -0.0476,  ...,  0.1827,  0.0080, -0.1848]]],\n",
      "       device='cuda:0'), tensor([[[ 0.1318, -0.3516,  0.3153,  ..., -0.4985,  0.7155, -0.4406],\n",
      "         [-0.0289, -0.0485,  0.2886,  ..., -0.4011,  0.5454, -0.4058],\n",
      "         [-0.0573,  0.1635,  0.0633,  ...,  0.0806,  0.3430, -0.2656],\n",
      "         ...,\n",
      "         [ 0.1412,  0.0686,  0.2109,  ...,  0.3936,  0.2380, -0.4187],\n",
      "         [ 0.0359, -0.0570,  0.2266,  ...,  0.2588,  0.1416, -0.3261],\n",
      "         [-0.0203, -0.0401,  0.1259,  ...,  0.3826,  0.2047, -0.4269]]],\n",
      "       device='cuda:0'), tensor([[[ 0.2893, -0.6681,  0.9027,  ..., -0.4443,  0.7517, -0.8656],\n",
      "         [-0.0124, -0.3234,  0.6558,  ..., -0.2219,  0.6519, -0.8386],\n",
      "         [-0.0466, -0.0520,  0.4719,  ...,  0.2519,  0.3133, -0.7997],\n",
      "         ...,\n",
      "         [ 0.3466,  0.0395,  0.1817,  ...,  0.4132,  0.1938, -0.7329],\n",
      "         [ 0.1697, -0.0412,  0.1026,  ...,  0.2571,  0.1294, -0.6026],\n",
      "         [ 0.0272,  0.0364,  0.1209,  ...,  0.3563,  0.2440, -0.7346]]],\n",
      "       device='cuda:0'), tensor([[[ 0.3583, -0.4285,  0.4851,  ..., -0.9060,  0.2924, -0.6405],\n",
      "         [-0.0770, -0.0449,  0.1313,  ..., -0.4432,  0.2624, -0.4836],\n",
      "         [-0.1397,  0.4187, -0.1108,  ...,  0.1721, -0.0904, -0.3034],\n",
      "         ...,\n",
      "         [ 0.3459, -0.0439,  0.1023,  ...,  0.3413,  0.3433, -0.1387],\n",
      "         [ 0.0733, -0.0798, -0.0037,  ...,  0.2416,  0.2102, -0.1467],\n",
      "         [ 0.0510, -0.0077,  0.0340,  ...,  0.3621,  0.3676, -0.1777]]],\n",
      "       device='cuda:0'), tensor([[[ 0.2483, -0.2390,  0.4439,  ..., -0.7018,  0.5774, -0.6920],\n",
      "         [-0.1764,  0.1380,  0.1587,  ..., -0.1847,  0.4236, -0.5697],\n",
      "         [-0.1541,  0.6106, -0.0241,  ...,  0.3823,  0.0138, -0.3955],\n",
      "         ...,\n",
      "         [ 0.2266, -0.4615,  0.1229,  ...,  0.5799,  0.7145, -0.1622],\n",
      "         [-0.0902, -0.5284,  0.0209,  ...,  0.5477,  0.6004, -0.1545],\n",
      "         [-0.1239, -0.4333,  0.0399,  ...,  0.5560,  0.8115, -0.2296]]],\n",
      "       device='cuda:0'), tensor([[[ 0.2293, -0.2988,  0.1661,  ..., -0.6270,  0.6463, -1.1747],\n",
      "         [-0.2833, -0.0860, -0.0756,  ..., -0.1406,  0.4628, -1.0108],\n",
      "         [-0.2412,  0.3513, -0.1995,  ...,  0.4348,  0.0217, -0.7293],\n",
      "         ...,\n",
      "         [ 0.0571, -0.5662, -0.0168,  ...,  0.8244,  0.9411, -0.2160],\n",
      "         [-0.2727, -0.6051, -0.1294,  ...,  0.8921,  0.7996, -0.2259],\n",
      "         [-0.2351, -0.4857, -0.1109,  ...,  0.8114,  1.0493, -0.2178]]],\n",
      "       device='cuda:0'), tensor([[[ 0.2191,  0.0845,  0.0887,  ..., -0.6002,  0.2597, -1.0333],\n",
      "         [-0.2773,  0.2040, -0.1838,  ..., -0.2126,  0.1769, -0.6830],\n",
      "         [-0.3250,  0.5740, -0.2497,  ...,  0.3461, -0.3337, -0.4170],\n",
      "         ...,\n",
      "         [-0.0126, -0.3065,  0.1975,  ...,  0.7167,  0.9857, -0.2726],\n",
      "         [-0.3278, -0.3491,  0.0720,  ...,  0.7244,  0.8601, -0.3189],\n",
      "         [-0.2733, -0.1668,  0.0864,  ...,  0.6042,  1.0852, -0.3084]]],\n",
      "       device='cuda:0'), tensor([[[ 0.4561, -0.4218,  0.1171,  ..., -0.5514,  0.0998, -1.0359],\n",
      "         [-0.4534, -0.1853, -0.4653,  ...,  0.0561,  0.0129, -0.2758],\n",
      "         [-0.4262,  0.5500, -0.5238,  ...,  1.0360, -0.8286,  0.1969],\n",
      "         ...,\n",
      "         [ 0.8755, -0.5496,  0.6302,  ...,  1.0697,  1.9210, -0.5076],\n",
      "         [ 0.3782, -0.5481,  0.3455,  ...,  1.0224,  1.7951, -0.6144],\n",
      "         [ 0.3865, -0.3275,  0.3813,  ...,  0.9253,  2.2065, -0.5053]]],\n",
      "       device='cuda:0')),)\n",
      "512\n",
      "9\n",
      "1\n",
      "335\n",
      "512\n",
      "790364160\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/expanse/lustre/projects/csd819/a3murali/cache/'\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token = \"<hf_token>\")\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Transformers Version: {transformers.__version__}\")\n",
    "\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer, AutoModelForCausalLM, pipeline, LlamaForCausalLM\n",
    "\n",
    "model = \"ivnle/llamatales_jr_8b-lay8-hs512-hd8-33M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "\n",
    "llamatales_pipeline = pipeline(\"text-generation\", model = model, device = \"cuda\")\n",
    "\n",
    "# prompts = {\n",
    "#     1: \"Once upon a time there was a dragon\", \n",
    "#     2: \"Once upon a time there was a princess\", \n",
    "#     3: \"Once upon a time there were two children\",\n",
    "#     4: \"Once upon a time there was a prince\",\n",
    "#     5: \"Once upon a time there was a frog\",\n",
    "#     6: \"Once upon a time there was a king\",\n",
    "#     7: \"Once upon a time there was a queen\",\n",
    "#     8: \"Once upon a time there was a wolf\",\n",
    "#     9: \"Once upon a time there was a genie\",\n",
    "#     10: \"Once upon a time there was a poor boy\"\n",
    "# }\n",
    "prompts = {1: \"Once upon a time there was a dragon\"}\n",
    "#generation - generate stories for each prompt\n",
    "sequences = llamatales_pipeline(\n",
    "    prompts[1],\n",
    "    do_sample = True,\n",
    "    top_k = 10,\n",
    "    num_return_sequences = 1,\n",
    "    max_new_tokens = 512\n",
    ")\n",
    "generated_story = sequences[0]['generated_text']\n",
    "print(generated_story)\n",
    "\n",
    "num_tokens_generated_story = len(tokenizer.encode(generated_story))\n",
    "\n",
    "#test - collect hidden states\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"/expanse/lustre/projects/csd819/a3murali/cache/models--ivnle--llamatales_jr_8b-lay8-hs512-hd8-33M/snapshots/461f50f0024efb46b94dc68cc850d12d75ecb325\", output_hidden_states = True)\n",
    "model = AutoModelForCausalLM.from_config(config).to('cuda')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/expanse/lustre/projects/csd819/a3murali/cache/models--ivnle--llamatales_jr_8b-lay8-hs512-hd8-33M/snapshots/461f50f0024efb46b94dc68cc850d12d75ecb325/\", config = config)\n",
    "\n",
    "inputs = tokenizer(generated_story, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(inputs.input_ids, attention_mask=inputs[\"attention_mask\"], do_sample = True, top_k = 10, num_return_sequences = 1, max_new_tokens = 512, eos_token_id = tokenizer.eos_token_id, pad_token_id = tokenizer.pad_token_id, return_dict_in_generate=True)\n",
    "\n",
    "print(outputs.hidden_states[:1])\n",
    "\n",
    "convert_hidden_states = []\n",
    "\n",
    "for i in outputs.hidden_states:\n",
    "    convert_hidden_states.append([j.detach().cpu().numpy() for j in i])\n",
    "\n",
    "print(len(convert_hidden_states))\n",
    "print(len(convert_hidden_states[0]))\n",
    "print(len(convert_hidden_states[0][0]))\n",
    "print(len(convert_hidden_states[0][0][0]))\n",
    "print(len(convert_hidden_states[0][0][0][0]))\n",
    "\n",
    "print(len(convert_hidden_states) * len(convert_hidden_states[0]) * len(convert_hidden_states[0][0]) * len(convert_hidden_states[0][0][0]) * len(convert_hidden_states[0][0][0][0]))\n",
    "\n",
    "convert_hidden_states = np.array([])\n",
    "\n",
    "for i in outputs.hidden_states:\n",
    "    for j in i:\n",
    "        convert_hidden_states = np.append(convert_hidden_states, j.detach().cpu().numpy())\n",
    "\n",
    "# print(\"Min Value: \", np.min(np.array(convert_hidden_states)))\n",
    "# print(\"Max Value: \", np.max(convert_hidden_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd9a2f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(3898368,)\n",
      "(3898368,)\n",
      "[-0.01130614 -0.0261382   0.02006644 ...  0.77043104  1.76886702\n",
      " -0.55354446]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m hidden_vals:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(bin_ranges)):\n\u001b[0;32m---> 11\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m(i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mbin_ranges\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m<\u001b[39m bin_ranges[j][\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m     12\u001b[0m             bin_counts[j \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(type(convert_hidden_states))\n",
    "print(convert_hidden_states.shape)\n",
    "hidden_vals = convert_hidden_states.flatten()\n",
    "print(hidden_vals.shape)\n",
    "bin_counts = [0 for i in range(len(bin_ranges) + 2)]\n",
    "# bin_counts.append(0)\n",
    "# bin_counts.append(0)\n",
    "print(hidden_vals)\n",
    "for i in hidden_vals:\n",
    "    for j in range(len(bin_ranges)):\n",
    "        if(i >= bin_ranges[j][0] and i < bin_ranges[j][1]):\n",
    "            bin_counts[j + 1] += 1\n",
    "    if(i < -1):\n",
    "        bin_counts[0] += 1\n",
    "    elif(i >= 1):\n",
    "        bin_counts[len(bin_counts) - 1] += 1\n",
    "\n",
    "\n",
    "# plt.hist(bin_counts, bins = 258)\n",
    "# plt.show()\n",
    "print(bin_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce860932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
