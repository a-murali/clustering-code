{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c37e65f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0, -0.9921875, -0.984375, -0.9765625, -0.96875, -0.9609375, -0.953125, -0.9453125, -0.9375, -0.9296875, -0.921875, -0.9140625, -0.90625, -0.8984375, -0.890625, -0.8828125, -0.875, -0.8671875, -0.859375, -0.8515625, -0.84375, -0.8359375, -0.828125, -0.8203125, -0.8125, -0.8046875, -0.796875, -0.7890625, -0.78125, -0.7734375, -0.765625, -0.7578125, -0.75, -0.7421875, -0.734375, -0.7265625, -0.71875, -0.7109375, -0.703125, -0.6953125, -0.6875, -0.6796875, -0.671875, -0.6640625, -0.65625, -0.6484375, -0.640625, -0.6328125, -0.625, -0.6171875, -0.609375, -0.6015625, -0.59375, -0.5859375, -0.578125, -0.5703125, -0.5625, -0.5546875, -0.546875, -0.5390625, -0.53125, -0.5234375, -0.515625, -0.5078125, -0.5, -0.4921875, -0.484375, -0.4765625, -0.46875, -0.4609375, -0.453125, -0.4453125, -0.4375, -0.4296875, -0.421875, -0.4140625, -0.40625, -0.3984375, -0.390625, -0.3828125, -0.375, -0.3671875, -0.359375, -0.3515625, -0.34375, -0.3359375, -0.328125, -0.3203125, -0.3125, -0.3046875, -0.296875, -0.2890625, -0.28125, -0.2734375, -0.265625, -0.2578125, -0.25, -0.2421875, -0.234375, -0.2265625, -0.21875, -0.2109375, -0.203125, -0.1953125, -0.1875, -0.1796875, -0.171875, -0.1640625, -0.15625, -0.1484375, -0.140625, -0.1328125, -0.125, -0.1171875, -0.109375, -0.1015625, -0.09375, -0.0859375, -0.078125, -0.0703125, -0.0625, -0.0546875, -0.046875, -0.0390625, -0.03125, -0.0234375, -0.015625, -0.0078125, 0.0, 0.0078125, 0.015625, 0.0234375, 0.03125, 0.0390625, 0.046875, 0.0546875, 0.0625, 0.0703125, 0.078125, 0.0859375, 0.09375, 0.1015625, 0.109375, 0.1171875, 0.125, 0.1328125, 0.140625, 0.1484375, 0.15625, 0.1640625, 0.171875, 0.1796875, 0.1875, 0.1953125, 0.203125, 0.2109375, 0.21875, 0.2265625, 0.234375, 0.2421875, 0.25, 0.2578125, 0.265625, 0.2734375, 0.28125, 0.2890625, 0.296875, 0.3046875, 0.3125, 0.3203125, 0.328125, 0.3359375, 0.34375, 0.3515625, 0.359375, 0.3671875, 0.375, 0.3828125, 0.390625, 0.3984375, 0.40625, 0.4140625, 0.421875, 0.4296875, 0.4375, 0.4453125, 0.453125, 0.4609375, 0.46875, 0.4765625, 0.484375, 0.4921875, 0.5, 0.5078125, 0.515625, 0.5234375, 0.53125, 0.5390625, 0.546875, 0.5546875, 0.5625, 0.5703125, 0.578125, 0.5859375, 0.59375, 0.6015625, 0.609375, 0.6171875, 0.625, 0.6328125, 0.640625, 0.6484375, 0.65625, 0.6640625, 0.671875, 0.6796875, 0.6875, 0.6953125, 0.703125, 0.7109375, 0.71875, 0.7265625, 0.734375, 0.7421875, 0.75, 0.7578125, 0.765625, 0.7734375, 0.78125, 0.7890625, 0.796875, 0.8046875, 0.8125, 0.8203125, 0.828125, 0.8359375, 0.84375, 0.8515625, 0.859375, 0.8671875, 0.875, 0.8828125, 0.890625, 0.8984375, 0.90625, 0.9140625, 0.921875, 0.9296875, 0.9375, 0.9453125, 0.953125, 0.9609375, 0.96875, 0.9765625, 0.984375, 0.9921875, 1.0]\n"
     ]
    }
   ],
   "source": [
    "#128 bins below 0\n",
    "#128 bins above 0\n",
    "#1 bin below -1\n",
    "#1 bin above 1\n",
    "bins = [i / 128 for i in range(-128, 129)]\n",
    "print(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95ee0016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins.insert(0, float(-inf))\n",
    "# bins.append(float(inf))\n",
    "# print(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a6005e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-1.0, -0.9921875), (-0.9921875, -0.984375), (-0.984375, -0.9765625), (-0.9765625, -0.96875), (-0.96875, -0.9609375), (-0.9609375, -0.953125), (-0.953125, -0.9453125), (-0.9453125, -0.9375), (-0.9375, -0.9296875), (-0.9296875, -0.921875), (-0.921875, -0.9140625), (-0.9140625, -0.90625), (-0.90625, -0.8984375), (-0.8984375, -0.890625), (-0.890625, -0.8828125), (-0.8828125, -0.875), (-0.875, -0.8671875), (-0.8671875, -0.859375), (-0.859375, -0.8515625), (-0.8515625, -0.84375), (-0.84375, -0.8359375), (-0.8359375, -0.828125), (-0.828125, -0.8203125), (-0.8203125, -0.8125), (-0.8125, -0.8046875), (-0.8046875, -0.796875), (-0.796875, -0.7890625), (-0.7890625, -0.78125), (-0.78125, -0.7734375), (-0.7734375, -0.765625), (-0.765625, -0.7578125), (-0.7578125, -0.75), (-0.75, -0.7421875), (-0.7421875, -0.734375), (-0.734375, -0.7265625), (-0.7265625, -0.71875), (-0.71875, -0.7109375), (-0.7109375, -0.703125), (-0.703125, -0.6953125), (-0.6953125, -0.6875), (-0.6875, -0.6796875), (-0.6796875, -0.671875), (-0.671875, -0.6640625), (-0.6640625, -0.65625), (-0.65625, -0.6484375), (-0.6484375, -0.640625), (-0.640625, -0.6328125), (-0.6328125, -0.625), (-0.625, -0.6171875), (-0.6171875, -0.609375), (-0.609375, -0.6015625), (-0.6015625, -0.59375), (-0.59375, -0.5859375), (-0.5859375, -0.578125), (-0.578125, -0.5703125), (-0.5703125, -0.5625), (-0.5625, -0.5546875), (-0.5546875, -0.546875), (-0.546875, -0.5390625), (-0.5390625, -0.53125), (-0.53125, -0.5234375), (-0.5234375, -0.515625), (-0.515625, -0.5078125), (-0.5078125, -0.5), (-0.5, -0.4921875), (-0.4921875, -0.484375), (-0.484375, -0.4765625), (-0.4765625, -0.46875), (-0.46875, -0.4609375), (-0.4609375, -0.453125), (-0.453125, -0.4453125), (-0.4453125, -0.4375), (-0.4375, -0.4296875), (-0.4296875, -0.421875), (-0.421875, -0.4140625), (-0.4140625, -0.40625), (-0.40625, -0.3984375), (-0.3984375, -0.390625), (-0.390625, -0.3828125), (-0.3828125, -0.375), (-0.375, -0.3671875), (-0.3671875, -0.359375), (-0.359375, -0.3515625), (-0.3515625, -0.34375), (-0.34375, -0.3359375), (-0.3359375, -0.328125), (-0.328125, -0.3203125), (-0.3203125, -0.3125), (-0.3125, -0.3046875), (-0.3046875, -0.296875), (-0.296875, -0.2890625), (-0.2890625, -0.28125), (-0.28125, -0.2734375), (-0.2734375, -0.265625), (-0.265625, -0.2578125), (-0.2578125, -0.25), (-0.25, -0.2421875), (-0.2421875, -0.234375), (-0.234375, -0.2265625), (-0.2265625, -0.21875), (-0.21875, -0.2109375), (-0.2109375, -0.203125), (-0.203125, -0.1953125), (-0.1953125, -0.1875), (-0.1875, -0.1796875), (-0.1796875, -0.171875), (-0.171875, -0.1640625), (-0.1640625, -0.15625), (-0.15625, -0.1484375), (-0.1484375, -0.140625), (-0.140625, -0.1328125), (-0.1328125, -0.125), (-0.125, -0.1171875), (-0.1171875, -0.109375), (-0.109375, -0.1015625), (-0.1015625, -0.09375), (-0.09375, -0.0859375), (-0.0859375, -0.078125), (-0.078125, -0.0703125), (-0.0703125, -0.0625), (-0.0625, -0.0546875), (-0.0546875, -0.046875), (-0.046875, -0.0390625), (-0.0390625, -0.03125), (-0.03125, -0.0234375), (-0.0234375, -0.015625), (-0.015625, -0.0078125), (-0.0078125, 0.0), (0.0, 0.0078125), (0.0078125, 0.015625), (0.015625, 0.0234375), (0.0234375, 0.03125), (0.03125, 0.0390625), (0.0390625, 0.046875), (0.046875, 0.0546875), (0.0546875, 0.0625), (0.0625, 0.0703125), (0.0703125, 0.078125), (0.078125, 0.0859375), (0.0859375, 0.09375), (0.09375, 0.1015625), (0.1015625, 0.109375), (0.109375, 0.1171875), (0.1171875, 0.125), (0.125, 0.1328125), (0.1328125, 0.140625), (0.140625, 0.1484375), (0.1484375, 0.15625), (0.15625, 0.1640625), (0.1640625, 0.171875), (0.171875, 0.1796875), (0.1796875, 0.1875), (0.1875, 0.1953125), (0.1953125, 0.203125), (0.203125, 0.2109375), (0.2109375, 0.21875), (0.21875, 0.2265625), (0.2265625, 0.234375), (0.234375, 0.2421875), (0.2421875, 0.25), (0.25, 0.2578125), (0.2578125, 0.265625), (0.265625, 0.2734375), (0.2734375, 0.28125), (0.28125, 0.2890625), (0.2890625, 0.296875), (0.296875, 0.3046875), (0.3046875, 0.3125), (0.3125, 0.3203125), (0.3203125, 0.328125), (0.328125, 0.3359375), (0.3359375, 0.34375), (0.34375, 0.3515625), (0.3515625, 0.359375), (0.359375, 0.3671875), (0.3671875, 0.375), (0.375, 0.3828125), (0.3828125, 0.390625), (0.390625, 0.3984375), (0.3984375, 0.40625), (0.40625, 0.4140625), (0.4140625, 0.421875), (0.421875, 0.4296875), (0.4296875, 0.4375), (0.4375, 0.4453125), (0.4453125, 0.453125), (0.453125, 0.4609375), (0.4609375, 0.46875), (0.46875, 0.4765625), (0.4765625, 0.484375), (0.484375, 0.4921875), (0.4921875, 0.5), (0.5, 0.5078125), (0.5078125, 0.515625), (0.515625, 0.5234375), (0.5234375, 0.53125), (0.53125, 0.5390625), (0.5390625, 0.546875), (0.546875, 0.5546875), (0.5546875, 0.5625), (0.5625, 0.5703125), (0.5703125, 0.578125), (0.578125, 0.5859375), (0.5859375, 0.59375), (0.59375, 0.6015625), (0.6015625, 0.609375), (0.609375, 0.6171875), (0.6171875, 0.625), (0.625, 0.6328125), (0.6328125, 0.640625), (0.640625, 0.6484375), (0.6484375, 0.65625), (0.65625, 0.6640625), (0.6640625, 0.671875), (0.671875, 0.6796875), (0.6796875, 0.6875), (0.6875, 0.6953125), (0.6953125, 0.703125), (0.703125, 0.7109375), (0.7109375, 0.71875), (0.71875, 0.7265625), (0.7265625, 0.734375), (0.734375, 0.7421875), (0.7421875, 0.75), (0.75, 0.7578125), (0.7578125, 0.765625), (0.765625, 0.7734375), (0.7734375, 0.78125), (0.78125, 0.7890625), (0.7890625, 0.796875), (0.796875, 0.8046875), (0.8046875, 0.8125), (0.8125, 0.8203125), (0.8203125, 0.828125), (0.828125, 0.8359375), (0.8359375, 0.84375), (0.84375, 0.8515625), (0.8515625, 0.859375), (0.859375, 0.8671875), (0.8671875, 0.875), (0.875, 0.8828125), (0.8828125, 0.890625), (0.890625, 0.8984375), (0.8984375, 0.90625), (0.90625, 0.9140625), (0.9140625, 0.921875), (0.921875, 0.9296875), (0.9296875, 0.9375), (0.9375, 0.9453125), (0.9453125, 0.953125), (0.953125, 0.9609375), (0.9609375, 0.96875), (0.96875, 0.9765625), (0.9765625, 0.984375), (0.984375, 0.9921875), (0.9921875, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "bin_ranges = []\n",
    "for i in range(len(bins) - 1):\n",
    "    bin_ranges.append((bins[i], bins[i + 1]))\n",
    "\n",
    "print(bin_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a009f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/expanse/lustre/projects/csd819/a3murali/cache/'\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token = \"<hf_token>\")\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Transformers Version: {transformers.__version__}\")\n",
    "\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer, AutoModelForCausalLM, pipeline, LlamaForCausalLM\n",
    "\n",
    "model = \"ivnle/llamatales_jr_8b-lay8-hs512-hd8-33M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "\n",
    "llamatales_pipeline = pipeline(\"text-generation\", model = model, device = \"cuda\")\n",
    "\n",
    "# prompts = {\n",
    "#     1: \"Once upon a time there was a dragon\", \n",
    "#     2: \"Once upon a time there was a princess\", \n",
    "#     3: \"Once upon a time there were two children\",\n",
    "#     4: \"Once upon a time there was a prince\",\n",
    "#     5: \"Once upon a time there was a frog\",\n",
    "#     6: \"Once upon a time there was a king\",\n",
    "#     7: \"Once upon a time there was a queen\",\n",
    "#     8: \"Once upon a time there was a wolf\",\n",
    "#     9: \"Once upon a time there was a genie\",\n",
    "#     10: \"Once upon a time there was a poor boy\"\n",
    "# }\n",
    "prompts = {1: \"Once upon a time there was a dragon\"}\n",
    "#generation - generate stories for each prompt\n",
    "sequences = llamatales_pipeline(\n",
    "    prompts[1],\n",
    "    do_sample = True,\n",
    "    top_k = 10,\n",
    "    num_return_sequences = 1,\n",
    "    max_new_tokens = 512\n",
    ")\n",
    "generated_story = sequences[0]['generated_text']\n",
    "print(generated_story)\n",
    "\n",
    "num_tokens_generated_story = len(tokenizer.encode(generated_story))\n",
    "\n",
    "#test - collect hidden states\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"/expanse/lustre/projects/csd819/a3murali/cache/models--ivnle--llamatales_jr_8b-lay8-hs512-hd8-33M/snapshots/461f50f0024efb46b94dc68cc850d12d75ecb325\", output_hidden_states = True)\n",
    "model = AutoModelForCausalLM.from_config(config).to('cuda')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/expanse/lustre/projects/csd819/a3murali/cache/models--ivnle--llamatales_jr_8b-lay8-hs512-hd8-33M/snapshots/461f50f0024efb46b94dc68cc850d12d75ecb325/\", config = config)\n",
    "\n",
    "inputs = tokenizer(generated_story, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(inputs.input_ids, attention_mask=inputs[\"attention_mask\"], do_sample = True, top_k = 10, num_return_sequences = 1, max_new_tokens = 512, eos_token_id = tokenizer.eos_token_id, pad_token_id = tokenizer.pad_token_id, return_dict_in_generate=True)\n",
    "\n",
    "convert_hidden_states = np.array([])\n",
    "\n",
    "convert_hidden_states = np.append(convert_hidden_states, np.array([j.detach().cpu().numpy() for j in i]))\n",
    "\n",
    "# print(\"Min Value: \", np.min(np.array(convert_hidden_states)))\n",
    "# print(\"Max Value: \", np.max(convert_hidden_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "054e65c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(3635712,)\n",
      "(3635712,)\n",
      "[ 0.00562103 -0.00115525  0.0048254  ...  0.9034965  -0.09795559\n",
      "  0.28680092]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m hidden_vals:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(bin_ranges)):\n\u001b[0;32m---> 11\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m(\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbin_ranges\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m<\u001b[39m bin_ranges[j][\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m     12\u001b[0m             bin_counts[j \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(type(convert_hidden_states))\n",
    "print(convert_hidden_states.shape)\n",
    "hidden_vals = convert_hidden_states.flatten()\n",
    "print(hidden_vals.shape)\n",
    "bin_counts = [0 for i in range(len(bin_ranges) + 2)]\n",
    "# bin_counts.append(0)\n",
    "# bin_counts.append(0)\n",
    "print(hidden_vals)\n",
    "for i in hidden_vals:\n",
    "    for j in range(len(bin_ranges)):\n",
    "        if(i >= bin_ranges[j][0] and i < bin_ranges[j][1]):\n",
    "            bin_counts[j + 1] += 1\n",
    "    if(i < -1):\n",
    "        bin_counts[0] += 1\n",
    "    elif(i >= 1):\n",
    "        bin_counts[len(bin_counts) - 1] += 1\n",
    "\n",
    "\n",
    "# plt.hist(bin_counts, bins = 258)\n",
    "# plt.show()\n",
    "print(bin_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68166eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
