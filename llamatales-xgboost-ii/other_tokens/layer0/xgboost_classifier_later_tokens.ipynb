{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "138b9187-7def-48ff-a26f-12d249897810",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost.core import XGBoostError\n",
    "\n",
    "import csv\n",
    "\n",
    "import cupy as cp\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40fe6220-eee3-4f0c-9427-46fa99111a13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>story</th>\n",
       "      <th>hidden_state_file</th>\n",
       "      <th>len_generated_story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon. It was bi...</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon. He loved ...</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon named Sam....</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon. He was a ...</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon. The drago...</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prompt_id                                 prompt  \\\n",
       "0             1    Once upon a time there was a dragon   \n",
       "1             1    Once upon a time there was a dragon   \n",
       "2             1    Once upon a time there was a dragon   \n",
       "3             1    Once upon a time there was a dragon   \n",
       "4             1    Once upon a time there was a dragon   \n",
       "...         ...                                    ...   \n",
       "9995         10  Once upon a time there was a poor boy   \n",
       "9996         10  Once upon a time there was a poor boy   \n",
       "9997         10  Once upon a time there was a poor boy   \n",
       "9998         10  Once upon a time there was a poor boy   \n",
       "9999         10  Once upon a time there was a poor boy   \n",
       "\n",
       "                                                  story  \\\n",
       "0     Once upon a time there was a dragon. It was bi...   \n",
       "1     Once upon a time there was a dragon. He loved ...   \n",
       "2     Once upon a time there was a dragon named Sam....   \n",
       "3     Once upon a time there was a dragon. He was a ...   \n",
       "4     Once upon a time there was a dragon. The drago...   \n",
       "...                                                 ...   \n",
       "9995  Once upon a time there was a poor boy named Ti...   \n",
       "9996  Once upon a time there was a poor boy named Ti...   \n",
       "9997  Once upon a time there was a poor boy named Ti...   \n",
       "9998  Once upon a time there was a poor boy named Ti...   \n",
       "9999  Once upon a time there was a poor boy named Ti...   \n",
       "\n",
       "                  hidden_state_file  len_generated_story  \n",
       "0      ./hidden_states/prompt_1.npz                  273  \n",
       "1      ./hidden_states/prompt_1.npz                  246  \n",
       "2      ./hidden_states/prompt_1.npz                  397  \n",
       "3      ./hidden_states/prompt_1.npz                  294  \n",
       "4      ./hidden_states/prompt_1.npz                  296  \n",
       "...                             ...                  ...  \n",
       "9995  ./hidden_states/prompt_10.npz                  315  \n",
       "9996  ./hidden_states/prompt_10.npz                  270  \n",
       "9997  ./hidden_states/prompt_10.npz                  206  \n",
       "9998  ./hidden_states/prompt_10.npz                  375  \n",
       "9999  ./hidden_states/prompt_10.npz                  341  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../story_dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39918677-9de6-47de-9cd9-cdfe96b79439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hidden_states_by_layer = {}\n",
    "# curr_labels = []\n",
    "# NUM_PROMPTS = 10\n",
    "# # NUM_PROMPTS = 2\n",
    "# context_level = 49\n",
    "\n",
    "# #Load hidden states to generate first token\n",
    "# for prompt_id in range(1, NUM_PROMPTS + 1):\n",
    "#     with np.load(f'../../hidden_states/prompt_{prompt_id}.npz') as loaded_data:\n",
    "#         for i in tqdm(range(1000)):\n",
    "#             curr_hidden_states = loaded_data[f\"arr_{i}\"]\n",
    "#             # print(curr_hidden_states.shape)\n",
    "#             if(context_level > curr_hidden_states.shape[0]):\n",
    "#                 continue\n",
    "\n",
    "#             curr_hidden_states = curr_hidden_states[context_level]\n",
    "#             curr_labels.append(df.iloc[i * prompt_id].prompt_id)\n",
    "            \n",
    "#             #By layer\n",
    "#             for layer in range(1):\n",
    "#                 curr_layer_hidden_states = curr_hidden_states[layer][0].astype('float32') #FAISS expects data in type float32 instead of float64 - saves memory too!\n",
    "#                 # print(curr_layer_hidden_states.shape)\n",
    "                \n",
    "#                 if(f\"layer_{layer}\" in hidden_states_by_layer):\n",
    "#                     hidden_states_by_layer[f\"layer_{layer}\"].append(curr_layer_hidden_states)\n",
    "#                 else:\n",
    "#                     hidden_states_by_layer[f\"layer_{layer}\"] = [curr_layer_hidden_states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bcf72d3-5120-4cc8-9ac4-ae6c5f512723",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states_by_cl = {}\n",
    "curr_labels = {}\n",
    "NUM_PROMPTS = 10\n",
    "layer = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6a6dd98-d137-4966-8772-5af229b96a72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len = max(df[:NUM_PROMPTS*1000][\"len_generated_story\"])\n",
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bad53aa-086a-409e-8cb8-6abc9375ef9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>story</th>\n",
       "      <th>hidden_state_file</th>\n",
       "      <th>len_generated_story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9851</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prompt_id                                 prompt  \\\n",
       "9851         10  Once upon a time there was a poor boy   \n",
       "\n",
       "                                                  story  \\\n",
       "9851  Once upon a time there was a poor boy named Ti...   \n",
       "\n",
       "                  hidden_state_file  len_generated_story  \n",
       "9851  ./hidden_states/prompt_10.npz                  522  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"len_generated_story\"] >= max_story_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07f82317-93da-4fcd-bbc2-14f05b26994e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_story_len = min(df[\"len_generated_story\"])\n",
    "min_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d45fce9e-1ecd-4c07-9171-8085f6fc7460",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_levels = [0] #get hs used to generate second token\n",
    "context_levels.extend([i for i in range(23, max_story_len, 25)]) #actual context level is context_level + 2 (gather hs to generate the context_level + 2 token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12c1fbb9-0515-465d-8246-1691fa440f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #results using hs to generate first token already captured in other notebook\n",
    "# #get hs to generate second token, 25th token, 50th token, etc.\n",
    "\n",
    "# #Load hidden states to generate first token\n",
    "# for prompt_id in range(1, NUM_PROMPTS + 1):\n",
    "#     with np.load(f'../../hidden_states/prompt_{prompt_id}.npz') as loaded_data:\n",
    "#         for i in tqdm(range(1000)):\n",
    "#             for context_level in context_levels:\n",
    "#                 curr_hidden_states = loaded_data[f\"arr_{i}\"]\n",
    "#                 # print(curr_hidden_states.shape)\n",
    "#                 if(context_level > curr_hidden_states.shape[0] - 1):\n",
    "#                     continue\n",
    "                \n",
    "#                 curr_hidden_states = curr_hidden_states[context_level][layer][0].astype('float32')\n",
    "                \n",
    "#                 if(f\"cl_{context_level + 2}\" in hidden_states_by_cl):\n",
    "#                     hidden_states_by_cl[f\"cl_{context_level + 2}\"].append(curr_hidden_states)\n",
    "#                     curr_labels[f\"cl_{context_level + 2}\"].append(df.iloc[i * prompt_id].prompt_id)\n",
    "#                 else:\n",
    "#                     hidden_states_by_cl[f\"cl_{context_level + 2}\"] = [curr_hidden_states]\n",
    "#                     curr_labels[f\"cl_{context_level + 2}\"] = [df.iloc[i * prompt_id].prompt_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4990ba60-9834-46aa-bf55-ac67088bd227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:22<00:00, 44.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:20<00:00, 47.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:22<00:00, 44.13it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:20<00:00, 48.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:21<00:00, 45.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:20<00:00, 48.73it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:20<00:00, 48.36it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:21<00:00, 47.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:22<00:00, 43.48it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:23<00:00, 43.26it/s]\n"
     ]
    }
   ],
   "source": [
    "hidden_states_by_cl = {f\"cl_{cl+2}\": [] for cl in context_levels}\n",
    "curr_labels = {f\"cl_{cl+2}\": [] for cl in context_levels}\n",
    "\n",
    "for prompt_id in range(1, NUM_PROMPTS + 1):\n",
    "    with np.load(f'../../hidden_states/prompt_{prompt_id}.npz') as loaded_data:\n",
    "\n",
    "        for i in tqdm(range(1000)):\n",
    "            hs = loaded_data[f\"arr_{i}\"]  # load once\n",
    "\n",
    "            for context_level in context_levels:\n",
    "                if context_level >= hs.shape[0]:\n",
    "                    continue\n",
    "\n",
    "                key = f\"cl_{context_level + 2}\"\n",
    "\n",
    "                hidden_states_by_cl[key].append(\n",
    "                    hs[context_level][layer][0].astype(\"float32\")\n",
    "                )\n",
    "                curr_labels[key].append(prompt_id - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fc51a06-9ad8-4e4f-b338-73e2ac5b96cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def safe_split(total, train_ratio=0.8):\n",
    "    train = int(train_ratio * total)   # floor\n",
    "    test  = total - train              # leftover\n",
    "    return train, test\n",
    "\n",
    "def build_dataset(curr_context_level_hs, curr_labels, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Groups samples by prompt_id, splits safely into train/test,\n",
    "    and returns X_train, y_train, X_test, y_test.\n",
    "    \"\"\"\n",
    "\n",
    "    unique_ids = sorted(set(curr_labels))\n",
    "\n",
    "    X_train_list = []\n",
    "    X_test_list = []\n",
    "    y_train_list = []\n",
    "    y_test_list = []\n",
    "\n",
    "    for pid in unique_ids:\n",
    "\n",
    "        # get samples for this prompt id\n",
    "        mask = (curr_labels == pid)\n",
    "        X_pid = curr_context_level_hs[mask]\n",
    "        y_pid = curr_labels[mask]\n",
    "\n",
    "        total = len(X_pid)\n",
    "        train_n, test_n = safe_split(total, train_ratio)\n",
    "\n",
    "        # split\n",
    "        X_train_list.append(X_pid[:train_n])\n",
    "        y_train_list.append(y_pid[:train_n])\n",
    "\n",
    "        X_test_list.append(X_pid[train_n:])\n",
    "        y_test_list.append(y_pid[train_n:])\n",
    "\n",
    "    # concatenate all prompt-id blocks\n",
    "    X_train = np.concatenate(X_train_list, axis=0)\n",
    "    y_train = np.concatenate(y_train_list, axis=0)\n",
    "    X_test  = np.concatenate(X_test_list, axis=0)\n",
    "    y_test  = np.concatenate(y_test_list, axis=0)\n",
    "\n",
    "    # return cp.array(X_train), cp.array(y_train), cp.array(X_test), cp.array(y_test)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c4b6544-7649-4390-8bbe-fe4ce312d3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1, 512)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(hidden_states_by_cl[f\"cl_2\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29da1cb8-6627-48b9-9a31-b6019108ac00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(curr_labels[f\"cl_2\"]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d26b3c5-e3ab-4823-954a-6937a516890e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 512)\n",
      "(10000, 512)\n",
      "0    800\n",
      "1    800\n",
      "2    800\n",
      "3    800\n",
      "4    800\n",
      "5    800\n",
      "6    800\n",
      "7    800\n",
      "8    800\n",
      "9    800\n",
      "Name: count, dtype: int64\n",
      "0    200\n",
      "1    200\n",
      "2    200\n",
      "3    200\n",
      "4    200\n",
      "5    200\n",
      "6    200\n",
      "7    200\n",
      "8    200\n",
      "9    200\n",
      "Name: count, dtype: int64\n",
      "Train Data Shape:  (8000, 512)\n",
      "Test Data Shape:  (2000, 512)\n",
      "Train Accuracy: 0.271625\n",
      "Test Accuracy: 0.272\n",
      "Prompt 1 Train Accuracy: 0.00375\n",
      "Prompt 1 Test Accuracy: 0.0\n",
      "Prompt 2 Train Accuracy: 0.0\n",
      "Prompt 2 Test Accuracy: 0.0\n",
      "Prompt 3 Train Accuracy: 0.59375\n",
      "Prompt 3 Test Accuracy: 0.655\n",
      "Prompt 4 Train Accuracy: 0.0075\n",
      "Prompt 4 Test Accuracy: 0.0\n",
      "Prompt 5 Train Accuracy: 0.97875\n",
      "Prompt 5 Test Accuracy: 0.995\n",
      "Prompt 6 Train Accuracy: 0.14\n",
      "Prompt 6 Test Accuracy: 0.1\n",
      "Prompt 7 Train Accuracy: 0.88875\n",
      "Prompt 7 Test Accuracy: 0.86\n",
      "Prompt 8 Train Accuracy: 0.0\n",
      "Prompt 8 Test Accuracy: 0.0\n",
      "Prompt 9 Train Accuracy: 0.10375\n",
      "Prompt 9 Test Accuracy: 0.11\n",
      "Prompt 10 Train Accuracy: 0.0\n",
      "Prompt 10 Test Accuracy: 0.0\n",
      "(10000, 512)\n",
      "(10000, 512)\n",
      "0    800\n",
      "1    800\n",
      "2    800\n",
      "3    800\n",
      "4    800\n",
      "5    800\n",
      "6    800\n",
      "7    800\n",
      "8    800\n",
      "9    800\n",
      "Name: count, dtype: int64\n",
      "0    200\n",
      "1    200\n",
      "2    200\n",
      "3    200\n",
      "4    200\n",
      "5    200\n",
      "6    200\n",
      "7    200\n",
      "8    200\n",
      "9    200\n",
      "Name: count, dtype: int64\n",
      "Train Data Shape:  (8000, 512)\n",
      "Test Data Shape:  (2000, 512)\n",
      "Train Accuracy: 0.314625\n",
      "Test Accuracy: 0.182\n",
      "Prompt 1 Train Accuracy: 0.32625\n",
      "Prompt 1 Test Accuracy: 0.24\n",
      "Prompt 2 Train Accuracy: 0.26\n",
      "Prompt 2 Test Accuracy: 0.105\n",
      "Prompt 3 Train Accuracy: 0.26875\n",
      "Prompt 3 Test Accuracy: 0.165\n",
      "Prompt 4 Train Accuracy: 0.2375\n",
      "Prompt 4 Test Accuracy: 0.15\n",
      "Prompt 5 Train Accuracy: 0.40625\n",
      "Prompt 5 Test Accuracy: 0.27\n",
      "Prompt 6 Train Accuracy: 0.295\n",
      "Prompt 6 Test Accuracy: 0.175\n",
      "Prompt 7 Train Accuracy: 0.2575\n",
      "Prompt 7 Test Accuracy: 0.135\n",
      "Prompt 8 Train Accuracy: 0.43\n",
      "Prompt 8 Test Accuracy: 0.27\n",
      "Prompt 9 Train Accuracy: 0.28875\n",
      "Prompt 9 Test Accuracy: 0.1\n",
      "Prompt 10 Train Accuracy: 0.37625\n",
      "Prompt 10 Test Accuracy: 0.21\n",
      "(9999, 512)\n",
      "(9999, 512)\n",
      "0    800\n",
      "1    800\n",
      "2    800\n",
      "3    800\n",
      "4    800\n",
      "5    800\n",
      "7    800\n",
      "8    800\n",
      "9    800\n",
      "6    799\n",
      "Name: count, dtype: int64\n",
      "0    200\n",
      "1    200\n",
      "2    200\n",
      "3    200\n",
      "4    200\n",
      "5    200\n",
      "6    200\n",
      "7    200\n",
      "8    200\n",
      "9    200\n",
      "Name: count, dtype: int64\n",
      "Train Data Shape:  (7999, 512)\n",
      "Test Data Shape:  (2000, 512)\n",
      "Train Accuracy: 0.32079009876234527\n",
      "Test Accuracy: 0.155\n",
      "Prompt 1 Train Accuracy: 0.3525\n",
      "Prompt 1 Test Accuracy: 0.195\n",
      "Prompt 2 Train Accuracy: 0.255\n",
      "Prompt 2 Test Accuracy: 0.1\n",
      "Prompt 3 Train Accuracy: 0.34125\n",
      "Prompt 3 Test Accuracy: 0.14\n",
      "Prompt 4 Train Accuracy: 0.34375\n",
      "Prompt 4 Test Accuracy: 0.13\n",
      "Prompt 5 Train Accuracy: 0.33625\n",
      "Prompt 5 Test Accuracy: 0.16\n",
      "Prompt 6 Train Accuracy: 0.33625\n",
      "Prompt 6 Test Accuracy: 0.165\n",
      "Prompt 7 Train Accuracy: 0.25782227784730916\n",
      "Prompt 7 Test Accuracy: 0.115\n",
      "Prompt 8 Train Accuracy: 0.3325\n",
      "Prompt 8 Test Accuracy: 0.215\n",
      "Prompt 9 Train Accuracy: 0.31125\n",
      "Prompt 9 Test Accuracy: 0.165\n",
      "Prompt 10 Train Accuracy: 0.34125\n",
      "Prompt 10 Test Accuracy: 0.165\n",
      "(9999, 512)\n",
      "(9999, 512)\n",
      "0    800\n",
      "1    800\n",
      "2    800\n",
      "3    800\n",
      "4    800\n",
      "5    800\n",
      "7    800\n",
      "8    800\n",
      "9    800\n",
      "6    799\n",
      "Name: count, dtype: int64\n",
      "0    200\n",
      "1    200\n",
      "2    200\n",
      "3    200\n",
      "4    200\n",
      "5    200\n",
      "6    200\n",
      "7    200\n",
      "8    200\n",
      "9    200\n",
      "Name: count, dtype: int64\n",
      "Train Data Shape:  (7999, 512)\n",
      "Test Data Shape:  (2000, 512)\n",
      "Train Accuracy: 0.32779097387173395\n",
      "Test Accuracy: 0.1545\n",
      "Prompt 1 Train Accuracy: 0.28375\n",
      "Prompt 1 Test Accuracy: 0.14\n",
      "Prompt 2 Train Accuracy: 0.2375\n",
      "Prompt 2 Test Accuracy: 0.095\n",
      "Prompt 3 Train Accuracy: 0.38375\n",
      "Prompt 3 Test Accuracy: 0.17\n",
      "Prompt 4 Train Accuracy: 0.3675\n",
      "Prompt 4 Test Accuracy: 0.195\n",
      "Prompt 5 Train Accuracy: 0.3025\n",
      "Prompt 5 Test Accuracy: 0.13\n",
      "Prompt 6 Train Accuracy: 0.37125\n",
      "Prompt 6 Test Accuracy: 0.22\n",
      "Prompt 7 Train Accuracy: 0.2565707133917397\n",
      "Prompt 7 Test Accuracy: 0.075\n",
      "Prompt 8 Train Accuracy: 0.4375\n",
      "Prompt 8 Test Accuracy: 0.18\n",
      "Prompt 9 Train Accuracy: 0.285\n",
      "Prompt 9 Test Accuracy: 0.14\n",
      "Prompt 10 Train Accuracy: 0.3525\n",
      "Prompt 10 Test Accuracy: 0.2\n",
      "(9999, 512)\n",
      "(9999, 512)\n",
      "0    800\n",
      "1    800\n",
      "2    800\n",
      "3    800\n",
      "4    800\n",
      "5    800\n",
      "7    800\n",
      "8    800\n",
      "9    800\n",
      "6    799\n",
      "Name: count, dtype: int64\n",
      "0    200\n",
      "1    200\n",
      "2    200\n",
      "3    200\n",
      "4    200\n",
      "5    200\n",
      "6    200\n",
      "7    200\n",
      "8    200\n",
      "9    200\n",
      "Name: count, dtype: int64\n",
      "Train Data Shape:  (7999, 512)\n",
      "Test Data Shape:  (2000, 512)\n",
      "Train Accuracy: 0.3226653331666458\n",
      "Test Accuracy: 0.151\n",
      "Prompt 1 Train Accuracy: 0.28\n",
      "Prompt 1 Test Accuracy: 0.135\n",
      "Prompt 2 Train Accuracy: 0.3275\n",
      "Prompt 2 Test Accuracy: 0.12\n",
      "Prompt 3 Train Accuracy: 0.4675\n",
      "Prompt 3 Test Accuracy: 0.265\n",
      "Prompt 4 Train Accuracy: 0.28875\n",
      "Prompt 4 Test Accuracy: 0.15\n",
      "Prompt 5 Train Accuracy: 0.285\n",
      "Prompt 5 Test Accuracy: 0.115\n",
      "Prompt 6 Train Accuracy: 0.24875\n",
      "Prompt 6 Test Accuracy: 0.12\n",
      "Prompt 7 Train Accuracy: 0.34167709637046306\n",
      "Prompt 7 Test Accuracy: 0.14\n",
      "Prompt 8 Train Accuracy: 0.33625\n",
      "Prompt 8 Test Accuracy: 0.15\n",
      "Prompt 9 Train Accuracy: 0.275\n",
      "Prompt 9 Test Accuracy: 0.145\n",
      "Prompt 10 Train Accuracy: 0.37625\n",
      "Prompt 10 Test Accuracy: 0.17\n",
      "(9999, 512)\n",
      "(9999, 512)\n",
      "0    800\n",
      "1    800\n",
      "2    800\n",
      "3    800\n",
      "4    800\n",
      "5    800\n",
      "7    800\n",
      "8    800\n",
      "9    800\n",
      "6    799\n",
      "Name: count, dtype: int64\n",
      "0    200\n",
      "1    200\n",
      "2    200\n",
      "3    200\n",
      "4    200\n",
      "5    200\n",
      "6    200\n",
      "7    200\n",
      "8    200\n",
      "9    200\n",
      "Name: count, dtype: int64\n",
      "Train Data Shape:  (7999, 512)\n",
      "Test Data Shape:  (2000, 512)\n",
      "Train Accuracy: 0.31978997374671836\n",
      "Test Accuracy: 0.1675\n",
      "Prompt 1 Train Accuracy: 0.32125\n",
      "Prompt 1 Test Accuracy: 0.155\n",
      "Prompt 2 Train Accuracy: 0.3675\n",
      "Prompt 2 Test Accuracy: 0.205\n",
      "Prompt 3 Train Accuracy: 0.3325\n",
      "Prompt 3 Test Accuracy: 0.155\n",
      "Prompt 4 Train Accuracy: 0.20875\n",
      "Prompt 4 Test Accuracy: 0.045\n",
      "Prompt 5 Train Accuracy: 0.31375\n",
      "Prompt 5 Test Accuracy: 0.155\n",
      "Prompt 6 Train Accuracy: 0.305\n",
      "Prompt 6 Test Accuracy: 0.175\n",
      "Prompt 7 Train Accuracy: 0.3742177722152691\n",
      "Prompt 7 Test Accuracy: 0.285\n",
      "Prompt 8 Train Accuracy: 0.33125\n",
      "Prompt 8 Test Accuracy: 0.165\n",
      "Prompt 9 Train Accuracy: 0.29625\n",
      "Prompt 9 Test Accuracy: 0.14\n",
      "Prompt 10 Train Accuracy: 0.3475\n",
      "Prompt 10 Test Accuracy: 0.195\n",
      "(9984, 512)\n",
      "(9984, 512)\n",
      "1    800\n",
      "2    800\n",
      "4    800\n",
      "8    800\n",
      "0    799\n",
      "9    799\n",
      "5    798\n",
      "3    797\n",
      "6    796\n",
      "7    796\n",
      "Name: count, dtype: int64\n",
      "0    200\n",
      "1    200\n",
      "2    200\n",
      "3    200\n",
      "4    200\n",
      "5    200\n",
      "7    200\n",
      "8    200\n",
      "9    200\n",
      "6    199\n",
      "Name: count, dtype: int64\n",
      "Train Data Shape:  (7985, 512)\n",
      "Test Data Shape:  (1999, 512)\n",
      "Train Accuracy: 0.32047589229805884\n",
      "Test Accuracy: 0.1485742871435718\n",
      "Prompt 1 Train Accuracy: 0.2878598247809762\n",
      "Prompt 1 Test Accuracy: 0.14\n",
      "Prompt 2 Train Accuracy: 0.31\n",
      "Prompt 2 Test Accuracy: 0.145\n",
      "Prompt 3 Train Accuracy: 0.35875\n",
      "Prompt 3 Test Accuracy: 0.195\n",
      "Prompt 4 Train Accuracy: 0.2797992471769134\n",
      "Prompt 4 Test Accuracy: 0.115\n",
      "Prompt 5 Train Accuracy: 0.30125\n",
      "Prompt 5 Test Accuracy: 0.14\n",
      "Prompt 6 Train Accuracy: 0.3333333333333333\n",
      "Prompt 6 Test Accuracy: 0.125\n",
      "Prompt 7 Train Accuracy: 0.34673366834170855\n",
      "Prompt 7 Test Accuracy: 0.15577889447236182\n",
      "Prompt 8 Train Accuracy: 0.30025125628140703\n",
      "Prompt 8 Test Accuracy: 0.15\n",
      "Prompt 9 Train Accuracy: 0.3825\n",
      "Prompt 9 Test Accuracy: 0.175\n",
      "Prompt 10 Train Accuracy: 0.3041301627033792\n",
      "Prompt 10 Test Accuracy: 0.145\n",
      "(9835, 512)\n",
      "(9835, 512)\n",
      "9    796\n",
      "2    794\n",
      "8    794\n",
      "4    792\n",
      "0    790\n",
      "6    782\n",
      "5    780\n",
      "1    779\n",
      "7    779\n",
      "3    777\n",
      "Name: count, dtype: int64\n",
      "9    200\n",
      "2    199\n",
      "4    199\n",
      "8    199\n",
      "0    198\n",
      "5    196\n",
      "6    196\n",
      "1    195\n",
      "3    195\n",
      "7    195\n",
      "Name: count, dtype: int64\n",
      "Train Data Shape:  (7863, 512)\n",
      "Test Data Shape:  (1972, 512)\n",
      "Train Accuracy: 0.3171817372504133\n",
      "Test Accuracy: 0.15060851926977686\n",
      "Prompt 1 Train Accuracy: 0.2848101265822785\n",
      "Prompt 1 Test Accuracy: 0.17676767676767677\n",
      "Prompt 2 Train Accuracy: 0.25288831835686776\n",
      "Prompt 2 Test Accuracy: 0.13333333333333333\n",
      "Prompt 3 Train Accuracy: 0.36397984886649876\n",
      "Prompt 3 Test Accuracy: 0.1306532663316583\n",
      "Prompt 4 Train Accuracy: 0.3127413127413127\n",
      "Prompt 4 Test Accuracy: 0.18461538461538463\n",
      "Prompt 5 Train Accuracy: 0.31313131313131315\n",
      "Prompt 5 Test Accuracy: 0.12060301507537688\n",
      "Prompt 6 Train Accuracy: 0.3153846153846154\n",
      "Prompt 6 Test Accuracy: 0.12755102040816327\n",
      "Prompt 7 Train Accuracy: 0.3171355498721228\n",
      "Prompt 7 Test Accuracy: 0.11224489795918367\n",
      "Prompt 8 Train Accuracy: 0.2362002567394095\n",
      "Prompt 8 Test Accuracy: 0.11282051282051282\n",
      "Prompt 9 Train Accuracy: 0.4105793450881612\n",
      "Prompt 9 Test Accuracy: 0.25125628140703515\n",
      "Prompt 10 Train Accuracy: 0.36180904522613067\n",
      "Prompt 10 Test Accuracy: 0.155\n",
      "(9361, 512)\n",
      "(9361, 512)\n",
      "8    779\n",
      "2    777\n",
      "9    776\n",
      "4    764\n",
      "0    755\n",
      "6    732\n",
      "7    732\n",
      "5    728\n",
      "1    724\n",
      "3    718\n",
      "Name: count, dtype: int64\n",
      "2    195\n",
      "8    195\n",
      "9    195\n",
      "4    192\n",
      "0    189\n",
      "7    184\n",
      "6    183\n",
      "5    182\n",
      "1    181\n",
      "3    180\n",
      "Name: count, dtype: int64\n",
      "Train Data Shape:  (7485, 512)\n",
      "Test Data Shape:  (1876, 512)\n",
      "Train Accuracy: 0.321309285237141\n",
      "Test Accuracy: 0.15405117270788912\n",
      "Prompt 1 Train Accuracy: 0.304635761589404\n",
      "Prompt 1 Test Accuracy: 0.1111111111111111\n",
      "Prompt 2 Train Accuracy: 0.3411602209944751\n",
      "Prompt 2 Test Accuracy: 0.13812154696132597\n",
      "Prompt 3 Train Accuracy: 0.41827541827541825\n",
      "Prompt 3 Test Accuracy: 0.29743589743589743\n",
      "Prompt 4 Train Accuracy: 0.24512534818941503\n",
      "Prompt 4 Test Accuracy: 0.044444444444444446\n",
      "Prompt 5 Train Accuracy: 0.3102094240837696\n",
      "Prompt 5 Test Accuracy: 0.140625\n",
      "Prompt 6 Train Accuracy: 0.44368131868131866\n",
      "Prompt 6 Test Accuracy: 0.26373626373626374\n",
      "Prompt 7 Train Accuracy: 0.3224043715846995\n",
      "Prompt 7 Test Accuracy: 0.16393442622950818\n",
      "Prompt 8 Train Accuracy: 0.25956284153005466\n",
      "Prompt 8 Test Accuracy: 0.09782608695652174\n",
      "Prompt 9 Train Accuracy: 0.28369704749679076\n",
      "Prompt 9 Test Accuracy: 0.11282051282051282\n",
      "Prompt 10 Train Accuracy: 0.28350515463917525\n",
      "Prompt 10 Test Accuracy: 0.1641025641025641\n",
      "(8394, 512)\n",
      "(8394, 512)\n",
      "9    738\n",
      "2    720\n",
      "8    709\n",
      "4    692\n",
      "0    675\n",
      "7    652\n",
      "1    636\n",
      "6    635\n",
      "5    630\n",
      "3    624\n",
      "Name: count, dtype: int64\n",
      "9    185\n",
      "2    180\n",
      "8    178\n",
      "4    174\n",
      "0    169\n",
      "7    164\n",
      "1    160\n",
      "6    159\n",
      "5    158\n",
      "3    156\n",
      "Name: count, dtype: int64\n",
      "Train Data Shape:  (6711, 512)\n",
      "Test Data Shape:  (1683, 512)\n",
      "Train Accuracy: 0.32975711518402623\n",
      "Test Accuracy: 0.1437908496732026\n",
      "Prompt 1 Train Accuracy: 0.27111111111111114\n",
      "Prompt 1 Test Accuracy: 0.10650887573964497\n",
      "Prompt 2 Train Accuracy: 0.23113207547169812\n",
      "Prompt 2 Test Accuracy: 0.06875\n",
      "Prompt 3 Train Accuracy: 0.4625\n",
      "Prompt 3 Test Accuracy: 0.2833333333333333\n",
      "Prompt 4 Train Accuracy: 0.22916666666666666\n",
      "Prompt 4 Test Accuracy: 0.10897435897435898\n",
      "Prompt 5 Train Accuracy: 0.3208092485549133\n",
      "Prompt 5 Test Accuracy: 0.09770114942528736\n",
      "Prompt 6 Train Accuracy: 0.3619047619047619\n",
      "Prompt 6 Test Accuracy: 0.17721518987341772\n",
      "Prompt 7 Train Accuracy: 0.32125984251968503\n",
      "Prompt 7 Test Accuracy: 0.1069182389937107\n",
      "Prompt 8 Train Accuracy: 0.2776073619631902\n",
      "Prompt 8 Test Accuracy: 0.04878048780487805\n",
      "Prompt 9 Train Accuracy: 0.3328631875881523\n",
      "Prompt 9 Test Accuracy: 0.16853932584269662\n",
      "Prompt 10 Train Accuracy: 0.45528455284552843\n",
      "Prompt 10 Test Accuracy: 0.24324324324324326\n",
      "(6898, 512)\n",
      "(6898, 512)\n",
      "9    648\n",
      "8    624\n",
      "2    621\n",
      "4    581\n",
      "0    548\n",
      "7    522\n",
      "6    501\n",
      "1    495\n",
      "3    492\n",
      "5    483\n",
      "Name: count, dtype: int64\n",
      "9    162\n",
      "2    156\n",
      "8    156\n",
      "4    146\n",
      "0    138\n",
      "7    131\n",
      "6    126\n",
      "1    124\n",
      "3    123\n",
      "5    121\n",
      "Name: count, dtype: int64\n",
      "Train Data Shape:  (5515, 512)\n",
      "Test Data Shape:  (1383, 512)\n",
      "Train Accuracy: 0.3394378966455122\n",
      "Test Accuracy: 0.1547360809833695\n",
      "Prompt 1 Train Accuracy: 0.3175182481751825\n",
      "Prompt 1 Test Accuracy: 0.12318840579710146\n",
      "Prompt 2 Train Accuracy: 0.24848484848484848\n",
      "Prompt 2 Test Accuracy: 0.04838709677419355\n",
      "Prompt 3 Train Accuracy: 0.4975845410628019\n",
      "Prompt 3 Test Accuracy: 0.2948717948717949\n",
      "Prompt 4 Train Accuracy: 0.2073170731707317\n",
      "Prompt 4 Test Accuracy: 0.04065040650406504\n",
      "Prompt 5 Train Accuracy: 0.31497418244406195\n",
      "Prompt 5 Test Accuracy: 0.136986301369863\n",
      "Prompt 6 Train Accuracy: 0.2795031055900621\n",
      "Prompt 6 Test Accuracy: 0.09917355371900827\n",
      "Prompt 7 Train Accuracy: 0.3193612774451098\n",
      "Prompt 7 Test Accuracy: 0.12698412698412698\n",
      "Prompt 8 Train Accuracy: 0.36015325670498083\n",
      "Prompt 8 Test Accuracy: 0.17557251908396945\n",
      "Prompt 9 Train Accuracy: 0.34935897435897434\n",
      "Prompt 9 Test Accuracy: 0.20512820512820512\n",
      "Prompt 10 Train Accuracy: 0.43209876543209874\n",
      "Prompt 10 Test Accuracy: 0.22839506172839505\n",
      "(5137, 512)\n",
      "(5137, 512)\n",
      "9    508\n",
      "8    504\n",
      "2    500\n",
      "4    452\n",
      "0    408\n",
      "7    376\n",
      "6    347\n",
      "1    344\n",
      "5    336\n",
      "3    328\n",
      "Name: count, dtype: int64\n",
      "9    128\n",
      "8    127\n",
      "2    126\n",
      "4    114\n",
      "0    103\n",
      "7     95\n",
      "1     87\n",
      "6     87\n",
      "5     85\n",
      "3     82\n",
      "Name: count, dtype: int64\n",
      "Train Data Shape:  (4103, 512)\n",
      "Test Data Shape:  (1034, 512)\n",
      "Train Accuracy: 0.3614428466975384\n",
      "Test Accuracy: 0.1528046421663443\n",
      "Prompt 1 Train Accuracy: 0.27450980392156865\n",
      "Prompt 1 Test Accuracy: 0.13592233009708737\n",
      "Prompt 2 Train Accuracy: 0.3023255813953488\n",
      "Prompt 2 Test Accuracy: 0.06896551724137931\n",
      "Prompt 3 Train Accuracy: 0.394\n",
      "Prompt 3 Test Accuracy: 0.24603174603174602\n",
      "Prompt 4 Train Accuracy: 0.29573170731707316\n",
      "Prompt 4 Test Accuracy: 0.0975609756097561\n",
      "Prompt 5 Train Accuracy: 0.4469026548672566\n",
      "Prompt 5 Test Accuracy: 0.23684210526315788\n",
      "Prompt 6 Train Accuracy: 0.25892857142857145\n",
      "Prompt 6 Test Accuracy: 0.08235294117647059\n",
      "Prompt 7 Train Accuracy: 0.22478386167146974\n",
      "Prompt 7 Test Accuracy: 0.10344827586206896\n",
      "Prompt 8 Train Accuracy: 0.35638297872340424\n",
      "Prompt 8 Test Accuracy: 0.05263157894736842\n",
      "Prompt 9 Train Accuracy: 0.4107142857142857\n",
      "Prompt 9 Test Accuracy: 0.12598425196850394\n",
      "Prompt 10 Train Accuracy: 0.5216535433070866\n",
      "Prompt 10 Test Accuracy: 0.2734375\n",
      "(3342, 512)\n",
      "(3342, 512)\n",
      "9    370\n",
      "8    365\n",
      "2    343\n",
      "4    292\n",
      "0    256\n",
      "7    230\n",
      "6    217\n",
      "1    211\n",
      "5    206\n",
      "3    180\n",
      "Name: count, dtype: int64\n",
      "9    93\n",
      "8    92\n",
      "2    86\n",
      "4    73\n",
      "0    64\n",
      "7    58\n",
      "6    55\n",
      "1    53\n",
      "5    52\n",
      "3    46\n",
      "Name: count, dtype: int64\n",
      "Train Data Shape:  (2670, 512)\n",
      "Test Data Shape:  (672, 512)\n",
      "Train Accuracy: 0.3955056179775281\n",
      "Test Accuracy: 0.1636904761904762\n",
      "Prompt 1 Train Accuracy: 0.390625\n",
      "Prompt 1 Test Accuracy: 0.109375\n",
      "Prompt 2 Train Accuracy: 0.46445497630331756\n",
      "Prompt 2 Test Accuracy: 0.24528301886792453\n",
      "Prompt 3 Train Accuracy: 0.49271137026239065\n",
      "Prompt 3 Test Accuracy: 0.2441860465116279\n",
      "Prompt 4 Train Accuracy: 0.25555555555555554\n",
      "Prompt 4 Test Accuracy: 0.08695652173913043\n",
      "Prompt 5 Train Accuracy: 0.363013698630137\n",
      "Prompt 5 Test Accuracy: 0.1780821917808219\n",
      "Prompt 6 Train Accuracy: 0.19902912621359223\n",
      "Prompt 6 Test Accuracy: 0.1346153846153846\n",
      "Prompt 7 Train Accuracy: 0.271889400921659\n",
      "Prompt 7 Test Accuracy: 0.01818181818181818\n",
      "Prompt 8 Train Accuracy: 0.30434782608695654\n",
      "Prompt 8 Test Accuracy: 0.06896551724137931\n",
      "Prompt 9 Train Accuracy: 0.5095890410958904\n",
      "Prompt 9 Test Accuracy: 0.2826086956521739\n",
      "Prompt 10 Train Accuracy: 0.4891891891891892\n",
      "Prompt 10 Test Accuracy: 0.15053763440860216\n",
      "(1890, 512)\n",
      "(1890, 512)\n",
      "9    234\n",
      "8    224\n",
      "2    202\n",
      "4    175\n",
      "0    144\n",
      "7    114\n",
      "6    111\n",
      "1    109\n",
      "5    100\n",
      "3     95\n",
      "Name: count, dtype: int64\n",
      "9    59\n",
      "8    57\n",
      "2    51\n",
      "4    44\n",
      "0    36\n",
      "7    29\n",
      "1    28\n",
      "6    28\n",
      "5    26\n",
      "3    24\n",
      "Name: count, dtype: int64\n",
      "Train Data Shape:  (1508, 512)\n",
      "Test Data Shape:  (382, 512)\n",
      "Train Accuracy: 0.45557029177718833\n",
      "Test Accuracy: 0.17539267015706805\n",
      "Prompt 1 Train Accuracy: 0.4722222222222222\n",
      "Prompt 1 Test Accuracy: 0.1111111111111111\n",
      "Prompt 2 Train Accuracy: 0.3302752293577982\n",
      "Prompt 2 Test Accuracy: 0.07142857142857142\n",
      "Prompt 3 Train Accuracy: 0.48514851485148514\n",
      "Prompt 3 Test Accuracy: 0.1568627450980392\n",
      "Prompt 4 Train Accuracy: 0.21052631578947367\n",
      "Prompt 4 Test Accuracy: 0.041666666666666664\n",
      "Prompt 5 Train Accuracy: 0.4057142857142857\n",
      "Prompt 5 Test Accuracy: 0.1590909090909091\n",
      "Prompt 6 Train Accuracy: 0.39\n",
      "Prompt 6 Test Accuracy: 0.15384615384615385\n",
      "Prompt 7 Train Accuracy: 0.46846846846846846\n",
      "Prompt 7 Test Accuracy: 0.10714285714285714\n",
      "Prompt 8 Train Accuracy: 0.2807017543859649\n",
      "Prompt 8 Test Accuracy: 0.10344827586206896\n",
      "Prompt 9 Train Accuracy: 0.59375\n",
      "Prompt 9 Test Accuracy: 0.2982456140350877\n",
      "Prompt 10 Train Accuracy: 0.5897435897435898\n",
      "Prompt 10 Test Accuracy: 0.3050847457627119\n",
      "(985, 512)\n",
      "(985, 512)\n",
      "9    141\n",
      "8    124\n",
      "2    112\n",
      "4     96\n",
      "0     74\n",
      "7     58\n",
      "1     51\n",
      "6     46\n",
      "3     44\n",
      "5     40\n",
      "Name: count, dtype: int64\n",
      "9    36\n",
      "8    31\n",
      "2    28\n",
      "4    24\n",
      "0    19\n",
      "7    15\n",
      "1    13\n",
      "6    12\n",
      "3    11\n",
      "5    10\n",
      "Name: count, dtype: int64\n",
      "Train Data Shape:  (786, 512)\n",
      "Test Data Shape:  (199, 512)\n",
      "Train Accuracy: 0.5267175572519084\n",
      "Test Accuracy: 0.20603015075376885\n",
      "Prompt 1 Train Accuracy: 0.3783783783783784\n",
      "Prompt 1 Test Accuracy: 0.05263157894736842\n",
      "Prompt 2 Train Accuracy: 0.29411764705882354\n",
      "Prompt 2 Test Accuracy: 0.15384615384615385\n",
      "Prompt 3 Train Accuracy: 0.5625\n",
      "Prompt 3 Test Accuracy: 0.17857142857142858\n",
      "Prompt 4 Train Accuracy: 0.36363636363636365\n",
      "Prompt 4 Test Accuracy: 0.09090909090909091\n",
      "Prompt 5 Train Accuracy: 0.6458333333333334\n",
      "Prompt 5 Test Accuracy: 0.20833333333333334\n",
      "Prompt 6 Train Accuracy: 0.425\n",
      "Prompt 6 Test Accuracy: 0.0\n",
      "Prompt 7 Train Accuracy: 0.3695652173913043\n",
      "Prompt 7 Test Accuracy: 0.25\n",
      "Prompt 8 Train Accuracy: 0.4827586206896552\n",
      "Prompt 8 Test Accuracy: 0.2\n",
      "Prompt 9 Train Accuracy: 0.6048387096774194\n",
      "Prompt 9 Test Accuracy: 0.22580645161290322\n",
      "Prompt 10 Train Accuracy: 0.6595744680851063\n",
      "Prompt 10 Test Accuracy: 0.3888888888888889\n",
      "(474, 512)\n",
      "(474, 512)\n",
      "9    72\n",
      "8    61\n",
      "2    54\n",
      "0    37\n",
      "4    37\n",
      "7    29\n",
      "1    24\n",
      "3    23\n",
      "5    19\n",
      "6    18\n",
      "Name: count, dtype: int64\n",
      "9    19\n",
      "8    16\n",
      "2    14\n",
      "0    10\n",
      "4    10\n",
      "7     8\n",
      "1     7\n",
      "3     6\n",
      "5     5\n",
      "6     5\n",
      "Name: count, dtype: int64\n",
      "Train Data Shape:  (374, 512)\n",
      "Test Data Shape:  (100, 512)\n",
      "Train Accuracy: 0.5989304812834224\n",
      "Test Accuracy: 0.18\n",
      "Prompt 1 Train Accuracy: 0.2972972972972973\n",
      "Prompt 1 Test Accuracy: 0.1\n",
      "Prompt 2 Train Accuracy: 0.5\n",
      "Prompt 2 Test Accuracy: 0.0\n",
      "Prompt 3 Train Accuracy: 0.7037037037037037\n",
      "Prompt 3 Test Accuracy: 0.21428571428571427\n",
      "Prompt 4 Train Accuracy: 0.6086956521739131\n",
      "Prompt 4 Test Accuracy: 0.0\n",
      "Prompt 5 Train Accuracy: 0.43243243243243246\n",
      "Prompt 5 Test Accuracy: 0.0\n",
      "Prompt 6 Train Accuracy: 0.7368421052631579\n",
      "Prompt 6 Test Accuracy: 0.2\n",
      "Prompt 7 Train Accuracy: 0.4444444444444444\n",
      "Prompt 7 Test Accuracy: 0.0\n",
      "Prompt 8 Train Accuracy: 0.4827586206896552\n",
      "Prompt 8 Test Accuracy: 0.125\n",
      "Prompt 9 Train Accuracy: 0.7213114754098361\n",
      "Prompt 9 Test Accuracy: 0.3125\n",
      "Prompt 10 Train Accuracy: 0.7361111111111112\n",
      "Prompt 10 Test Accuracy: 0.3684210526315789\n",
      "(192, 512)\n",
      "(192, 512)\n",
      "8    33\n",
      "9    31\n",
      "2    20\n",
      "4    16\n",
      "0    11\n",
      "1    11\n",
      "7    10\n",
      "5     7\n",
      "3     6\n",
      "6     5\n",
      "Name: count, dtype: int64\n",
      "8    9\n",
      "9    8\n",
      "2    6\n",
      "4    4\n",
      "0    3\n",
      "1    3\n",
      "7    3\n",
      "3    2\n",
      "5    2\n",
      "6    2\n",
      "Name: count, dtype: int64\n",
      "Train Data Shape:  (150, 512)\n",
      "Test Data Shape:  (42, 512)\n",
      "Train Accuracy: 0.7266666666666667\n",
      "Test Accuracy: 0.11904761904761904\n",
      "Prompt 1 Train Accuracy: 0.5454545454545454\n",
      "Prompt 1 Test Accuracy: 0.0\n",
      "Prompt 2 Train Accuracy: 0.5454545454545454\n",
      "Prompt 2 Test Accuracy: 0.0\n",
      "Prompt 3 Train Accuracy: 0.8\n",
      "Prompt 3 Test Accuracy: 0.0\n",
      "Prompt 4 Train Accuracy: 0.6666666666666666\n",
      "Prompt 4 Test Accuracy: 0.0\n",
      "Prompt 5 Train Accuracy: 0.625\n",
      "Prompt 5 Test Accuracy: 0.25\n",
      "Prompt 6 Train Accuracy: 0.7142857142857143\n",
      "Prompt 6 Test Accuracy: 0.0\n",
      "Prompt 7 Train Accuracy: 0.6\n",
      "Prompt 7 Test Accuracy: 0.0\n",
      "Prompt 8 Train Accuracy: 0.7\n",
      "Prompt 8 Test Accuracy: 0.0\n",
      "Prompt 9 Train Accuracy: 0.8181818181818182\n",
      "Prompt 9 Test Accuracy: 0.2222222222222222\n",
      "Prompt 10 Train Accuracy: 0.8064516129032258\n",
      "Prompt 10 Test Accuracy: 0.25\n",
      "(73, 512)\n",
      "(73, 512)\n"
     ]
    }
   ],
   "source": [
    "# with open(\"results.csv\", \"w+\", newline='') as csvfile:\n",
    "#     csv_writer = csv.writer(csvfile, delimiter=',')\n",
    "#     header = ['Layer', 'Context_Level', 'Train_Accuracy', 'Test_Accuracy']\n",
    "#     prompt_headers = []\n",
    "#     for i in range(1, 11):\n",
    "#         prompt_headers.extend([f\"Prompt_{i}_Train_Accuracy\", f\"Prompt_{i}_Test_Accuracy\"])\n",
    "\n",
    "#     header.extend(prompt_headers)\n",
    "#     csv_writer.writerow(header)\n",
    "\n",
    "for context_level in context_levels:\n",
    "    cl_hs_array = hidden_states_by_cl[f\"cl_{context_level + 2}\"]\n",
    "    curr_label_set = curr_labels[f\"cl_{context_level + 2}\"]\n",
    "    # print(cl_hs_array[0].shape)\n",
    "    # print(cl_hs_array[-1].shape)\n",
    "    #1x512\n",
    "\n",
    "    print(np.array(cl_hs_array).shape)\n",
    "    for hs in range(len(cl_hs_array)):\n",
    "        cl_hs_array[hs] = cl_hs_array[hs].flatten()\n",
    "\n",
    "    curr_context_level_hs = np.array(cl_hs_array)\n",
    "    print(curr_context_level_hs.shape)\n",
    "\n",
    "    curr_label_set = np.array(curr_label_set)\n",
    "\n",
    "    unique_ids = sorted(set(curr_label_set))\n",
    "\n",
    "    if(len(unique_ids) < 10): break\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = build_dataset(curr_context_level_hs, curr_label_set)\n",
    "\n",
    "    #split into train and test and see how many samples of each class are in the test set (might explain 0.0 acc performance in test set).\n",
    "    # print(sorted(set(y_train)))\n",
    "    # print(sorted(set(y_test)))\n",
    "    print(pd.Series(y_train).value_counts())\n",
    "    print(pd.Series(y_test).value_counts())\n",
    "\n",
    "    print(\"Train Data Shape: \", X_train.shape)\n",
    "    print(\"Test Data Shape: \", X_test.shape)\n",
    "    \n",
    "    X_train = cp.array(X_train)\n",
    "    y_train = cp.array(y_train)\n",
    "    X_test = cp.array(X_test)\n",
    "    y_test = cp.array(y_test)\n",
    "\n",
    "    classifier = XGBClassifier(seed = 42, objective = 'multi:softmax', eval_metric = \"merror\", num_class = len(unique_ids), tree_method='hist', device='cuda')\n",
    "    classifier.fit(X_train, y_train)\n",
    "    preds_train = classifier.predict(X_train)\n",
    "    preds = classifier.predict(X_test)\n",
    "\n",
    "    train_accuracy = np.mean(cp.array(preds_train) == y_train)\n",
    "    accuracy = np.mean(cp.array(preds) == y_test)\n",
    "\n",
    "    print(f\"Train Accuracy: {train_accuracy}\")\n",
    "    print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "    prompt_accs = []\n",
    "\n",
    "    for i in range(10):\n",
    "        mask = y_test == i\n",
    "        prompt_test = y_test[mask]\n",
    "        prompt_preds = cp.array(preds)[mask]\n",
    "        prompt_test_acc = np.mean(prompt_preds == prompt_test)\n",
    "\n",
    "        mask_train = y_train == i\n",
    "        prompt_train = y_train[mask_train]\n",
    "        prompt_preds_train = cp.array(preds_train)[mask_train]\n",
    "        prompt_train_acc = np.mean(prompt_preds_train == prompt_train)\n",
    "\n",
    "        print(f\"Prompt {i + 1} Train Accuracy: {prompt_train_acc}\")\n",
    "        print(f\"Prompt {i + 1} Test Accuracy: {prompt_test_acc}\")\n",
    "\n",
    "        prompt_accs.append(prompt_train_acc)\n",
    "        prompt_accs.append(prompt_test_acc)\n",
    "\n",
    "    \n",
    "    # with open(\"results.csv\", \"a+\", newline='') as csvfile:\n",
    "    #     csv_writer = csv.writer(csvfile, delimiter=',')\n",
    "    #     values = [layer, context_level + 2, train_accuracy, accuracy]\n",
    "    #     values.extend(prompt_accs)\n",
    "    #     csv_writer.writerow(values)\n",
    "            \n",
    "\n",
    "\n",
    "    del classifier, X_train, y_train, X_test, y_test, preds\n",
    "\n",
    "    # XGBoost cleanup\n",
    "    try:\n",
    "        booster = classifier.get_booster()\n",
    "        del booster\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # CuPy cleanup\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    cp.get_default_pinned_memory_pool().free_all_blocks()\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b512fbc2-1245-494d-a256-2cc6781dd314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in curr_labels.keys():\n",
    "#     print(pd.Series(curr_labels[key]).value_counts())\n",
    "\n",
    "#     #split into train and test and see how many samples of each class are in the test set (might explain 0.0 acc performance in test set).\n",
    "#     X_train, y_train, X_test, y_test = build_dataset(curr_context_level_hs, curr_label_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a830ed2-048b-40ec-b461-0a3b0017b9de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
