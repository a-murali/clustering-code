{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd47861a-18bd-4ba7-a919-8fd60f3fdf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost.core import XGBoostError\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import plot_importance\n",
    "\n",
    "import shap\n",
    "\n",
    "import csv\n",
    "\n",
    "import cupy as cp\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aee32a8-c6c6-4dfd-b126-450061bf5781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.14\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57fcfaba-3152-4910-91c5-47161c30c4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "882df8f6-4418-4dfc-9e43-6e01f91f287c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.50.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27a7c2ad-e49d-452a-9462-3e7f397c391d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3dc4ed7-915b-4bc6-a3fa-9a2dfde996fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>story</th>\n",
       "      <th>hidden_state_file</th>\n",
       "      <th>len_generated_story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon. It was bi...</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon. He loved ...</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon named Sam....</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon. He was a ...</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon. The drago...</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prompt_id                                 prompt  \\\n",
       "0             1    Once upon a time there was a dragon   \n",
       "1             1    Once upon a time there was a dragon   \n",
       "2             1    Once upon a time there was a dragon   \n",
       "3             1    Once upon a time there was a dragon   \n",
       "4             1    Once upon a time there was a dragon   \n",
       "...         ...                                    ...   \n",
       "9995         10  Once upon a time there was a poor boy   \n",
       "9996         10  Once upon a time there was a poor boy   \n",
       "9997         10  Once upon a time there was a poor boy   \n",
       "9998         10  Once upon a time there was a poor boy   \n",
       "9999         10  Once upon a time there was a poor boy   \n",
       "\n",
       "                                                  story  \\\n",
       "0     Once upon a time there was a dragon. It was bi...   \n",
       "1     Once upon a time there was a dragon. He loved ...   \n",
       "2     Once upon a time there was a dragon named Sam....   \n",
       "3     Once upon a time there was a dragon. He was a ...   \n",
       "4     Once upon a time there was a dragon. The drago...   \n",
       "...                                                 ...   \n",
       "9995  Once upon a time there was a poor boy named Ti...   \n",
       "9996  Once upon a time there was a poor boy named Ti...   \n",
       "9997  Once upon a time there was a poor boy named Ti...   \n",
       "9998  Once upon a time there was a poor boy named Ti...   \n",
       "9999  Once upon a time there was a poor boy named Ti...   \n",
       "\n",
       "                  hidden_state_file  len_generated_story  \n",
       "0      ./hidden_states/prompt_1.npz                  273  \n",
       "1      ./hidden_states/prompt_1.npz                  246  \n",
       "2      ./hidden_states/prompt_1.npz                  397  \n",
       "3      ./hidden_states/prompt_1.npz                  294  \n",
       "4      ./hidden_states/prompt_1.npz                  296  \n",
       "...                             ...                  ...  \n",
       "9995  ./hidden_states/prompt_10.npz                  315  \n",
       "9996  ./hidden_states/prompt_10.npz                  270  \n",
       "9997  ./hidden_states/prompt_10.npz                  206  \n",
       "9998  ./hidden_states/prompt_10.npz                  375  \n",
       "9999  ./hidden_states/prompt_10.npz                  341  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../story_dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "438a8c08-d97b-4b5f-ab67-0b1d9bae5929",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states_by_cl = {}\n",
    "curr_labels = {}\n",
    "NUM_PROMPTS = 10\n",
    "layer = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b42ff054-3d1a-4951-a4d3-f861bf5118e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len = max(df[:NUM_PROMPTS*1000][\"len_generated_story\"])\n",
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a6254a0-6b3f-4d49-9c7e-f077304f93c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>story</th>\n",
       "      <th>hidden_state_file</th>\n",
       "      <th>len_generated_story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9851</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prompt_id                                 prompt  \\\n",
       "9851         10  Once upon a time there was a poor boy   \n",
       "\n",
       "                                                  story  \\\n",
       "9851  Once upon a time there was a poor boy named Ti...   \n",
       "\n",
       "                  hidden_state_file  len_generated_story  \n",
       "9851  ./hidden_states/prompt_10.npz                  522  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"len_generated_story\"] >= max_story_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4719bff7-21c6-4b65-ac6e-bf099f3aef0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_story_len = min(df[\"len_generated_story\"])\n",
    "min_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7fe0a33-60a1-4f8a-879c-1ab8f95553bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_levels = [0] #get hs used to generate second token\n",
    "context_levels.extend([i for i in range(23, max_story_len, 25)]) #actual context level is context_level + 2 (gather hs to generate the context_level + 2 token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3765f70a-505d-4eb8-b9d7-0a2a019492f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:22<00:00, 43.90it/s]\n",
      " 44%|██████████████████████████████████▉                                             | 436/1000 [00:09<00:12, 45.02it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m np.load(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m../../../llamatales-xgboost-ii/hidden_states/prompt_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.npz\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m loaded_data:\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[32m1000\u001b[39m)):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m         hs = \u001b[43mloaded_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43marr_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# load once\u001b[39;00m\n\u001b[32m     10\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m context_level \u001b[38;5;129;01min\u001b[39;00m context_levels:\n\u001b[32m     11\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m context_level >= hs.shape[\u001b[32m0\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_npyio_impl.py:257\u001b[39m, in \u001b[36mNpzFile.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28mbytes\u001b[39m.seek(\u001b[32m0\u001b[39m)\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m magic == \u001b[38;5;28mformat\u001b[39m.MAGIC_PREFIX:\n\u001b[32m    249\u001b[39m     \u001b[38;5;66;03m# FIXME: This seems like it will copy strings around\u001b[39;00m\n\u001b[32m    250\u001b[39m     \u001b[38;5;66;03m#   more than is strictly necessary.  The zipfile\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    255\u001b[39m     \u001b[38;5;66;03m#   (or at least uncompress) the data\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;66;03m#   directly into the array memory.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_header_size\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    264\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_format_impl.py:869\u001b[39m, in \u001b[36mread_array\u001b[39m\u001b[34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[39m\n\u001b[32m    867\u001b[39m             read_count = \u001b[38;5;28mmin\u001b[39m(max_read_count, count - i)\n\u001b[32m    868\u001b[39m             read_size = \u001b[38;5;28mint\u001b[39m(read_count * dtype.itemsize)\n\u001b[32m--> \u001b[39m\u001b[32m869\u001b[39m             data = \u001b[43m_read_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43marray data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    870\u001b[39m             array[i:i + read_count] = numpy.frombuffer(data, dtype=dtype,\n\u001b[32m    871\u001b[39m                                                      count=read_count)\n\u001b[32m    873\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m array.size != count:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_format_impl.py:1013\u001b[39m, in \u001b[36m_read_bytes\u001b[39m\u001b[34m(fp, size, error_template)\u001b[39m\n\u001b[32m   1008\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m   1009\u001b[39m     \u001b[38;5;66;03m# io files (default in python3) return None or raise on\u001b[39;00m\n\u001b[32m   1010\u001b[39m     \u001b[38;5;66;03m# would-block, python2 file will truncate, probably nothing can be\u001b[39;00m\n\u001b[32m   1011\u001b[39m     \u001b[38;5;66;03m# done about that.  note that regular files can't be non-blocking\u001b[39;00m\n\u001b[32m   1012\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1013\u001b[39m         r = \u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m         data += r\n\u001b[32m   1015\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(r) == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) == size:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/zipfile.py:982\u001b[39m, in \u001b[36mZipExtFile.read\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m    980\u001b[39m \u001b[38;5;28mself\u001b[39m._offset = \u001b[32m0\u001b[39m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m n > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._eof:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    983\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n < \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[32m    984\u001b[39m         \u001b[38;5;28mself\u001b[39m._readbuffer = data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/zipfile.py:1058\u001b[39m, in \u001b[36mZipExtFile._read1\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compress_type == ZIP_DEFLATED:\n\u001b[32m   1057\u001b[39m     n = \u001b[38;5;28mmax\u001b[39m(n, \u001b[38;5;28mself\u001b[39m.MIN_READ_SIZE)\n\u001b[32m-> \u001b[39m\u001b[32m1058\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decompressor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1059\u001b[39m     \u001b[38;5;28mself\u001b[39m._eof = (\u001b[38;5;28mself\u001b[39m._decompressor.eof \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1060\u001b[39m                  \u001b[38;5;28mself\u001b[39m._compress_left <= \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m   1061\u001b[39m                  \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decompressor.unconsumed_tail)\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._eof:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "hidden_states_by_cl = {f\"cl_{cl+2}\": [] for cl in context_levels}\n",
    "curr_labels = {f\"cl_{cl+2}\": [] for cl in context_levels}\n",
    "\n",
    "for prompt_id in range(1, NUM_PROMPTS + 1):\n",
    "    with np.load(f'../../../llamatales-xgboost-ii/hidden_states/prompt_{prompt_id}.npz') as loaded_data:\n",
    "\n",
    "        for i in tqdm(range(1000)):\n",
    "            hs = loaded_data[f\"arr_{i}\"]  # load once\n",
    "\n",
    "            for context_level in context_levels:\n",
    "                if context_level >= hs.shape[0]:\n",
    "                    continue\n",
    "\n",
    "                key = f\"cl_{context_level + 2}\"\n",
    "\n",
    "                hidden_states_by_cl[key].append(\n",
    "                    hs[context_level][layer][0].astype(\"float32\")\n",
    "                )\n",
    "                curr_labels[key].append(prompt_id - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1146b9-779e-449c-997e-4017ea03d77c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def safe_split(total, train_ratio=0.8):\n",
    "    train = int(train_ratio * total)   # floor\n",
    "    test  = total - train              # leftover\n",
    "    return train, test\n",
    "\n",
    "def build_dataset(curr_context_level_hs, curr_labels, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Groups samples by prompt_id, splits safely into train/test,\n",
    "    and returns X_train, y_train, X_test, y_test.\n",
    "    \"\"\"\n",
    "\n",
    "    unique_ids = sorted(set(curr_labels))\n",
    "\n",
    "    X_train_list = []\n",
    "    X_test_list = []\n",
    "    y_train_list = []\n",
    "    y_test_list = []\n",
    "\n",
    "    for pid in unique_ids:\n",
    "\n",
    "        # get samples for this prompt id\n",
    "        mask = (curr_labels == pid)\n",
    "        X_pid = curr_context_level_hs[mask]\n",
    "        y_pid = curr_labels[mask]\n",
    "\n",
    "        total = len(X_pid)\n",
    "        train_n, test_n = safe_split(total, train_ratio)\n",
    "\n",
    "        # split\n",
    "        X_train_list.append(X_pid[:train_n])\n",
    "        y_train_list.append(y_pid[:train_n])\n",
    "\n",
    "        X_test_list.append(X_pid[train_n:])\n",
    "        y_test_list.append(y_pid[train_n:])\n",
    "\n",
    "    # concatenate all prompt-id blocks\n",
    "    X_train = np.concatenate(X_train_list, axis=0)\n",
    "    y_train = np.concatenate(y_train_list, axis=0)\n",
    "    X_test  = np.concatenate(X_test_list, axis=0)\n",
    "    y_test  = np.concatenate(y_test_list, axis=0)\n",
    "\n",
    "    # return cp.array(X_train), cp.array(y_train), cp.array(X_test), cp.array(y_test)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1912b03-779e-49c8-bacf-527f24bbca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(hidden_states_by_cl[f\"cl_2\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be63d0a5-32d7-474e-aefc-ea4fea59f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(curr_labels[f\"cl_2\"]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6bd7be-c454-4c38-81c4-22d78a28efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results-shap_values.csv\", \"w+\", newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile, delimiter=',')\n",
    "        header = ['Layer', 'Context_Level', 'Most_Important_Test_Feature']\n",
    "        prompt_headers = []\n",
    "        for i in range(1, 11):\n",
    "            prompt_headers.extend([f\"Prompt_{i}_Most_Important_Test_Feature\"])\n",
    "    \n",
    "        header.extend(prompt_headers)\n",
    "        csv_writer.writerow(header)\n",
    "for context_level in context_levels[1:]:\n",
    "    print(f\"Optimizing Layer {layer} at Context Level {context_level + 2}\")\n",
    "    cl_hs_array = hidden_states_by_cl[f\"cl_{context_level + 2}\"]\n",
    "    curr_label_set = curr_labels[f\"cl_{context_level + 2}\"]\n",
    "    # print(cl_hs_array[0].shape)\n",
    "    # print(cl_hs_array[-1].shape)\n",
    "    #1x512\n",
    "\n",
    "    print(np.array(cl_hs_array).shape)\n",
    "    for hs in range(len(cl_hs_array)):\n",
    "        cl_hs_array[hs] = cl_hs_array[hs].flatten()\n",
    "\n",
    "    curr_context_level_hs = np.array(cl_hs_array)\n",
    "    print(curr_context_level_hs.shape)\n",
    "\n",
    "    curr_label_set = np.array(curr_label_set)\n",
    "\n",
    "    unique_ids = sorted(set(curr_label_set))\n",
    "\n",
    "    if(len(unique_ids) < 10): break\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = build_dataset(curr_context_level_hs, curr_label_set)\n",
    "\n",
    "    X_train_opt, X_valid, y_train_opt, y_valid = train_test_split(X_train, y_train, test_size = 0.2, random_state=42)\n",
    "\n",
    "    #split into train and test and see how many samples of each class are in the test set (might explain 0.0 acc performance in test set).\n",
    "    print(pd.Series(y_train).value_counts())\n",
    "    print(pd.Series(y_test).value_counts())\n",
    "    print(pd.Series(y_train_opt).value_counts())\n",
    "    print(pd.Series(y_valid).value_counts())\n",
    "\n",
    "    print(\"Train Data Shape: \", X_train.shape)\n",
    "    print(\"Test Data Shape: \", X_test.shape)\n",
    "    print(\"Optimizer Train Data Shape: \", X_train_opt.shape)\n",
    "\n",
    "    X_train = cp.array(X_train)\n",
    "    y_train = cp.array(y_train)\n",
    "    X_test = cp.array(X_test)\n",
    "    y_test = cp.array(y_test)\n",
    "\n",
    "    X_train_opt = cp.array(X_train_opt)\n",
    "    y_train_opt = cp.array(y_train_opt)\n",
    "    X_valid = cp.array(X_valid)\n",
    "    y_valid = cp.array(y_valid)\n",
    "\n",
    "    #Test 1\n",
    "    # classifier = XGBClassifier(max_depth = 3, \n",
    "    #                            reg_alpha = 10, \n",
    "    #                            reg_lambda = 10, \n",
    "    #                            gamma = 10, \n",
    "    #                            subsample = 0.75,\n",
    "    #                            colsample_bytree = 0.75,\n",
    "    #                            eta = 0.01,\n",
    "    #                            n_estimators = 500,\n",
    "    #                            # min_child_weight = 20,\n",
    "    #                            seed = 42, objective = 'multi:softmax', eval_metric = \"merror\", num_class = len(unique_ids), tree_method='hist', device='cuda')\n",
    "\n",
    "    #Test 2\n",
    "    # classifier = XGBClassifier(max_depth = 6, \n",
    "    #                            reg_alpha = 10, \n",
    "    #                            reg_lambda = 10, \n",
    "    #                            gamma = 10, \n",
    "    #                            subsample = 0.75,\n",
    "    #                            colsample_bytree = 0.75,\n",
    "    #                            eta = 0.01,\n",
    "    #                            n_estimators = 500,\n",
    "    #                            min_child_weight = 20,\n",
    "    #                            seed = 42, objective = 'multi:softmax', eval_metric = \"merror\", num_class = len(unique_ids), tree_method='hist', device='cuda')\n",
    "\n",
    "    classifier = XGBClassifier(seed = 42, objective = 'multi:softmax', eval_metric = \"merror\", num_class = len(unique_ids), tree_method='hist', device='cuda')\n",
    "    \n",
    "    \n",
    "    classifier.fit(X_train, y_train)\n",
    "    # preds_train = classifier.predict(X_train)\n",
    "    # preds = classifier.predict(X_test)\n",
    "    preds_train = np.argmax(classifier.predict_proba(X_train), axis=1)\n",
    "    preds = np.argmax(classifier.predict_proba(X_test), axis=1)\n",
    "\n",
    "    plot_importance(classifier, max_num_features=20, importance_type='gain')\n",
    "    plt.show()\n",
    "\n",
    "    # plot_importance(classifier, max_num_features=20, importance_type='cover')\n",
    "    # plt.show()\n",
    "\n",
    "    # plot_importance(classifier, max_num_features=20, importance_type='weight')\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    used_features = classifier.get_booster().get_score().keys()\n",
    "    print(\"# of Used Features\", len(used_features))\n",
    "\n",
    "\n",
    "    explainer = shap.TreeExplainer(classifier)\n",
    "    shap_values = explainer(cp.asnumpy(X_test))\n",
    "\n",
    "    prompt_feats = []\n",
    "    for i in range(shap_values.values.shape[2]):\n",
    "        print(f\"Class {i}\")\n",
    "        shap.summary_plot(shap_values[:, :, i], cp.asnumpy(X_test))\n",
    "        shap.plots.bar(shap_values[:, :, i])\n",
    "\n",
    "        # mean_abs_shap = np.abs(shap_values[:, :, i]).mean(axis=0)\n",
    "        # most_important_idx = mean_abs_shap.argmax()\n",
    "        # most_important_feature = X.columns[most_important_idx]\n",
    "\n",
    "        most_important_prompt_feature = np.argsort(-np.abs(shap_values.values[:, :, i]).mean(axis = 0))[0]\n",
    "\n",
    "        print(f\"Most Important Feature for Prompt {i}: \", most_important_prompt_feature)\n",
    "        prompt_feats.append(most_important_prompt_feature)\n",
    "\n",
    "    #Overall\n",
    "    # mean_abs_shap = np.abs(shap_values).mean(axis=(0, 2))\n",
    "    # most_important_idx = mean_abs_shap.argmax()\n",
    "    # most_important_feature = X.columns[most_important_idx]\n",
    "\n",
    "    most_important_overall_feature = np.argsort(-np.abs(shap_values.values).mean(axis=(0, 2)))[0]\n",
    "\n",
    "    print(f\"Most Important Overall Feature: \", most_important_overall_feature)\n",
    "\n",
    "    train_accuracy = np.mean(cp.array(preds_train) == y_train)\n",
    "    accuracy = np.mean(cp.array(preds) == y_test)\n",
    "\n",
    "    print(f\"Train Accuracy: {train_accuracy}\")\n",
    "    print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "    # prompt_accs = []\n",
    "\n",
    "    for i in range(10):\n",
    "        mask = y_test == i\n",
    "        prompt_test = y_test[mask]\n",
    "        prompt_preds = cp.array(preds)[mask]\n",
    "        prompt_test_acc = np.mean(prompt_preds == prompt_test)\n",
    "\n",
    "        mask_train = y_train == i\n",
    "        prompt_train = y_train[mask_train]\n",
    "        prompt_preds_train = cp.array(preds_train)[mask_train]\n",
    "        prompt_train_acc = np.mean(prompt_preds_train == prompt_train)\n",
    "\n",
    "        print(f\"Prompt {i + 1} Train Accuracy: {prompt_train_acc}\")\n",
    "        print(f\"Prompt {i + 1} Test Accuracy: {prompt_test_acc}\")\n",
    "\n",
    "        # prompt_accs.append(prompt_train_acc)\n",
    "        # prompt_accs.append(prompt_test_acc)\n",
    "\n",
    "    with open(\"results-shap_values.csv\", \"a+\", newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile, delimiter=',')\n",
    "            values = [layer, context_level + 2, most_important_overall_feature]\n",
    "            values.extend(prompt_feats)\n",
    "            csv_writer.writerow(values)\n",
    "            \n",
    "\n",
    "\n",
    "    del classifier, X_train, y_train, X_test, y_test, preds\n",
    "\n",
    "    # XGBoost cleanup\n",
    "    try:\n",
    "        booster = classifier.get_booster()\n",
    "        del booster\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # CuPy cleanup\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    cp.get_default_pinned_memory_pool().free_all_blocks()\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26164269-f1ef-4d81-9330-6b8f161eb466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.argsort(-np.abs(shap_values.values[:, :, i]).mean(axis = 0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e64228b-60eb-4ade-9f89-7812fb10eaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.argsort(-np.abs(shap_values.values).mean(axis=(0, 2)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8312619-83d2-42b7-b830-e04e6ee202d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b80b420-ee05-49f3-b7cc-be63d751646c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap_values.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4ecca8-e6d2-4ab1-b96e-b58ac3a7e6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values.base_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454e0604-4486-40e8-9606-402f16b2392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761440e8-324e-482b-9539-50e9deb22d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(shap_values.values.shape[2]):\n",
    "#     print(f\"Class {i}\")\n",
    "#     shap.summary_plot(shap_values[:, :, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7482476c-d28b-46d6-8d85-88d8642695be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_idx = 0  # choose class\n",
    "\n",
    "# shap.plots.beeswarm(shap_values[:, :, class_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e94b49-9414-4eb3-930e-b7a009036a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.summary_plot(\n",
    "#     shap_values.values[:, :, class_idx],\n",
    "#     cp.asnumpy(X_test)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f182c08-3b5a-4430-b269-382a77532c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(shap_values.values.shape[2]):\n",
    "#     print(f\"Class {i}\")\n",
    "#     shap.plots.beeswarm(shap_values[:, :, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752039b9-a9c0-4c1d-ba4a-f472d7700430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_importance = np.mean(np.abs(shap_values), axis=(0,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
