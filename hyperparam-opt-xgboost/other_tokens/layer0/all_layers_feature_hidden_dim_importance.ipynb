{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd47861a-18bd-4ba7-a919-8fd60f3fdf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost.core import XGBoostError\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import plot_importance\n",
    "\n",
    "import shap\n",
    "\n",
    "import csv\n",
    "\n",
    "import cupy as cp\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aee32a8-c6c6-4dfd-b126-450061bf5781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.14\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57fcfaba-3152-4910-91c5-47161c30c4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "882df8f6-4418-4dfc-9e43-6e01f91f287c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.50.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27a7c2ad-e49d-452a-9462-3e7f397c391d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3dc4ed7-915b-4bc6-a3fa-9a2dfde996fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>story</th>\n",
       "      <th>hidden_state_file</th>\n",
       "      <th>len_generated_story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon. It was bi...</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon. He loved ...</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon named Sam....</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon. He was a ...</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon. The drago...</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prompt_id                                 prompt  \\\n",
       "0             1    Once upon a time there was a dragon   \n",
       "1             1    Once upon a time there was a dragon   \n",
       "2             1    Once upon a time there was a dragon   \n",
       "3             1    Once upon a time there was a dragon   \n",
       "4             1    Once upon a time there was a dragon   \n",
       "...         ...                                    ...   \n",
       "9995         10  Once upon a time there was a poor boy   \n",
       "9996         10  Once upon a time there was a poor boy   \n",
       "9997         10  Once upon a time there was a poor boy   \n",
       "9998         10  Once upon a time there was a poor boy   \n",
       "9999         10  Once upon a time there was a poor boy   \n",
       "\n",
       "                                                  story  \\\n",
       "0     Once upon a time there was a dragon. It was bi...   \n",
       "1     Once upon a time there was a dragon. He loved ...   \n",
       "2     Once upon a time there was a dragon named Sam....   \n",
       "3     Once upon a time there was a dragon. He was a ...   \n",
       "4     Once upon a time there was a dragon. The drago...   \n",
       "...                                                 ...   \n",
       "9995  Once upon a time there was a poor boy named Ti...   \n",
       "9996  Once upon a time there was a poor boy named Ti...   \n",
       "9997  Once upon a time there was a poor boy named Ti...   \n",
       "9998  Once upon a time there was a poor boy named Ti...   \n",
       "9999  Once upon a time there was a poor boy named Ti...   \n",
       "\n",
       "                  hidden_state_file  len_generated_story  \n",
       "0      ./hidden_states/prompt_1.npz                  273  \n",
       "1      ./hidden_states/prompt_1.npz                  246  \n",
       "2      ./hidden_states/prompt_1.npz                  397  \n",
       "3      ./hidden_states/prompt_1.npz                  294  \n",
       "4      ./hidden_states/prompt_1.npz                  296  \n",
       "...                             ...                  ...  \n",
       "9995  ./hidden_states/prompt_10.npz                  315  \n",
       "9996  ./hidden_states/prompt_10.npz                  270  \n",
       "9997  ./hidden_states/prompt_10.npz                  206  \n",
       "9998  ./hidden_states/prompt_10.npz                  375  \n",
       "9999  ./hidden_states/prompt_10.npz                  341  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../story_dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "438a8c08-d97b-4b5f-ab67-0b1d9bae5929",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states_by_cl = {}\n",
    "curr_labels = {}\n",
    "NUM_PROMPTS = 10\n",
    "layers = [i for i in range(9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b42ff054-3d1a-4951-a4d3-f861bf5118e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len = max(df[:NUM_PROMPTS*1000][\"len_generated_story\"])\n",
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a6254a0-6b3f-4d49-9c7e-f077304f93c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>story</th>\n",
       "      <th>hidden_state_file</th>\n",
       "      <th>len_generated_story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9851</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prompt_id                                 prompt  \\\n",
       "9851         10  Once upon a time there was a poor boy   \n",
       "\n",
       "                                                  story  \\\n",
       "9851  Once upon a time there was a poor boy named Ti...   \n",
       "\n",
       "                  hidden_state_file  len_generated_story  \n",
       "9851  ./hidden_states/prompt_10.npz                  522  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"len_generated_story\"] >= max_story_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4719bff7-21c6-4b65-ac6e-bf099f3aef0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_story_len = min(df[\"len_generated_story\"])\n",
    "min_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7fe0a33-60a1-4f8a-879c-1ab8f95553bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_levels = [0] #get hs used to generate second token\n",
    "context_levels.extend([i for i in range(23, max_story_len, 25)]) #actual context level is context_level + 2 (gather hs to generate the context_level + 2 token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad1146b9-779e-449c-997e-4017ea03d77c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def safe_split(total, train_ratio=0.8):\n",
    "    train = int(train_ratio * total)   # floor\n",
    "    test  = total - train              # leftover\n",
    "    return train, test\n",
    "\n",
    "def build_dataset(curr_context_level_hs, curr_labels, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Groups samples by prompt_id, splits safely into train/test,\n",
    "    and returns X_train, y_train, X_test, y_test.\n",
    "    \"\"\"\n",
    "\n",
    "    unique_ids = sorted(set(curr_labels))\n",
    "\n",
    "    X_train_list = []\n",
    "    X_test_list = []\n",
    "    y_train_list = []\n",
    "    y_test_list = []\n",
    "\n",
    "    for pid in unique_ids:\n",
    "\n",
    "        # get samples for this prompt id\n",
    "        mask = (curr_labels == pid)\n",
    "        X_pid = curr_context_level_hs[mask]\n",
    "        y_pid = curr_labels[mask]\n",
    "\n",
    "        total = len(X_pid)\n",
    "        train_n, test_n = safe_split(total, train_ratio)\n",
    "\n",
    "        # split\n",
    "        X_train_list.append(X_pid[:train_n])\n",
    "        y_train_list.append(y_pid[:train_n])\n",
    "\n",
    "        X_test_list.append(X_pid[train_n:])\n",
    "        y_test_list.append(y_pid[train_n:])\n",
    "\n",
    "    # concatenate all prompt-id blocks\n",
    "    X_train = np.concatenate(X_train_list, axis=0)\n",
    "    y_train = np.concatenate(y_train_list, axis=0)\n",
    "    X_test  = np.concatenate(X_test_list, axis=0)\n",
    "    y_test  = np.concatenate(y_test_list, axis=0)\n",
    "\n",
    "    # return cp.array(X_train), cp.array(y_train), cp.array(X_test), cp.array(y_test)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac6bd7be-c454-4c38-81c4-22d78a28efd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 9 is out of bounds for axis 0 with size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     24\u001b[39m                     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     26\u001b[39m                 key = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcl_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext_level\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m2\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     28\u001b[39m                 hidden_states_by_cl[key].append(\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m                     \u001b[43mhs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcontext_level\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m[\u001b[32m0\u001b[39m].astype(\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m                 )\n\u001b[32m     31\u001b[39m                 curr_labels[key].append(prompt_id - \u001b[32m1\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m context_level \u001b[38;5;129;01min\u001b[39;00m context_levels[\u001b[32m1\u001b[39m:]:\n",
      "\u001b[31mIndexError\u001b[39m: index 9 is out of bounds for axis 0 with size 9"
     ]
    }
   ],
   "source": [
    "# with open(\"results-shap_values.csv\", \"w+\", newline='') as csvfile:\n",
    "#         csv_writer = csv.writer(csvfile, delimiter=',')\n",
    "#         header = ['Layer', 'Context_Level', 'Most_Important_Test_Feature']\n",
    "#         prompt_headers = []\n",
    "#         for i in range(1, 11):\n",
    "#             prompt_headers.extend([f\"Prompt_{i}_Most_Important_Test_Feature\"])\n",
    "    \n",
    "#         header.extend(prompt_headers)\n",
    "#         csv_writer.writerow(header)\n",
    "\n",
    "for layer in layers:\n",
    "\n",
    "    hidden_states_by_cl = {f\"cl_{cl+2}\": [] for cl in context_levels}\n",
    "    curr_labels = {f\"cl_{cl+2}\": [] for cl in context_levels}\n",
    "    \n",
    "    for prompt_id in range(1, NUM_PROMPTS + 1):\n",
    "        with np.load(f'../../../llamatales-xgboost-ii/hidden_states/prompt_{prompt_id}.npz') as loaded_data:\n",
    "    \n",
    "            for i in tqdm(range(1000)):\n",
    "                hs = loaded_data[f\"arr_{i}\"]  # load once\n",
    "    \n",
    "                for context_level in context_levels:\n",
    "                    if context_level >= hs.shape[0]:\n",
    "                        continue\n",
    "    \n",
    "                    key = f\"cl_{context_level + 2}\"\n",
    "    \n",
    "                    hidden_states_by_cl[key].append(\n",
    "                        hs[context_level][layer][0].astype(\"float32\")\n",
    "                    )\n",
    "                    curr_labels[key].append(prompt_id - 1)\n",
    "\n",
    "\n",
    "    for context_level in context_levels[1:]:\n",
    "        print(f\"Optimizing Layer {layer} at Context Level {context_level + 2}\")\n",
    "        cl_hs_array = hidden_states_by_cl[f\"cl_{context_level + 2}\"]\n",
    "        curr_label_set = curr_labels[f\"cl_{context_level + 2}\"]\n",
    "        # print(cl_hs_array[0].shape)\n",
    "        # print(cl_hs_array[-1].shape)\n",
    "        #1x512\n",
    "    \n",
    "        print(np.array(cl_hs_array).shape)\n",
    "        for hs in range(len(cl_hs_array)):\n",
    "            cl_hs_array[hs] = cl_hs_array[hs].flatten()\n",
    "    \n",
    "        curr_context_level_hs = np.array(cl_hs_array)\n",
    "        print(curr_context_level_hs.shape)\n",
    "    \n",
    "        curr_label_set = np.array(curr_label_set)\n",
    "    \n",
    "        unique_ids = sorted(set(curr_label_set))\n",
    "    \n",
    "        if(len(unique_ids) < 10): break\n",
    "        \n",
    "        X_train, y_train, X_test, y_test = build_dataset(curr_context_level_hs, curr_label_set)\n",
    "    \n",
    "        X_train_opt, X_valid, y_train_opt, y_valid = train_test_split(X_train, y_train, test_size = 0.2, random_state=42)\n",
    "    \n",
    "        #split into train and test and see how many samples of each class are in the test set (might explain 0.0 acc performance in test set).\n",
    "        print(pd.Series(y_train).value_counts())\n",
    "        print(pd.Series(y_test).value_counts())\n",
    "        print(pd.Series(y_train_opt).value_counts())\n",
    "        print(pd.Series(y_valid).value_counts())\n",
    "    \n",
    "        print(\"Train Data Shape: \", X_train.shape)\n",
    "        print(\"Test Data Shape: \", X_test.shape)\n",
    "        print(\"Optimizer Train Data Shape: \", X_train_opt.shape)\n",
    "    \n",
    "        X_train = cp.array(X_train)\n",
    "        y_train = cp.array(y_train)\n",
    "        X_test = cp.array(X_test)\n",
    "        y_test = cp.array(y_test)\n",
    "    \n",
    "        X_train_opt = cp.array(X_train_opt)\n",
    "        y_train_opt = cp.array(y_train_opt)\n",
    "        X_valid = cp.array(X_valid)\n",
    "        y_valid = cp.array(y_valid)\n",
    "    \n",
    "        #Test 1\n",
    "        # classifier = XGBClassifier(max_depth = 3, \n",
    "        #                            reg_alpha = 10, \n",
    "        #                            reg_lambda = 10, \n",
    "        #                            gamma = 10, \n",
    "        #                            subsample = 0.75,\n",
    "        #                            colsample_bytree = 0.75,\n",
    "        #                            eta = 0.01,\n",
    "        #                            n_estimators = 500,\n",
    "        #                            # min_child_weight = 20,\n",
    "        #                            seed = 42, objective = 'multi:softmax', eval_metric = \"merror\", num_class = len(unique_ids), tree_method='hist', device='cuda')\n",
    "    \n",
    "        #Test 2\n",
    "        # classifier = XGBClassifier(max_depth = 6, \n",
    "        #                            reg_alpha = 10, \n",
    "        #                            reg_lambda = 10, \n",
    "        #                            gamma = 10, \n",
    "        #                            subsample = 0.75,\n",
    "        #                            colsample_bytree = 0.75,\n",
    "        #                            eta = 0.01,\n",
    "        #                            n_estimators = 500,\n",
    "        #                            min_child_weight = 20,\n",
    "        #                            seed = 42, objective = 'multi:softmax', eval_metric = \"merror\", num_class = len(unique_ids), tree_method='hist', device='cuda')\n",
    "    \n",
    "        classifier = XGBClassifier(seed = 42, objective = 'multi:softmax', eval_metric = \"merror\", num_class = len(unique_ids), tree_method='hist', device='cuda')\n",
    "        \n",
    "        \n",
    "        classifier.fit(X_train, y_train)\n",
    "        # preds_train = classifier.predict(X_train)\n",
    "        # preds = classifier.predict(X_test)\n",
    "        preds_train = np.argmax(classifier.predict_proba(X_train), axis=1)\n",
    "        preds = np.argmax(classifier.predict_proba(X_test), axis=1)\n",
    "    \n",
    "        plot_importance(classifier, max_num_features=20, importance_type='gain')\n",
    "        plt.show()\n",
    "    \n",
    "        # plot_importance(classifier, max_num_features=20, importance_type='cover')\n",
    "        # plt.show()\n",
    "    \n",
    "        # plot_importance(classifier, max_num_features=20, importance_type='weight')\n",
    "        # plt.show()\n",
    "    \n",
    "    \n",
    "        used_features = classifier.get_booster().get_score().keys()\n",
    "        print(\"# of Used Features\", len(used_features))\n",
    "    \n",
    "    \n",
    "        explainer = shap.TreeExplainer(classifier)\n",
    "        shap_values = explainer(cp.asnumpy(X_test))\n",
    "    \n",
    "        prompt_feats = []\n",
    "        for i in range(shap_values.values.shape[2]):\n",
    "            print(f\"Class {i}\")\n",
    "            shap.summary_plot(shap_values[:, :, i], cp.asnumpy(X_test))\n",
    "            shap.plots.bar(shap_values[:, :, i])\n",
    "    \n",
    "            # mean_abs_shap = np.abs(shap_values[:, :, i]).mean(axis=0)\n",
    "            # most_important_idx = mean_abs_shap.argmax()\n",
    "            # most_important_feature = X.columns[most_important_idx]\n",
    "    \n",
    "            most_important_prompt_feature = np.argsort(-np.abs(shap_values.values[:, :, i]).mean(axis = 0))[0]\n",
    "    \n",
    "            print(f\"Most Important Feature for Prompt {i}: \", most_important_prompt_feature)\n",
    "            prompt_feats.append(most_important_prompt_feature)\n",
    "    \n",
    "        #Overall\n",
    "        # mean_abs_shap = np.abs(shap_values).mean(axis=(0, 2))\n",
    "        # most_important_idx = mean_abs_shap.argmax()\n",
    "        # most_important_feature = X.columns[most_important_idx]\n",
    "    \n",
    "        most_important_overall_feature = np.argsort(-np.abs(shap_values.values).mean(axis=(0, 2)))[0]\n",
    "    \n",
    "        print(f\"Most Important Overall Feature: \", most_important_overall_feature)\n",
    "    \n",
    "        train_accuracy = np.mean(cp.array(preds_train) == y_train)\n",
    "        accuracy = np.mean(cp.array(preds) == y_test)\n",
    "    \n",
    "        print(f\"Train Accuracy: {train_accuracy}\")\n",
    "        print(f\"Test Accuracy: {accuracy}\")\n",
    "    \n",
    "        # prompt_accs = []\n",
    "    \n",
    "        for i in range(10):\n",
    "            mask = y_test == i\n",
    "            prompt_test = y_test[mask]\n",
    "            prompt_preds = cp.array(preds)[mask]\n",
    "            prompt_test_acc = np.mean(prompt_preds == prompt_test)\n",
    "    \n",
    "            mask_train = y_train == i\n",
    "            prompt_train = y_train[mask_train]\n",
    "            prompt_preds_train = cp.array(preds_train)[mask_train]\n",
    "            prompt_train_acc = np.mean(prompt_preds_train == prompt_train)\n",
    "    \n",
    "            print(f\"Prompt {i + 1} Train Accuracy: {prompt_train_acc}\")\n",
    "            print(f\"Prompt {i + 1} Test Accuracy: {prompt_test_acc}\")\n",
    "    \n",
    "            # prompt_accs.append(prompt_train_acc)\n",
    "            # prompt_accs.append(prompt_test_acc)\n",
    "    \n",
    "        with open(\"results-shap_values.csv\", \"a+\", newline='') as csvfile:\n",
    "                csv_writer = csv.writer(csvfile, delimiter=',')\n",
    "                values = [layer, context_level + 2, most_important_overall_feature]\n",
    "                values.extend(prompt_feats)\n",
    "                csv_writer.writerow(values)\n",
    "                \n",
    "    \n",
    "    \n",
    "        del classifier, X_train, y_train, X_test, y_test, preds\n",
    "    \n",
    "        # XGBoost cleanup\n",
    "        try:\n",
    "            booster = classifier.get_booster()\n",
    "            del booster\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # CuPy cleanup\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "        cp.get_default_pinned_memory_pool().free_all_blocks()\n",
    "        \n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26164269-f1ef-4d81-9330-6b8f161eb466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.argsort(-np.abs(shap_values.values[:, :, i]).mean(axis = 0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e64228b-60eb-4ade-9f89-7812fb10eaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.argsort(-np.abs(shap_values.values).mean(axis=(0, 2)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8312619-83d2-42b7-b830-e04e6ee202d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b80b420-ee05-49f3-b7cc-be63d751646c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap_values.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4ecca8-e6d2-4ab1-b96e-b58ac3a7e6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values.base_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454e0604-4486-40e8-9606-402f16b2392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761440e8-324e-482b-9539-50e9deb22d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(shap_values.values.shape[2]):\n",
    "#     print(f\"Class {i}\")\n",
    "#     shap.summary_plot(shap_values[:, :, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7482476c-d28b-46d6-8d85-88d8642695be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_idx = 0  # choose class\n",
    "\n",
    "# shap.plots.beeswarm(shap_values[:, :, class_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e94b49-9414-4eb3-930e-b7a009036a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.summary_plot(\n",
    "#     shap_values.values[:, :, class_idx],\n",
    "#     cp.asnumpy(X_test)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f182c08-3b5a-4430-b269-382a77532c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(shap_values.values.shape[2]):\n",
    "#     print(f\"Class {i}\")\n",
    "#     shap.plots.beeswarm(shap_values[:, :, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752039b9-a9c0-4c1d-ba4a-f472d7700430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_importance = np.mean(np.abs(shap_values), axis=(0,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
