{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "695603db-d2c0-4c74-a899-31747b53d83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (4.7.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.18.3)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.10.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.46)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.3)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
      "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (2.3.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: optuna-dashboard in /usr/local/lib/python3.10/dist-packages (0.20.0)\n",
      "Requirement already satisfied: bottle>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from optuna-dashboard) (0.13.4)\n",
      "Requirement already satisfied: optuna>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from optuna-dashboard) (4.7.0)\n",
      "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from optuna-dashboard) (2.3.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.6.0->optuna-dashboard) (1.18.3)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna>=3.6.0->optuna-dashboard) (6.10.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna>=3.6.0->optuna-dashboard) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.6.0->optuna-dashboard) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.6.0->optuna-dashboard) (2.0.46)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna>=3.6.0->optuna-dashboard) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna>=3.6.0->optuna-dashboard) (6.0.3)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna>=3.6.0->optuna-dashboard) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna>=3.6.0->optuna-dashboard) (4.15.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.6.0->optuna-dashboard) (3.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna>=3.6.0->optuna-dashboard) (2.1.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: optuna-integration in /usr/local/lib/python3.10/dist-packages (4.7.0)\n",
      "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (from optuna-integration) (4.7.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (1.18.3)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (6.10.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (2.0.46)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (6.0.3)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna->optuna-integration) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna->optuna-integration) (4.15.0)\n",
      "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna->optuna-integration) (2.3.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna->optuna-integration) (3.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna->optuna-integration) (2.1.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna\n",
    "!pip install optuna-dashboard\n",
    "!pip install optuna-integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "138b9187-7def-48ff-a26f-12d249897810",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost.core import XGBoostError\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "import cupy as cp\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40fe6220-eee3-4f0c-9427-46fa99111a13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>story</th>\n",
       "      <th>hidden_state_file</th>\n",
       "      <th>len_generated_story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon. It was bi...</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon. He loved ...</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon named Sam....</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon. He was a ...</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon. The drago...</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prompt_id                                 prompt  \\\n",
       "0             1    Once upon a time there was a dragon   \n",
       "1             1    Once upon a time there was a dragon   \n",
       "2             1    Once upon a time there was a dragon   \n",
       "3             1    Once upon a time there was a dragon   \n",
       "4             1    Once upon a time there was a dragon   \n",
       "...         ...                                    ...   \n",
       "9995         10  Once upon a time there was a poor boy   \n",
       "9996         10  Once upon a time there was a poor boy   \n",
       "9997         10  Once upon a time there was a poor boy   \n",
       "9998         10  Once upon a time there was a poor boy   \n",
       "9999         10  Once upon a time there was a poor boy   \n",
       "\n",
       "                                                  story  \\\n",
       "0     Once upon a time there was a dragon. It was bi...   \n",
       "1     Once upon a time there was a dragon. He loved ...   \n",
       "2     Once upon a time there was a dragon named Sam....   \n",
       "3     Once upon a time there was a dragon. He was a ...   \n",
       "4     Once upon a time there was a dragon. The drago...   \n",
       "...                                                 ...   \n",
       "9995  Once upon a time there was a poor boy named Ti...   \n",
       "9996  Once upon a time there was a poor boy named Ti...   \n",
       "9997  Once upon a time there was a poor boy named Ti...   \n",
       "9998  Once upon a time there was a poor boy named Ti...   \n",
       "9999  Once upon a time there was a poor boy named Ti...   \n",
       "\n",
       "                  hidden_state_file  len_generated_story  \n",
       "0      ./hidden_states/prompt_1.npz                  273  \n",
       "1      ./hidden_states/prompt_1.npz                  246  \n",
       "2      ./hidden_states/prompt_1.npz                  397  \n",
       "3      ./hidden_states/prompt_1.npz                  294  \n",
       "4      ./hidden_states/prompt_1.npz                  296  \n",
       "...                             ...                  ...  \n",
       "9995  ./hidden_states/prompt_10.npz                  315  \n",
       "9996  ./hidden_states/prompt_10.npz                  270  \n",
       "9997  ./hidden_states/prompt_10.npz                  206  \n",
       "9998  ./hidden_states/prompt_10.npz                  375  \n",
       "9999  ./hidden_states/prompt_10.npz                  341  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../story_dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39918677-9de6-47de-9cd9-cdfe96b79439",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1204.72it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1219.00it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1213.16it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1189.16it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1198.19it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1207.41it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1200.80it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1200.88it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1205.92it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1098.58it/s]\n"
     ]
    }
   ],
   "source": [
    "hidden_states_by_layer = {}\n",
    "NUM_PROMPTS = 10\n",
    "# NUM_PROMPTS = 2\n",
    "\n",
    "#Load hidden states to generate first token\n",
    "for prompt_id in range(1, NUM_PROMPTS + 1):\n",
    "    with np.load(f'../../../llamatales-xgboost-ii/hidden_states/first_prompt_{prompt_id}.npz') as loaded_data:\n",
    "        for i in tqdm(range(1000)):\n",
    "            curr_hidden_states = loaded_data[f\"arr_{i}\"]\n",
    "            # print(curr_hidden_states.shape)\n",
    "            \n",
    "            #By layer\n",
    "            for layer in range(1):\n",
    "                curr_layer_hidden_states = curr_hidden_states[layer][0].astype('float32') #FAISS expects data in type float32 instead of float64 - saves memory too!\n",
    "                # print(curr_layer_hidden_states.shape)\n",
    "                \n",
    "                if(f\"layer_{layer}\" in hidden_states_by_layer):\n",
    "                    hidden_states_by_layer[f\"layer_{layer}\"].append(curr_layer_hidden_states)\n",
    "                else:\n",
    "                    hidden_states_by_layer[f\"layer_{layer}\"] = [curr_layer_hidden_states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d26b3c5-e3ab-4823-954a-6937a516890e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 512)\n",
      "(10, 512)\n"
     ]
    }
   ],
   "source": [
    "layer_hs_array = hidden_states_by_layer[\"layer_0\"]\n",
    "print(layer_hs_array[0].shape)\n",
    "print(layer_hs_array[-1].shape)\n",
    "#9x512 (prompts 1-9) or 10x512 (prompt 10)\n",
    "\n",
    "#Convert prompt 10 hidden states to only encode last 9 tokens so dimensions are consistent w other prompts\n",
    "for hs in range(len(layer_hs_array)):\n",
    "    if(layer_hs_array[hs].shape[0] > 9):\n",
    "        layer_hs_array[hs] = layer_hs_array[hs][1:]\n",
    "\n",
    "\n",
    "for hs in range(len(layer_hs_array)):\n",
    "    layer_hs_array[hs] = layer_hs_array[hs].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07f82317-93da-4fcd-bbc2-14f05b26994e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_story_len = min(df[\"len_generated_story\"])\n",
    "min_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6a6dd98-d137-4966-8772-5af229b96a72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_story_len = max(df[:NUM_PROMPTS*1000][\"len_generated_story\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "139d266d-2eb6-4d6a-8de6-9e65671ab8e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>story</th>\n",
       "      <th>hidden_state_file</th>\n",
       "      <th>len_generated_story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9851</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prompt_id                                 prompt  \\\n",
       "9851         10  Once upon a time there was a poor boy   \n",
       "\n",
       "                                                  story  \\\n",
       "9851  Once upon a time there was a poor boy named Ti...   \n",
       "\n",
       "                  hidden_state_file  len_generated_story  \n",
       "9851  ./hidden_states/prompt_10.npz                  522  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"len_generated_story\"] >= max_story_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fc51a06-9ad8-4e4f-b338-73e2ac5b96cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def safe_split(total, train_ratio=0.8):\n",
    "    train = int(train_ratio * total)   # floor\n",
    "    test  = total - train              # leftover\n",
    "    return train, test\n",
    "\n",
    "def build_dataset(curr_context_level_hs, curr_labels, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Groups samples by prompt_id, splits safely into train/test,\n",
    "    and returns X_train, y_train, X_test, y_test.\n",
    "    \"\"\"\n",
    "\n",
    "    unique_ids = sorted(set(curr_labels))\n",
    "\n",
    "    X_train_list = []\n",
    "    X_test_list = []\n",
    "    y_train_list = []\n",
    "    y_test_list = []\n",
    "\n",
    "    for pid in unique_ids:\n",
    "\n",
    "        # get samples for this prompt id\n",
    "        mask = (curr_labels == pid)\n",
    "        X_pid = curr_context_level_hs[mask]\n",
    "        y_pid = curr_labels[mask]\n",
    "\n",
    "        total = len(X_pid)\n",
    "        train_n, test_n = safe_split(total, train_ratio)\n",
    "\n",
    "        # split\n",
    "        X_train_list.append(X_pid[:train_n])\n",
    "        y_train_list.append(y_pid[:train_n])\n",
    "\n",
    "        X_test_list.append(X_pid[train_n:])\n",
    "        y_test_list.append(y_pid[train_n:])\n",
    "\n",
    "    # concatenate all prompt-id blocks\n",
    "    X_train = np.concatenate(X_train_list, axis=0)\n",
    "    y_train = np.concatenate(y_train_list, axis=0)\n",
    "    X_test  = np.concatenate(X_test_list, axis=0)\n",
    "    y_test  = np.concatenate(y_test_list, axis=0)\n",
    "\n",
    "    # return cp.array(X_train), cp.array(y_train), cp.array(X_test), cp.array(y_test)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c0aae8b-2ded-41e5-95d0-7687608ba387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 9 9 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-04 03:25:54,642]\u001b[0m A new study created in memory with name: no-name-9b1f0c91-d112-41a2-a9d9-507fab6ff951\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b576e35333ba410aa1ebe20a07ca8dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-04 03:26:02,394]\u001b[0m Trial 0 finished with value: 1.0 and parameters: {'max_depth': 8, 'learning_rate': 0.09421898669488918, 'n_estimators': 612, 'subsample': 0.7748534514042495, 'colsample_bytree': 0.9063197390403603, 'min_child_weight': 6, 'gamma': 1.4792150096615457}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:26:12,259]\u001b[0m Trial 1 finished with value: 1.0 and parameters: {'max_depth': 10, 'learning_rate': 0.09620331522778179, 'n_estimators': 832, 'subsample': 0.782842523375292, 'colsample_bytree': 0.6016799409595499, 'min_child_weight': 7, 'gamma': 0.4792344521911679}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:26:18,038]\u001b[0m Trial 2 finished with value: 1.0 and parameters: {'max_depth': 6, 'learning_rate': 0.02314632669309201, 'n_estimators': 428, 'subsample': 0.5802256430399488, 'colsample_bytree': 0.5731198162219382, 'min_child_weight': 1, 'gamma': 4.793281347760296}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:26:22,825]\u001b[0m Trial 3 finished with value: 1.0 and parameters: {'max_depth': 10, 'learning_rate': 0.045990561671616, 'n_estimators': 372, 'subsample': 0.8915479282330274, 'colsample_bytree': 0.679279443845658, 'min_child_weight': 7, 'gamma': 0.2120206171662664}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:26:33,620]\u001b[0m Trial 4 finished with value: 1.0 and parameters: {'max_depth': 6, 'learning_rate': 0.08458847177909386, 'n_estimators': 929, 'subsample': 0.9865057769072192, 'colsample_bytree': 0.5185801314711641, 'min_child_weight': 9, 'gamma': 1.467784287625065}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:26:41,546]\u001b[0m Trial 5 finished with value: 1.0 and parameters: {'max_depth': 3, 'learning_rate': 0.038014214127030224, 'n_estimators': 639, 'subsample': 0.7248235748693574, 'colsample_bytree': 0.6397765029305693, 'min_child_weight': 3, 'gamma': 3.6060073930293237}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:26:50,137]\u001b[0m Trial 6 finished with value: 1.0 and parameters: {'max_depth': 9, 'learning_rate': 0.034352679112471675, 'n_estimators': 694, 'subsample': 0.9693919272197067, 'colsample_bytree': 0.6739194838522085, 'min_child_weight': 2, 'gamma': 3.4161352003164995}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:26:56,693]\u001b[0m Trial 7 finished with value: 1.0 and parameters: {'max_depth': 10, 'learning_rate': 0.01066307839205954, 'n_estimators': 434, 'subsample': 0.95874162095707, 'colsample_bytree': 0.8354614138388228, 'min_child_weight': 8, 'gamma': 1.6570448199703558}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:27:00,504]\u001b[0m Trial 8 finished with value: 1.0 and parameters: {'max_depth': 3, 'learning_rate': 0.09438365179033124, 'n_estimators': 313, 'subsample': 0.89291638061366, 'colsample_bytree': 0.5587092854898283, 'min_child_weight': 8, 'gamma': 0.10090154473762214}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:27:12,251]\u001b[0m Trial 9 finished with value: 1.0 and parameters: {'max_depth': 4, 'learning_rate': 0.052183291134290544, 'n_estimators': 985, 'subsample': 0.886103283185687, 'colsample_bytree': 0.6201731593175918, 'min_child_weight': 8, 'gamma': 0.3126804143423956}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:27:19,694]\u001b[0m Trial 10 finished with value: 1.0 and parameters: {'max_depth': 8, 'learning_rate': 0.07000766681050169, 'n_estimators': 597, 'subsample': 0.5003172084725993, 'colsample_bytree': 0.9644422578581393, 'min_child_weight': 4, 'gamma': 2.280690477565498}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:27:21,320]\u001b[0m Trial 11 finished with value: 1.0 and parameters: {'max_depth': 8, 'learning_rate': 0.09912767280634784, 'n_estimators': 112, 'subsample': 0.7491970811099485, 'colsample_bytree': 0.8134326849466362, 'min_child_weight': 5, 'gamma': 1.0654181997226366}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:27:31,294]\u001b[0m Trial 12 finished with value: 1.0 and parameters: {'max_depth': 8, 'learning_rate': 0.07578285510518945, 'n_estimators': 813, 'subsample': 0.6882713575392058, 'colsample_bytree': 0.9554271292639712, 'min_child_weight': 6, 'gamma': 1.188780440612098}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:27:40,909]\u001b[0m Trial 13 finished with value: 1.0 and parameters: {'max_depth': 7, 'learning_rate': 0.07131787914743555, 'n_estimators': 791, 'subsample': 0.8260209368048145, 'colsample_bytree': 0.8745031404659499, 'min_child_weight': 10, 'gamma': 2.3843790215013367}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:27:50,386]\u001b[0m Trial 14 finished with value: 1.0 and parameters: {'max_depth': 9, 'learning_rate': 0.08425355325864606, 'n_estimators': 790, 'subsample': 0.8064959919821671, 'colsample_bytree': 0.7154916161519915, 'min_child_weight': 6, 'gamma': 0.8671300716083111}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2026-02-04 03:27:56,899]\u001b[0m Trial 15 finished with value: 1.0 and parameters: {'max_depth': 10, 'learning_rate': 0.058637597815623936, 'n_estimators': 520, 'subsample': 0.6436145741688275, 'colsample_bytree': 0.7676857359928991, 'min_child_weight': 5, 'gamma': 1.9634144415212944}. Best is trial 0 with value: 1.0.\u001b[0m\n",
      "\u001b[33m[W 2026-02-04 03:28:06,566]\u001b[0m Trial 16 failed with parameters: {'max_depth': 7, 'learning_rate': 0.089242518796575, 'n_estimators': 878, 'subsample': 0.815854990684939, 'colsample_bytree': 0.9027606875252668, 'min_child_weight': 4, 'gamma': 3.1655893991004556} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 206, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_1037/2524850559.py\", line 39, in objective\n",
      "    model.fit(X_train, y_train)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 2434, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2026-02-04 03:28:06,568]\u001b[0m Trial 16 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 60\u001b[0m\n\u001b[1;32m     55\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# study = optuna.create_study(\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m#     pruner=optuna.pruners.MedianPruner(), \u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m#     direction=\"maximize\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# n_jobs=-1\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy\u001b[38;5;241m.\u001b[39mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:68\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 68\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:165\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     frozen_trial_id \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:263\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    259\u001b[0m     updated_state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    262\u001b[0m ):\n\u001b[0;32m--> 263\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\u001b[38;5;241m.\u001b[39m_trial_id\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:206\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[10], line 39\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# initializing the XGBoost model\u001b[39;00m\n\u001b[1;32m     32\u001b[0m model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparam,\n\u001b[1;32m     33\u001b[0m                           seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m, \u001b[38;5;66;03m#for reproducibility\u001b[39;00m\n\u001b[1;32m     34\u001b[0m                           objective \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti:softmax\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m                           tree_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhist\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Using GPU for training \u001b[39;00m\n\u001b[1;32m     38\u001b[0m                           device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)       \u001b[38;5;66;03m# If you have multiple GPUs, you can specify the GPU ID\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# pruning_callback = XGBoostPruningCallback(trial, \"validation_0-merror\")\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# model.fit(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# preds = model.predict(X_valid)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py:774\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    773\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:1806\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1786\u001b[0m evals_result: EvalsLog \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1787\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1788\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1789\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1803\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39mfeature_types,\n\u001b[1;32m   1804\u001b[0m )\n\u001b[0;32m-> 1806\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1809\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1810\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1812\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1813\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1818\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1821\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py:774\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    773\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/training.py:199\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py:2434\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2430\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2433\u001b[0m     _check_call(\n\u001b[0;32m-> 2434\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2435\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2436\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2437\u001b[0m     )\n\u001b[1;32m   2438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2439\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "curr_labels = df.prompt_id.to_numpy() - 1\n",
    "print(curr_labels)\n",
    "curr_context_level_hs = np.array(layer_hs_array)\n",
    "\n",
    "unique_ids = sorted(set(curr_labels))\n",
    "\n",
    "X_train, y_train, X_test, y_test = build_dataset(curr_context_level_hs, curr_labels)\n",
    "# X_train, y_train, X_test, y_test = train_test_split(curr_context_level_hs, curr_labels, test_size = 0.2, random_state=42)\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2, random_state=42)\n",
    "\n",
    "X_train = cp.array(X_train)\n",
    "y_train = cp.array(y_train)\n",
    "X_test = cp.array(X_test)\n",
    "y_test = cp.array(y_test)\n",
    "# X_valid = cp.array(X_valid)\n",
    "# y_valid = cp.array(y_valid)\n",
    "\n",
    "# Defining the objective function\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "    }\n",
    "    \n",
    "    # initializing the XGBoost model\n",
    "    model = xgb.XGBClassifier(**param,\n",
    "                              seed = 42, #for reproducibility\n",
    "                              objective = 'multi:softmax',\n",
    "                              eval_metric = \"merror\",\n",
    "                              num_class = 10,\n",
    "                              tree_method = 'hist',  # Using GPU for training \n",
    "                              device = 'cuda')       # If you have multiple GPUs, you can specify the GPU ID\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # pruning_callback = XGBoostPruningCallback(trial, \"validation_0-merror\")\n",
    "    \n",
    "    # model.fit(\n",
    "    #     X_train, y_train,\n",
    "    #     eval_set=[(X_valid, y_valid)],\n",
    "    #     callbacks=[pruning_callback],\n",
    "    #     verbose=False\n",
    "    # )\n",
    "\n",
    "    # preds = model.predict(X_valid)\n",
    "    preds = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test.get(), preds)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "# study = optuna.create_study(\n",
    "#     pruner=optuna.pruners.MedianPruner(), \n",
    "#     direction=\"maximize\"\n",
    "# )\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=True) # n_jobs=-1\n",
    "\n",
    "\n",
    "print(f\"Best trial: {study.best_trial.value}\")\n",
    "print(f\"Best params: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f646c14e-f937-4afd-92d1-638924023cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 9 9 9]\n",
      "Train Data Shape:  (8000, 4608)\n",
      "Test Data Shape:  (2000, 4608)\n",
      "Train Accuracy: 1.0\n",
      "Accuracy: 1.0\n",
      "Prompt 1 Train Accuracy: 1.0\n",
      "Prompt 1 Test Accuracy: 1.0\n",
      "Prompt 2 Train Accuracy: 1.0\n",
      "Prompt 2 Test Accuracy: 1.0\n",
      "Prompt 3 Train Accuracy: 1.0\n",
      "Prompt 3 Test Accuracy: 1.0\n",
      "Prompt 4 Train Accuracy: 1.0\n",
      "Prompt 4 Test Accuracy: 1.0\n",
      "Prompt 5 Train Accuracy: 1.0\n",
      "Prompt 5 Test Accuracy: 1.0\n",
      "Prompt 6 Train Accuracy: 1.0\n",
      "Prompt 6 Test Accuracy: 1.0\n",
      "Prompt 7 Train Accuracy: 1.0\n",
      "Prompt 7 Test Accuracy: 1.0\n",
      "Prompt 8 Train Accuracy: 1.0\n",
      "Prompt 8 Test Accuracy: 1.0\n",
      "Prompt 9 Train Accuracy: 1.0\n",
      "Prompt 9 Test Accuracy: 1.0\n",
      "Prompt 10 Train Accuracy: 1.0\n",
      "Prompt 10 Test Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Context-level analysis\n",
    "# min_story_len = min(df[\"len_new_story\"])\n",
    "# with open(\"results.csv\", \"w+\", newline='') as csvfile:\n",
    "#     csv_writer = csv.writer(csvfile, delimiter=',')\n",
    "#     csv_writer.writerow(['Context Level', 'Accuracy'])\n",
    "\n",
    "with open(\"../results.csv\", \"w+\", newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile, delimiter=',')\n",
    "    header = ['Layer', 'Context_Level', 'Train_Accuracy', 'Test_Accuracy']\n",
    "    prompt_headers = []\n",
    "    for i in range(1, 11):\n",
    "        prompt_headers.extend([f\"Prompt_{i}_Train_Accuracy\", f\"Prompt_{i}_Test_Accuracy\"])\n",
    "\n",
    "    header.extend(prompt_headers)\n",
    "    csv_writer.writerow(header)\n",
    "\n",
    "curr_labels = df.prompt_id.to_numpy() - 1\n",
    "print(curr_labels)\n",
    "curr_context_level_hs = np.array(layer_hs_array)\n",
    "\n",
    "unique_ids = sorted(set(curr_labels))\n",
    "\n",
    "X_train, y_train, X_test, y_test = build_dataset(curr_context_level_hs, curr_labels)\n",
    "# X_train, y_train, X_test, y_test = train_test_split(curr_context_level_hs, curr_labels, test_size = 0.2, random_state=42)\n",
    "\n",
    "X_train, y_train, X_valid, y_valid = train_test_split(X_train, y_train, test_size = 0.2, random_state=42)\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=0.95)\n",
    "\n",
    "# X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "# X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# print(\"Train Data Shape: \", X_train_pca.shape)\n",
    "# # print(\"Train Labels Shape: \", y_train.shape)\n",
    "# print(\"Test Data Shape: \", X_test_pca.shape)\n",
    "# # print(\"Test Labels Shape: \", y_test.shape)\n",
    "\n",
    "# X_train_pca = cp.array(X_train_pca)\n",
    "# y_train = cp.array(y_train)\n",
    "# X_test_pca = cp.array(X_test_pca)\n",
    "# y_test = cp.array(y_test)\n",
    "\n",
    "print(\"Train Data Shape: \", X_train.shape)\n",
    "#     print(\"Train Labels Shape: \", y_train.shape)\n",
    "print(\"Test Data Shape: \", X_test.shape)\n",
    "#     print(\"Test Labels Shape: \", y_test.shape)\n",
    "\n",
    "X_train = cp.array(X_train)\n",
    "y_train = cp.array(y_train)\n",
    "X_test = cp.array(X_test)\n",
    "y_test = cp.array(y_test)\n",
    "\n",
    "# classifier = XGBClassifier(seed = 42, objective = 'multi:softmax', eval_metric = \"merror\", num_class = len(unique_ids))\n",
    "# classifier = XGBClassifier(seed = 42, objective = 'multi:softmax', eval_metric = \"merror\", num_class = len(unique_ids), tree_method='gpu_hist', predictor='gpu_predictor')\n",
    "classifier = XGBClassifier(seed = 42, objective = 'multi:softmax', eval_metric = \"merror\", num_class = 10, tree_method='hist', device='cuda')\n",
    "classifier.fit(X_train, y_train)\n",
    "preds_train = classifier.predict(X_train)\n",
    "preds = classifier.predict(X_test)\n",
    "\n",
    "# classifier.fit(X_train_pca, y_train)\n",
    "# preds = classifier.predict(X_test_pca)\n",
    "\n",
    "\n",
    "#     print(\"Predictions Shape: \", preds.shape)\n",
    "\n",
    "#     print(\"Unique Preds: \", pd.Series(preds).value_counts())\n",
    "#     print(\"Unique Test Labels: \", pd.Series(y_test).value_counts())\n",
    "\n",
    "train_accuracy = np.mean(cp.array(preds_train) == y_train)\n",
    "accuracy = np.mean(cp.array(preds) == y_test)\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "# with open(\"results.csv\", \"a+\", newline='') as csvfile:\n",
    "#     csv_writer = csv.writer(csvfile, delimiter=',')\n",
    "#     csv_writer.writerow([X_train.shape[1] // 512, accuracy])\n",
    "\n",
    "prompt_accs = []\n",
    "\n",
    "for i in range(10):\n",
    "    mask = y_test == i\n",
    "    prompt_test = y_test[mask]\n",
    "    prompt_preds = cp.array(preds)[mask]\n",
    "    prompt_test_acc = np.mean(prompt_preds == prompt_test)\n",
    "\n",
    "    mask_train = y_train == i\n",
    "    prompt_train = y_train[mask_train]\n",
    "    prompt_preds_train = cp.array(preds_train)[mask_train]\n",
    "    prompt_train_acc = np.mean(prompt_preds_train == prompt_train)\n",
    "\n",
    "    print(f\"Prompt {i + 1} Train Accuracy: {prompt_train_acc}\")\n",
    "    print(f\"Prompt {i + 1} Test Accuracy: {prompt_test_acc}\")\n",
    "\n",
    "    prompt_accs.append(prompt_train_acc)\n",
    "    prompt_accs.append(prompt_test_acc)\n",
    "\n",
    "\n",
    "with open(\"../results.csv\", \"a+\", newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile, delimiter=',')\n",
    "    values = [layer, 1, train_accuracy, accuracy]\n",
    "    values.extend(prompt_accs)\n",
    "    csv_writer.writerow(values)\n",
    "\n",
    "\n",
    "del classifier, X_train, y_train, X_test, y_test, preds\n",
    "\n",
    "# XGBoost cleanup\n",
    "try:\n",
    "    booster = classifier.get_booster()\n",
    "    del booster\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# CuPy cleanup (CRITICAL)\n",
    "cp.get_default_memory_pool().free_all_blocks()\n",
    "cp.get_default_pinned_memory_pool().free_all_blocks()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# print(max(curr_hs_shapes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2b8aa91-0ddc-4b34-8c29-61445c63b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd81093c-c815-4c81-b2bb-c28fa614a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a830ed2-048b-40ec-b461-0a3b0017b9de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
