{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20f78858-6116-4b7c-b63c-e84194d74685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get hidden states by context level and by layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c08f418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/sbksvol/amurali/'\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token = \"<hf_token>\")\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer, AutoModelForCausalLM, pipeline, LlamaForCausalLM, GenerationConfig\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "194dfcce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.2.2+cu121\n",
      "Transformers Version: 4.33.3\n",
      "NumPy Version: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Transformers Version: {transformers.__version__}\")\n",
    "print(f\"NumPy Version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6337c21e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1: \"Once upon a time there was a dragon\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                  | 1/1000 [00:02<34:10,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 512])\n",
      "Hidden states shape: 263 generated tokens × 9 layers × 1 sequences × 9 tokens × 512 dims\n",
      "3053.3718\n",
      "3094.3384\n",
      "3126.7314\n",
      "3157.2288\n",
      "3200.8206\n",
      "3247.9143\n",
      "3281.729\n",
      "3312.0684\n",
      "3350.6958\n",
      "3380.3496\n",
      "3406.9055\n",
      "3436.44\n",
      "3478.0977\n",
      "3515.0015\n",
      "3554.1714\n",
      "3586.1753\n",
      "3612.1433\n",
      "3641.903\n",
      "3668.8616\n",
      "3696.6523\n",
      "3721.286\n",
      "3748.007\n",
      "3773.895\n",
      "3802.56\n",
      "3829.883\n",
      "3860.369\n",
      "3887.3433\n",
      "3912.3137\n",
      "3942.7844\n",
      "3977.7188\n",
      "4003.6897\n",
      "4027.5972\n",
      "4051.592\n",
      "4072.6257\n",
      "4098.155\n",
      "4119.4585\n",
      "4143.108\n",
      "4166.0205\n",
      "4189.029\n",
      "4215.0415\n",
      "4240.1675\n",
      "4265.683\n",
      "4290.179\n",
      "4313.0977\n",
      "4337.406\n",
      "4365.9434\n",
      "4393.7812\n",
      "4425.125\n",
      "4446.6313\n",
      "4472.0\n",
      "4500.589\n",
      "4518.868\n",
      "4539.7314\n",
      "4566.8457\n",
      "4594.654\n",
      "4616.971\n",
      "4637.8447\n",
      "4660.352\n",
      "4685.661\n",
      "4709.8403\n",
      "4730.2104\n",
      "4750.6304\n",
      "4777.8066\n",
      "4803.3613\n",
      "4829.498\n",
      "4850.305\n",
      "4870.337\n",
      "4897.1577\n",
      "4925.2246\n",
      "4952.6206\n",
      "4972.509\n",
      "4993.458\n",
      "5010.1777\n",
      "5029.0845\n",
      "5050.328\n",
      "5069.8184\n",
      "5088.608\n",
      "5111.9604\n",
      "5137.178\n",
      "5153.6147\n",
      "5171.9263\n",
      "5189.284\n",
      "5207.274\n",
      "5226.2266\n",
      "5246.4565\n",
      "5267.2095\n",
      "5282.442\n",
      "5300.578\n",
      "5337.922\n",
      "5357.214\n",
      "5378.009\n",
      "5393.27\n",
      "5409.5938\n",
      "5425.7197\n",
      "5441.5776\n",
      "5458.674\n",
      "5481.7607\n",
      "5504.088\n",
      "5523.157\n",
      "5542.542\n",
      "5568.539\n",
      "5587.9287\n",
      "5608.1963\n",
      "5630.7554\n",
      "5646.6865\n",
      "5666.6875\n",
      "5686.454\n",
      "5700.0566\n",
      "5715.743\n",
      "5734.0493\n",
      "5752.915\n",
      "5774.8833\n",
      "5801.154\n",
      "5823.0415\n",
      "5840.128\n",
      "5856.9277\n",
      "5875.498\n",
      "5890.4653\n",
      "5906.7573\n",
      "5926.101\n",
      "5943.9023\n",
      "5958.473\n",
      "5972.2773\n",
      "5988.162\n",
      "6002.594\n",
      "6016.467\n",
      "6032.1133\n",
      "6050.192\n",
      "6065.1143\n",
      "6078.2935\n",
      "6092.5767\n",
      "6108.932\n",
      "6122.2896\n",
      "6135.683\n",
      "6152.7236\n",
      "6171.1377\n",
      "6183.345\n",
      "6196.897\n",
      "6211.475\n",
      "6226.778\n",
      "6241.883\n",
      "6255.1133\n",
      "6268.9624\n",
      "6282.1177\n",
      "6297.5938\n",
      "6310.1665\n",
      "6326.6846\n",
      "6338.9507\n",
      "6350.9927\n",
      "6365.797\n",
      "6379.4536\n",
      "6397.547\n",
      "6414.161\n",
      "6427.4863\n",
      "6441.5986\n",
      "6458.249\n",
      "6475.847\n",
      "6491.274\n",
      "6504.157\n",
      "6516.0303\n",
      "6527.3374\n",
      "6545.325\n",
      "6560.4204\n",
      "6575.8193\n",
      "6592.224\n",
      "6605.0977\n",
      "6617.9756\n",
      "6631.7534\n",
      "6645.3525\n",
      "6657.861\n",
      "6668.419\n",
      "6681.262\n",
      "6693.529\n",
      "6705.5435\n",
      "6718.1035\n",
      "6733.3545\n",
      "6749.9766\n",
      "6763.7007\n",
      "6776.837\n",
      "6791.7246\n",
      "6804.9043\n",
      "6819.786\n",
      "6834.0986\n",
      "6851.5513\n",
      "6867.585\n",
      "6877.874\n",
      "6889.3906\n",
      "6902.083\n",
      "6912.166\n",
      "6922.135\n",
      "6932.248\n",
      "6943.169\n",
      "6954.9175\n",
      "6965.945\n",
      "6976.8535\n",
      "6989.8687\n",
      "7001.6504\n",
      "7014.875\n",
      "7032.7866\n",
      "7047.836\n",
      "7060.2256\n",
      "7074.235\n",
      "7084.1123\n",
      "7095.2275\n",
      "7106.062\n",
      "7117.213\n",
      "7129.4863\n",
      "7146.317\n",
      "7160.4053\n",
      "7169.933\n",
      "7180.7324\n",
      "7196.4575\n",
      "7212.712\n",
      "7222.412\n",
      "7233.17\n",
      "7243.582\n",
      "7254.246\n",
      "7267.612\n",
      "7278.9883\n",
      "7291.975\n",
      "7305.116\n",
      "7325.824\n",
      "7337.539\n",
      "7346.5596\n",
      "7356.192\n",
      "7367.666\n",
      "7377.778\n",
      "7387.867\n",
      "7400.785\n",
      "7411.983\n",
      "7422.5107\n",
      "7434.3438\n",
      "7445.2295\n",
      "7455.3027\n",
      "7466.012\n",
      "7480.4355\n",
      "7493.1177\n",
      "7506.805\n",
      "7517.951\n",
      "7527.418\n",
      "7537.4937\n",
      "7548.1235\n",
      "7558.3774\n",
      "7570.6846\n",
      "7581.3716\n",
      "7593.197\n",
      "7606.4253\n",
      "7621.396\n",
      "7636.383\n",
      "7649.2563\n",
      "7660.868\n",
      "7674.4546\n",
      "7689.9746\n",
      "7703.2905\n",
      "7716.004\n",
      "7730.0874\n",
      "7741.9673\n",
      "7753.973\n",
      "7765.5146\n",
      "7775.996\n",
      "7789.0376\n",
      "7801.779\n",
      "7811.4683\n",
      "9 layers × 1 sequences × 9 tokens × 512 dims\n",
      "9 layers × 1 sequences × 10 tokens × 512 dims\n",
      "9 layers × 1 sequences × 11 tokens × 512 dims\n",
      "9 layers × 1 sequences × 12 tokens × 512 dims\n",
      "9 layers × 1 sequences × 13 tokens × 512 dims\n",
      "9 layers × 1 sequences × 14 tokens × 512 dims\n",
      "9 layers × 1 sequences × 15 tokens × 512 dims\n",
      "9 layers × 1 sequences × 16 tokens × 512 dims\n",
      "9 layers × 1 sequences × 17 tokens × 512 dims\n",
      "9 layers × 1 sequences × 18 tokens × 512 dims\n",
      "9 layers × 1 sequences × 19 tokens × 512 dims\n",
      "9 layers × 1 sequences × 20 tokens × 512 dims\n",
      "9 layers × 1 sequences × 21 tokens × 512 dims\n",
      "9 layers × 1 sequences × 22 tokens × 512 dims\n",
      "9 layers × 1 sequences × 23 tokens × 512 dims\n",
      "9 layers × 1 sequences × 24 tokens × 512 dims\n",
      "9 layers × 1 sequences × 25 tokens × 512 dims\n",
      "9 layers × 1 sequences × 26 tokens × 512 dims\n",
      "9 layers × 1 sequences × 27 tokens × 512 dims\n",
      "9 layers × 1 sequences × 28 tokens × 512 dims\n",
      "9 layers × 1 sequences × 29 tokens × 512 dims\n",
      "9 layers × 1 sequences × 30 tokens × 512 dims\n",
      "9 layers × 1 sequences × 31 tokens × 512 dims\n",
      "9 layers × 1 sequences × 32 tokens × 512 dims\n",
      "9 layers × 1 sequences × 33 tokens × 512 dims\n",
      "9 layers × 1 sequences × 34 tokens × 512 dims\n",
      "9 layers × 1 sequences × 35 tokens × 512 dims\n",
      "9 layers × 1 sequences × 36 tokens × 512 dims\n",
      "9 layers × 1 sequences × 37 tokens × 512 dims\n",
      "9 layers × 1 sequences × 38 tokens × 512 dims\n",
      "9 layers × 1 sequences × 39 tokens × 512 dims\n",
      "9 layers × 1 sequences × 40 tokens × 512 dims\n",
      "9 layers × 1 sequences × 41 tokens × 512 dims\n",
      "9 layers × 1 sequences × 42 tokens × 512 dims\n",
      "9 layers × 1 sequences × 43 tokens × 512 dims\n",
      "9 layers × 1 sequences × 44 tokens × 512 dims\n",
      "9 layers × 1 sequences × 45 tokens × 512 dims\n",
      "9 layers × 1 sequences × 46 tokens × 512 dims\n",
      "9 layers × 1 sequences × 47 tokens × 512 dims\n",
      "9 layers × 1 sequences × 48 tokens × 512 dims\n",
      "9 layers × 1 sequences × 49 tokens × 512 dims\n",
      "9 layers × 1 sequences × 50 tokens × 512 dims\n",
      "9 layers × 1 sequences × 51 tokens × 512 dims\n",
      "9 layers × 1 sequences × 52 tokens × 512 dims\n",
      "9 layers × 1 sequences × 53 tokens × 512 dims\n",
      "9 layers × 1 sequences × 54 tokens × 512 dims\n",
      "9 layers × 1 sequences × 55 tokens × 512 dims\n",
      "9 layers × 1 sequences × 56 tokens × 512 dims\n",
      "9 layers × 1 sequences × 57 tokens × 512 dims\n",
      "9 layers × 1 sequences × 58 tokens × 512 dims\n",
      "9 layers × 1 sequences × 59 tokens × 512 dims\n",
      "9 layers × 1 sequences × 60 tokens × 512 dims\n",
      "9 layers × 1 sequences × 61 tokens × 512 dims\n",
      "9 layers × 1 sequences × 62 tokens × 512 dims\n",
      "9 layers × 1 sequences × 63 tokens × 512 dims\n",
      "9 layers × 1 sequences × 64 tokens × 512 dims\n",
      "9 layers × 1 sequences × 65 tokens × 512 dims\n",
      "9 layers × 1 sequences × 66 tokens × 512 dims\n",
      "9 layers × 1 sequences × 67 tokens × 512 dims\n",
      "9 layers × 1 sequences × 68 tokens × 512 dims\n",
      "9 layers × 1 sequences × 69 tokens × 512 dims\n",
      "9 layers × 1 sequences × 70 tokens × 512 dims\n",
      "9 layers × 1 sequences × 71 tokens × 512 dims\n",
      "9 layers × 1 sequences × 72 tokens × 512 dims\n",
      "9 layers × 1 sequences × 73 tokens × 512 dims\n",
      "9 layers × 1 sequences × 74 tokens × 512 dims\n",
      "9 layers × 1 sequences × 75 tokens × 512 dims\n",
      "9 layers × 1 sequences × 76 tokens × 512 dims\n",
      "9 layers × 1 sequences × 77 tokens × 512 dims\n",
      "9 layers × 1 sequences × 78 tokens × 512 dims\n",
      "9 layers × 1 sequences × 79 tokens × 512 dims\n",
      "9 layers × 1 sequences × 80 tokens × 512 dims\n",
      "9 layers × 1 sequences × 81 tokens × 512 dims\n",
      "9 layers × 1 sequences × 82 tokens × 512 dims\n",
      "9 layers × 1 sequences × 83 tokens × 512 dims\n",
      "9 layers × 1 sequences × 84 tokens × 512 dims\n",
      "9 layers × 1 sequences × 85 tokens × 512 dims\n",
      "9 layers × 1 sequences × 86 tokens × 512 dims\n",
      "9 layers × 1 sequences × 87 tokens × 512 dims\n",
      "9 layers × 1 sequences × 88 tokens × 512 dims\n",
      "9 layers × 1 sequences × 89 tokens × 512 dims\n",
      "9 layers × 1 sequences × 90 tokens × 512 dims\n",
      "9 layers × 1 sequences × 91 tokens × 512 dims\n",
      "9 layers × 1 sequences × 92 tokens × 512 dims\n",
      "9 layers × 1 sequences × 93 tokens × 512 dims\n",
      "9 layers × 1 sequences × 94 tokens × 512 dims\n",
      "9 layers × 1 sequences × 95 tokens × 512 dims\n",
      "9 layers × 1 sequences × 96 tokens × 512 dims\n",
      "9 layers × 1 sequences × 97 tokens × 512 dims\n",
      "9 layers × 1 sequences × 98 tokens × 512 dims\n",
      "9 layers × 1 sequences × 99 tokens × 512 dims\n",
      "9 layers × 1 sequences × 100 tokens × 512 dims\n",
      "9 layers × 1 sequences × 101 tokens × 512 dims\n",
      "9 layers × 1 sequences × 102 tokens × 512 dims\n",
      "9 layers × 1 sequences × 103 tokens × 512 dims\n",
      "9 layers × 1 sequences × 104 tokens × 512 dims\n",
      "9 layers × 1 sequences × 105 tokens × 512 dims\n",
      "9 layers × 1 sequences × 106 tokens × 512 dims\n",
      "9 layers × 1 sequences × 107 tokens × 512 dims\n",
      "9 layers × 1 sequences × 108 tokens × 512 dims\n",
      "9 layers × 1 sequences × 109 tokens × 512 dims\n",
      "9 layers × 1 sequences × 110 tokens × 512 dims\n",
      "9 layers × 1 sequences × 111 tokens × 512 dims\n",
      "9 layers × 1 sequences × 112 tokens × 512 dims\n",
      "9 layers × 1 sequences × 113 tokens × 512 dims\n",
      "9 layers × 1 sequences × 114 tokens × 512 dims\n",
      "9 layers × 1 sequences × 115 tokens × 512 dims\n",
      "9 layers × 1 sequences × 116 tokens × 512 dims\n",
      "9 layers × 1 sequences × 117 tokens × 512 dims\n",
      "9 layers × 1 sequences × 118 tokens × 512 dims\n",
      "9 layers × 1 sequences × 119 tokens × 512 dims\n",
      "9 layers × 1 sequences × 120 tokens × 512 dims\n",
      "9 layers × 1 sequences × 121 tokens × 512 dims\n",
      "9 layers × 1 sequences × 122 tokens × 512 dims\n",
      "9 layers × 1 sequences × 123 tokens × 512 dims\n",
      "9 layers × 1 sequences × 124 tokens × 512 dims\n",
      "9 layers × 1 sequences × 125 tokens × 512 dims\n",
      "9 layers × 1 sequences × 126 tokens × 512 dims\n",
      "9 layers × 1 sequences × 127 tokens × 512 dims\n",
      "9 layers × 1 sequences × 128 tokens × 512 dims\n",
      "9 layers × 1 sequences × 129 tokens × 512 dims\n",
      "9 layers × 1 sequences × 130 tokens × 512 dims\n",
      "9 layers × 1 sequences × 131 tokens × 512 dims\n",
      "9 layers × 1 sequences × 132 tokens × 512 dims\n",
      "9 layers × 1 sequences × 133 tokens × 512 dims\n",
      "9 layers × 1 sequences × 134 tokens × 512 dims\n",
      "9 layers × 1 sequences × 135 tokens × 512 dims\n",
      "9 layers × 1 sequences × 136 tokens × 512 dims\n",
      "9 layers × 1 sequences × 137 tokens × 512 dims\n",
      "9 layers × 1 sequences × 138 tokens × 512 dims\n",
      "9 layers × 1 sequences × 139 tokens × 512 dims\n",
      "9 layers × 1 sequences × 140 tokens × 512 dims\n",
      "9 layers × 1 sequences × 141 tokens × 512 dims\n",
      "9 layers × 1 sequences × 142 tokens × 512 dims\n",
      "9 layers × 1 sequences × 143 tokens × 512 dims\n",
      "9 layers × 1 sequences × 144 tokens × 512 dims\n",
      "9 layers × 1 sequences × 145 tokens × 512 dims\n",
      "9 layers × 1 sequences × 146 tokens × 512 dims\n",
      "9 layers × 1 sequences × 147 tokens × 512 dims\n",
      "9 layers × 1 sequences × 148 tokens × 512 dims\n",
      "9 layers × 1 sequences × 149 tokens × 512 dims\n",
      "9 layers × 1 sequences × 150 tokens × 512 dims\n",
      "9 layers × 1 sequences × 151 tokens × 512 dims\n",
      "9 layers × 1 sequences × 152 tokens × 512 dims\n",
      "9 layers × 1 sequences × 153 tokens × 512 dims\n",
      "9 layers × 1 sequences × 154 tokens × 512 dims\n",
      "9 layers × 1 sequences × 155 tokens × 512 dims\n",
      "9 layers × 1 sequences × 156 tokens × 512 dims\n",
      "9 layers × 1 sequences × 157 tokens × 512 dims\n",
      "9 layers × 1 sequences × 158 tokens × 512 dims\n",
      "9 layers × 1 sequences × 159 tokens × 512 dims\n",
      "9 layers × 1 sequences × 160 tokens × 512 dims\n",
      "9 layers × 1 sequences × 161 tokens × 512 dims\n",
      "9 layers × 1 sequences × 162 tokens × 512 dims\n",
      "9 layers × 1 sequences × 163 tokens × 512 dims\n",
      "9 layers × 1 sequences × 164 tokens × 512 dims\n",
      "9 layers × 1 sequences × 165 tokens × 512 dims\n",
      "9 layers × 1 sequences × 166 tokens × 512 dims\n",
      "9 layers × 1 sequences × 167 tokens × 512 dims\n",
      "9 layers × 1 sequences × 168 tokens × 512 dims\n",
      "9 layers × 1 sequences × 169 tokens × 512 dims\n",
      "9 layers × 1 sequences × 170 tokens × 512 dims\n",
      "9 layers × 1 sequences × 171 tokens × 512 dims\n",
      "9 layers × 1 sequences × 172 tokens × 512 dims\n",
      "9 layers × 1 sequences × 173 tokens × 512 dims\n",
      "9 layers × 1 sequences × 174 tokens × 512 dims\n",
      "9 layers × 1 sequences × 175 tokens × 512 dims\n",
      "9 layers × 1 sequences × 176 tokens × 512 dims\n",
      "9 layers × 1 sequences × 177 tokens × 512 dims\n",
      "9 layers × 1 sequences × 178 tokens × 512 dims\n",
      "9 layers × 1 sequences × 179 tokens × 512 dims\n",
      "9 layers × 1 sequences × 180 tokens × 512 dims\n",
      "9 layers × 1 sequences × 181 tokens × 512 dims\n",
      "9 layers × 1 sequences × 182 tokens × 512 dims\n",
      "9 layers × 1 sequences × 183 tokens × 512 dims\n",
      "9 layers × 1 sequences × 184 tokens × 512 dims\n",
      "9 layers × 1 sequences × 185 tokens × 512 dims\n",
      "9 layers × 1 sequences × 186 tokens × 512 dims\n",
      "9 layers × 1 sequences × 187 tokens × 512 dims\n",
      "9 layers × 1 sequences × 188 tokens × 512 dims\n",
      "9 layers × 1 sequences × 189 tokens × 512 dims\n",
      "9 layers × 1 sequences × 190 tokens × 512 dims\n",
      "9 layers × 1 sequences × 191 tokens × 512 dims\n",
      "9 layers × 1 sequences × 192 tokens × 512 dims\n",
      "9 layers × 1 sequences × 193 tokens × 512 dims\n",
      "9 layers × 1 sequences × 194 tokens × 512 dims\n",
      "9 layers × 1 sequences × 195 tokens × 512 dims\n",
      "9 layers × 1 sequences × 196 tokens × 512 dims\n",
      "9 layers × 1 sequences × 197 tokens × 512 dims\n",
      "9 layers × 1 sequences × 198 tokens × 512 dims\n",
      "9 layers × 1 sequences × 199 tokens × 512 dims\n",
      "9 layers × 1 sequences × 200 tokens × 512 dims\n",
      "9 layers × 1 sequences × 201 tokens × 512 dims\n",
      "9 layers × 1 sequences × 202 tokens × 512 dims\n",
      "9 layers × 1 sequences × 203 tokens × 512 dims\n",
      "9 layers × 1 sequences × 204 tokens × 512 dims\n",
      "9 layers × 1 sequences × 205 tokens × 512 dims\n",
      "9 layers × 1 sequences × 206 tokens × 512 dims\n",
      "9 layers × 1 sequences × 207 tokens × 512 dims\n",
      "9 layers × 1 sequences × 208 tokens × 512 dims\n",
      "9 layers × 1 sequences × 209 tokens × 512 dims\n",
      "9 layers × 1 sequences × 210 tokens × 512 dims\n",
      "9 layers × 1 sequences × 211 tokens × 512 dims\n",
      "9 layers × 1 sequences × 212 tokens × 512 dims\n",
      "9 layers × 1 sequences × 213 tokens × 512 dims\n",
      "9 layers × 1 sequences × 214 tokens × 512 dims\n",
      "9 layers × 1 sequences × 215 tokens × 512 dims\n",
      "9 layers × 1 sequences × 216 tokens × 512 dims\n",
      "9 layers × 1 sequences × 217 tokens × 512 dims\n",
      "9 layers × 1 sequences × 218 tokens × 512 dims\n",
      "9 layers × 1 sequences × 219 tokens × 512 dims\n",
      "9 layers × 1 sequences × 220 tokens × 512 dims\n",
      "9 layers × 1 sequences × 221 tokens × 512 dims\n",
      "9 layers × 1 sequences × 222 tokens × 512 dims\n",
      "9 layers × 1 sequences × 223 tokens × 512 dims\n",
      "9 layers × 1 sequences × 224 tokens × 512 dims\n",
      "9 layers × 1 sequences × 225 tokens × 512 dims\n",
      "9 layers × 1 sequences × 226 tokens × 512 dims\n",
      "9 layers × 1 sequences × 227 tokens × 512 dims\n",
      "9 layers × 1 sequences × 228 tokens × 512 dims\n",
      "9 layers × 1 sequences × 229 tokens × 512 dims\n",
      "9 layers × 1 sequences × 230 tokens × 512 dims\n",
      "9 layers × 1 sequences × 231 tokens × 512 dims\n",
      "9 layers × 1 sequences × 232 tokens × 512 dims\n",
      "9 layers × 1 sequences × 233 tokens × 512 dims\n",
      "9 layers × 1 sequences × 234 tokens × 512 dims\n",
      "9 layers × 1 sequences × 235 tokens × 512 dims\n",
      "9 layers × 1 sequences × 236 tokens × 512 dims\n",
      "9 layers × 1 sequences × 237 tokens × 512 dims\n",
      "9 layers × 1 sequences × 238 tokens × 512 dims\n",
      "9 layers × 1 sequences × 239 tokens × 512 dims\n",
      "9 layers × 1 sequences × 240 tokens × 512 dims\n",
      "9 layers × 1 sequences × 241 tokens × 512 dims\n",
      "9 layers × 1 sequences × 242 tokens × 512 dims\n",
      "9 layers × 1 sequences × 243 tokens × 512 dims\n",
      "9 layers × 1 sequences × 244 tokens × 512 dims\n",
      "9 layers × 1 sequences × 245 tokens × 512 dims\n",
      "9 layers × 1 sequences × 246 tokens × 512 dims\n",
      "9 layers × 1 sequences × 247 tokens × 512 dims\n",
      "9 layers × 1 sequences × 248 tokens × 512 dims\n",
      "9 layers × 1 sequences × 249 tokens × 512 dims\n",
      "9 layers × 1 sequences × 250 tokens × 512 dims\n",
      "9 layers × 1 sequences × 251 tokens × 512 dims\n",
      "9 layers × 1 sequences × 252 tokens × 512 dims\n",
      "9 layers × 1 sequences × 253 tokens × 512 dims\n",
      "9 layers × 1 sequences × 254 tokens × 512 dims\n",
      "9 layers × 1 sequences × 255 tokens × 512 dims\n",
      "9 layers × 1 sequences × 256 tokens × 512 dims\n",
      "9 layers × 1 sequences × 257 tokens × 512 dims\n",
      "9 layers × 1 sequences × 258 tokens × 512 dims\n",
      "9 layers × 1 sequences × 259 tokens × 512 dims\n",
      "9 layers × 1 sequences × 260 tokens × 512 dims\n",
      "9 layers × 1 sequences × 261 tokens × 512 dims\n",
      "9 layers × 1 sequences × 262 tokens × 512 dims\n",
      "9 layers × 1 sequences × 263 tokens × 512 dims\n",
      "9 layers × 1 sequences × 264 tokens × 512 dims\n",
      "9 layers × 1 sequences × 265 tokens × 512 dims\n",
      "9 layers × 1 sequences × 266 tokens × 512 dims\n",
      "9 layers × 1 sequences × 267 tokens × 512 dims\n",
      "9 layers × 1 sequences × 268 tokens × 512 dims\n",
      "9 layers × 1 sequences × 269 tokens × 512 dims\n",
      "9 layers × 1 sequences × 270 tokens × 512 dims\n",
      "9 layers × 1 sequences × 271 tokens × 512 dims\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                 | 2/1000 [00:04<34:30,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 512])\n",
      "Hidden states shape: 266 generated tokens × 9 layers × 1 sequences × 9 tokens × 512 dims\n",
      "3053.3718\n",
      "3084.9817\n",
      "3162.695\n",
      "3209.57\n",
      "3245.1594\n",
      "3308.5852\n",
      "3339.002\n",
      "3376.4055\n",
      "3407.385\n",
      "3433.5278\n",
      "3467.8738\n",
      "3509.7734\n",
      "3554.0366\n",
      "3587.3052\n",
      "3614.9897\n",
      "3638.2275\n",
      "3663.7222\n",
      "3687.9421\n",
      "3718.2493\n",
      "3746.8508\n",
      "3769.3975\n",
      "3799.533\n",
      "3827.0156\n",
      "3854.8447\n",
      "3884.5405\n",
      "3923.6511\n",
      "3949.67\n",
      "3978.7317\n",
      "4002.0762\n",
      "4028.5505\n",
      "4058.5583\n",
      "4084.4858\n",
      "4105.7007\n",
      "4131.026\n",
      "4156.4634\n",
      "4182.852\n",
      "4208.631\n",
      "4238.416\n",
      "4270.171\n",
      "4296.577\n",
      "4322.2026\n",
      "4345.0664\n",
      "4367.879\n",
      "4392.205\n",
      "4418.022\n",
      "4440.5347\n",
      "4459.6455\n",
      "4484.522\n",
      "4507.443\n",
      "4529.0825\n",
      "4552.2886\n",
      "4576.919\n",
      "4596.5005\n",
      "4619.138\n",
      "4642.4585\n",
      "4673.472\n",
      "4694.5625\n",
      "4717.0854\n",
      "4738.962\n",
      "4762.275\n",
      "4782.666\n",
      "4804.354\n",
      "4830.5254\n",
      "4853.838\n",
      "4877.42\n",
      "4901.7407\n",
      "4922.7837\n",
      "4942.674\n",
      "4961.7134\n",
      "4986.156\n",
      "5006.023\n",
      "5028.996\n",
      "5045.7485\n",
      "5062.5576\n",
      "5080.734\n",
      "5101.058\n",
      "5126.545\n",
      "5148.3564\n",
      "5166.5303\n",
      "5203.4175\n",
      "5222.1055\n",
      "5239.52\n",
      "5259.7563\n",
      "5279.5225\n",
      "5296.346\n",
      "5314.228\n",
      "5334.584\n",
      "5352.3135\n",
      "5369.8867\n",
      "5390.8525\n",
      "5409.5693\n",
      "5440.2803\n",
      "5457.527\n",
      "5474.979\n",
      "5496.852\n",
      "5517.9966\n",
      "5536.5166\n",
      "5557.098\n",
      "5576.4595\n",
      "5597.426\n",
      "5618.297\n",
      "5636.8384\n",
      "5654.067\n",
      "5671.561\n",
      "5703.5483\n",
      "5719.283\n",
      "5752.0767\n",
      "5771.6562\n",
      "5793.505\n",
      "5809.203\n",
      "5825.1426\n",
      "5841.9316\n",
      "5858.1396\n",
      "5877.535\n",
      "5893.8057\n",
      "5912.7593\n",
      "5927.691\n",
      "5944.8315\n",
      "5975.725\n",
      "5989.919\n",
      "6016.2256\n",
      "6039.809\n",
      "6058.796\n",
      "6073.4546\n",
      "6090.7275\n",
      "6105.031\n",
      "6119.346\n",
      "6142.5176\n",
      "6164.345\n",
      "6180.5996\n",
      "6194.1357\n",
      "6213.98\n",
      "6227.981\n",
      "6243.151\n",
      "6259.719\n",
      "6276.098\n",
      "6293.1597\n",
      "6309.7607\n",
      "6325.732\n",
      "6337.984\n",
      "6363.673\n",
      "6376.2915\n",
      "6390.4336\n",
      "6404.239\n",
      "6416.1445\n",
      "6428.334\n",
      "6441.277\n",
      "6453.9824\n",
      "6468.995\n",
      "6481.3403\n",
      "6495.8916\n",
      "6510.7725\n",
      "6524.6226\n",
      "6537.6387\n",
      "6561.8867\n",
      "6575.9697\n",
      "6587.5312\n",
      "6599.2437\n",
      "6613.7114\n",
      "6633.522\n",
      "6649.853\n",
      "6664.2827\n",
      "6679.9526\n",
      "6694.511\n",
      "6709.588\n",
      "6723.36\n",
      "6734.3213\n",
      "6747.5513\n",
      "6762.91\n",
      "6777.2305\n",
      "6791.441\n",
      "6804.647\n",
      "6818.807\n",
      "6833.5986\n",
      "6848.6963\n",
      "6873.586\n",
      "6885.9277\n",
      "6899.7285\n",
      "6918.2563\n",
      "6934.5767\n",
      "6945.1255\n",
      "6959.1724\n",
      "6972.373\n",
      "6989.177\n",
      "7007.196\n",
      "7021.5806\n",
      "7034.8926\n",
      "7047.7017\n",
      "7062.027\n",
      "7076.889\n",
      "7090.536\n",
      "7107.3623\n",
      "7127.001\n",
      "7138.91\n",
      "7151.233\n",
      "7163.548\n",
      "7176.8623\n",
      "7194.9097\n",
      "7213.74\n",
      "7226.234\n",
      "7241.3774\n",
      "7254.343\n",
      "7267.493\n",
      "7283.1367\n",
      "7298.8003\n",
      "7315.737\n",
      "7332.526\n",
      "7347.589\n",
      "7362.3213\n",
      "7379.248\n",
      "7389.5757\n",
      "7401.2075\n",
      "7415.5522\n",
      "7427.968\n",
      "7440.911\n",
      "7455.0337\n",
      "7467.083\n",
      "7478.414\n",
      "7491.077\n",
      "7501.7476\n",
      "7513.342\n",
      "7532.426\n",
      "7546.4556\n",
      "7559.6484\n",
      "7573.028\n",
      "7583.2524\n",
      "7594.667\n",
      "7608.8926\n",
      "7620.3647\n",
      "7632.874\n",
      "7644.8115\n",
      "7659.131\n",
      "7671.0083\n",
      "7684.42\n",
      "7695.3467\n",
      "7708.3145\n",
      "7720.266\n",
      "7733.4487\n",
      "7747.314\n",
      "7761.1685\n",
      "7775.6523\n",
      "7786.2817\n",
      "7797.5117\n",
      "7808.2847\n",
      "7819.6826\n",
      "7835.2554\n",
      "7852.4316\n",
      "7862.6396\n",
      "7876.359\n",
      "7891.6685\n",
      "7915.8145\n",
      "7928.501\n",
      "7942.1123\n",
      "7951.777\n",
      "7972.7427\n",
      "7981.604\n",
      "7993.1216\n",
      "8005.084\n",
      "8016.8765\n",
      "8027.6626\n",
      "8039.6333\n",
      "8048.9526\n",
      "8062.696\n",
      "8073.684\n",
      "8086.8286\n",
      "8096.149\n",
      "9 layers × 1 sequences × 9 tokens × 512 dims\n",
      "9 layers × 1 sequences × 10 tokens × 512 dims\n",
      "9 layers × 1 sequences × 11 tokens × 512 dims\n",
      "9 layers × 1 sequences × 12 tokens × 512 dims\n",
      "9 layers × 1 sequences × 13 tokens × 512 dims\n",
      "9 layers × 1 sequences × 14 tokens × 512 dims\n",
      "9 layers × 1 sequences × 15 tokens × 512 dims\n",
      "9 layers × 1 sequences × 16 tokens × 512 dims\n",
      "9 layers × 1 sequences × 17 tokens × 512 dims\n",
      "9 layers × 1 sequences × 18 tokens × 512 dims\n",
      "9 layers × 1 sequences × 19 tokens × 512 dims\n",
      "9 layers × 1 sequences × 20 tokens × 512 dims\n",
      "9 layers × 1 sequences × 21 tokens × 512 dims\n",
      "9 layers × 1 sequences × 22 tokens × 512 dims\n",
      "9 layers × 1 sequences × 23 tokens × 512 dims\n",
      "9 layers × 1 sequences × 24 tokens × 512 dims\n",
      "9 layers × 1 sequences × 25 tokens × 512 dims\n",
      "9 layers × 1 sequences × 26 tokens × 512 dims\n",
      "9 layers × 1 sequences × 27 tokens × 512 dims\n",
      "9 layers × 1 sequences × 28 tokens × 512 dims\n",
      "9 layers × 1 sequences × 29 tokens × 512 dims\n",
      "9 layers × 1 sequences × 30 tokens × 512 dims\n",
      "9 layers × 1 sequences × 31 tokens × 512 dims\n",
      "9 layers × 1 sequences × 32 tokens × 512 dims\n",
      "9 layers × 1 sequences × 33 tokens × 512 dims\n",
      "9 layers × 1 sequences × 34 tokens × 512 dims\n",
      "9 layers × 1 sequences × 35 tokens × 512 dims\n",
      "9 layers × 1 sequences × 36 tokens × 512 dims\n",
      "9 layers × 1 sequences × 37 tokens × 512 dims\n",
      "9 layers × 1 sequences × 38 tokens × 512 dims\n",
      "9 layers × 1 sequences × 39 tokens × 512 dims\n",
      "9 layers × 1 sequences × 40 tokens × 512 dims\n",
      "9 layers × 1 sequences × 41 tokens × 512 dims\n",
      "9 layers × 1 sequences × 42 tokens × 512 dims\n",
      "9 layers × 1 sequences × 43 tokens × 512 dims\n",
      "9 layers × 1 sequences × 44 tokens × 512 dims\n",
      "9 layers × 1 sequences × 45 tokens × 512 dims\n",
      "9 layers × 1 sequences × 46 tokens × 512 dims\n",
      "9 layers × 1 sequences × 47 tokens × 512 dims\n",
      "9 layers × 1 sequences × 48 tokens × 512 dims\n",
      "9 layers × 1 sequences × 49 tokens × 512 dims\n",
      "9 layers × 1 sequences × 50 tokens × 512 dims\n",
      "9 layers × 1 sequences × 51 tokens × 512 dims\n",
      "9 layers × 1 sequences × 52 tokens × 512 dims\n",
      "9 layers × 1 sequences × 53 tokens × 512 dims\n",
      "9 layers × 1 sequences × 54 tokens × 512 dims\n",
      "9 layers × 1 sequences × 55 tokens × 512 dims\n",
      "9 layers × 1 sequences × 56 tokens × 512 dims\n",
      "9 layers × 1 sequences × 57 tokens × 512 dims\n",
      "9 layers × 1 sequences × 58 tokens × 512 dims\n",
      "9 layers × 1 sequences × 59 tokens × 512 dims\n",
      "9 layers × 1 sequences × 60 tokens × 512 dims\n",
      "9 layers × 1 sequences × 61 tokens × 512 dims\n",
      "9 layers × 1 sequences × 62 tokens × 512 dims\n",
      "9 layers × 1 sequences × 63 tokens × 512 dims\n",
      "9 layers × 1 sequences × 64 tokens × 512 dims\n",
      "9 layers × 1 sequences × 65 tokens × 512 dims\n",
      "9 layers × 1 sequences × 66 tokens × 512 dims\n",
      "9 layers × 1 sequences × 67 tokens × 512 dims\n",
      "9 layers × 1 sequences × 68 tokens × 512 dims\n",
      "9 layers × 1 sequences × 69 tokens × 512 dims\n",
      "9 layers × 1 sequences × 70 tokens × 512 dims\n",
      "9 layers × 1 sequences × 71 tokens × 512 dims\n",
      "9 layers × 1 sequences × 72 tokens × 512 dims\n",
      "9 layers × 1 sequences × 73 tokens × 512 dims\n",
      "9 layers × 1 sequences × 74 tokens × 512 dims\n",
      "9 layers × 1 sequences × 75 tokens × 512 dims\n",
      "9 layers × 1 sequences × 76 tokens × 512 dims\n",
      "9 layers × 1 sequences × 77 tokens × 512 dims\n",
      "9 layers × 1 sequences × 78 tokens × 512 dims\n",
      "9 layers × 1 sequences × 79 tokens × 512 dims\n",
      "9 layers × 1 sequences × 80 tokens × 512 dims\n",
      "9 layers × 1 sequences × 81 tokens × 512 dims\n",
      "9 layers × 1 sequences × 82 tokens × 512 dims\n",
      "9 layers × 1 sequences × 83 tokens × 512 dims\n",
      "9 layers × 1 sequences × 84 tokens × 512 dims\n",
      "9 layers × 1 sequences × 85 tokens × 512 dims\n",
      "9 layers × 1 sequences × 86 tokens × 512 dims\n",
      "9 layers × 1 sequences × 87 tokens × 512 dims\n",
      "9 layers × 1 sequences × 88 tokens × 512 dims\n",
      "9 layers × 1 sequences × 89 tokens × 512 dims\n",
      "9 layers × 1 sequences × 90 tokens × 512 dims\n",
      "9 layers × 1 sequences × 91 tokens × 512 dims\n",
      "9 layers × 1 sequences × 92 tokens × 512 dims\n",
      "9 layers × 1 sequences × 93 tokens × 512 dims\n",
      "9 layers × 1 sequences × 94 tokens × 512 dims\n",
      "9 layers × 1 sequences × 95 tokens × 512 dims\n",
      "9 layers × 1 sequences × 96 tokens × 512 dims\n",
      "9 layers × 1 sequences × 97 tokens × 512 dims\n",
      "9 layers × 1 sequences × 98 tokens × 512 dims\n",
      "9 layers × 1 sequences × 99 tokens × 512 dims\n",
      "9 layers × 1 sequences × 100 tokens × 512 dims\n",
      "9 layers × 1 sequences × 101 tokens × 512 dims\n",
      "9 layers × 1 sequences × 102 tokens × 512 dims\n",
      "9 layers × 1 sequences × 103 tokens × 512 dims\n",
      "9 layers × 1 sequences × 104 tokens × 512 dims\n",
      "9 layers × 1 sequences × 105 tokens × 512 dims\n",
      "9 layers × 1 sequences × 106 tokens × 512 dims\n",
      "9 layers × 1 sequences × 107 tokens × 512 dims\n",
      "9 layers × 1 sequences × 108 tokens × 512 dims\n",
      "9 layers × 1 sequences × 109 tokens × 512 dims\n",
      "9 layers × 1 sequences × 110 tokens × 512 dims\n",
      "9 layers × 1 sequences × 111 tokens × 512 dims\n",
      "9 layers × 1 sequences × 112 tokens × 512 dims\n",
      "9 layers × 1 sequences × 113 tokens × 512 dims\n",
      "9 layers × 1 sequences × 114 tokens × 512 dims\n",
      "9 layers × 1 sequences × 115 tokens × 512 dims\n",
      "9 layers × 1 sequences × 116 tokens × 512 dims\n",
      "9 layers × 1 sequences × 117 tokens × 512 dims\n",
      "9 layers × 1 sequences × 118 tokens × 512 dims\n",
      "9 layers × 1 sequences × 119 tokens × 512 dims\n",
      "9 layers × 1 sequences × 120 tokens × 512 dims\n",
      "9 layers × 1 sequences × 121 tokens × 512 dims\n",
      "9 layers × 1 sequences × 122 tokens × 512 dims\n",
      "9 layers × 1 sequences × 123 tokens × 512 dims\n",
      "9 layers × 1 sequences × 124 tokens × 512 dims\n",
      "9 layers × 1 sequences × 125 tokens × 512 dims\n",
      "9 layers × 1 sequences × 126 tokens × 512 dims\n",
      "9 layers × 1 sequences × 127 tokens × 512 dims\n",
      "9 layers × 1 sequences × 128 tokens × 512 dims\n",
      "9 layers × 1 sequences × 129 tokens × 512 dims\n",
      "9 layers × 1 sequences × 130 tokens × 512 dims\n",
      "9 layers × 1 sequences × 131 tokens × 512 dims\n",
      "9 layers × 1 sequences × 132 tokens × 512 dims\n",
      "9 layers × 1 sequences × 133 tokens × 512 dims\n",
      "9 layers × 1 sequences × 134 tokens × 512 dims\n",
      "9 layers × 1 sequences × 135 tokens × 512 dims\n",
      "9 layers × 1 sequences × 136 tokens × 512 dims\n",
      "9 layers × 1 sequences × 137 tokens × 512 dims\n",
      "9 layers × 1 sequences × 138 tokens × 512 dims\n",
      "9 layers × 1 sequences × 139 tokens × 512 dims\n",
      "9 layers × 1 sequences × 140 tokens × 512 dims\n",
      "9 layers × 1 sequences × 141 tokens × 512 dims\n",
      "9 layers × 1 sequences × 142 tokens × 512 dims\n",
      "9 layers × 1 sequences × 143 tokens × 512 dims\n",
      "9 layers × 1 sequences × 144 tokens × 512 dims\n",
      "9 layers × 1 sequences × 145 tokens × 512 dims\n",
      "9 layers × 1 sequences × 146 tokens × 512 dims\n",
      "9 layers × 1 sequences × 147 tokens × 512 dims\n",
      "9 layers × 1 sequences × 148 tokens × 512 dims\n",
      "9 layers × 1 sequences × 149 tokens × 512 dims\n",
      "9 layers × 1 sequences × 150 tokens × 512 dims\n",
      "9 layers × 1 sequences × 151 tokens × 512 dims\n",
      "9 layers × 1 sequences × 152 tokens × 512 dims\n",
      "9 layers × 1 sequences × 153 tokens × 512 dims\n",
      "9 layers × 1 sequences × 154 tokens × 512 dims\n",
      "9 layers × 1 sequences × 155 tokens × 512 dims\n",
      "9 layers × 1 sequences × 156 tokens × 512 dims\n",
      "9 layers × 1 sequences × 157 tokens × 512 dims\n",
      "9 layers × 1 sequences × 158 tokens × 512 dims\n",
      "9 layers × 1 sequences × 159 tokens × 512 dims\n",
      "9 layers × 1 sequences × 160 tokens × 512 dims\n",
      "9 layers × 1 sequences × 161 tokens × 512 dims\n",
      "9 layers × 1 sequences × 162 tokens × 512 dims\n",
      "9 layers × 1 sequences × 163 tokens × 512 dims\n",
      "9 layers × 1 sequences × 164 tokens × 512 dims\n",
      "9 layers × 1 sequences × 165 tokens × 512 dims\n",
      "9 layers × 1 sequences × 166 tokens × 512 dims\n",
      "9 layers × 1 sequences × 167 tokens × 512 dims\n",
      "9 layers × 1 sequences × 168 tokens × 512 dims\n",
      "9 layers × 1 sequences × 169 tokens × 512 dims\n",
      "9 layers × 1 sequences × 170 tokens × 512 dims\n",
      "9 layers × 1 sequences × 171 tokens × 512 dims\n",
      "9 layers × 1 sequences × 172 tokens × 512 dims\n",
      "9 layers × 1 sequences × 173 tokens × 512 dims\n",
      "9 layers × 1 sequences × 174 tokens × 512 dims\n",
      "9 layers × 1 sequences × 175 tokens × 512 dims\n",
      "9 layers × 1 sequences × 176 tokens × 512 dims\n",
      "9 layers × 1 sequences × 177 tokens × 512 dims\n",
      "9 layers × 1 sequences × 178 tokens × 512 dims\n",
      "9 layers × 1 sequences × 179 tokens × 512 dims\n",
      "9 layers × 1 sequences × 180 tokens × 512 dims\n",
      "9 layers × 1 sequences × 181 tokens × 512 dims\n",
      "9 layers × 1 sequences × 182 tokens × 512 dims\n",
      "9 layers × 1 sequences × 183 tokens × 512 dims\n",
      "9 layers × 1 sequences × 184 tokens × 512 dims\n",
      "9 layers × 1 sequences × 185 tokens × 512 dims\n",
      "9 layers × 1 sequences × 186 tokens × 512 dims\n",
      "9 layers × 1 sequences × 187 tokens × 512 dims\n",
      "9 layers × 1 sequences × 188 tokens × 512 dims\n",
      "9 layers × 1 sequences × 189 tokens × 512 dims\n",
      "9 layers × 1 sequences × 190 tokens × 512 dims\n",
      "9 layers × 1 sequences × 191 tokens × 512 dims\n",
      "9 layers × 1 sequences × 192 tokens × 512 dims\n",
      "9 layers × 1 sequences × 193 tokens × 512 dims\n",
      "9 layers × 1 sequences × 194 tokens × 512 dims\n",
      "9 layers × 1 sequences × 195 tokens × 512 dims\n",
      "9 layers × 1 sequences × 196 tokens × 512 dims\n",
      "9 layers × 1 sequences × 197 tokens × 512 dims\n",
      "9 layers × 1 sequences × 198 tokens × 512 dims\n",
      "9 layers × 1 sequences × 199 tokens × 512 dims\n",
      "9 layers × 1 sequences × 200 tokens × 512 dims\n",
      "9 layers × 1 sequences × 201 tokens × 512 dims\n",
      "9 layers × 1 sequences × 202 tokens × 512 dims\n",
      "9 layers × 1 sequences × 203 tokens × 512 dims\n",
      "9 layers × 1 sequences × 204 tokens × 512 dims\n",
      "9 layers × 1 sequences × 205 tokens × 512 dims\n",
      "9 layers × 1 sequences × 206 tokens × 512 dims\n",
      "9 layers × 1 sequences × 207 tokens × 512 dims\n",
      "9 layers × 1 sequences × 208 tokens × 512 dims\n",
      "9 layers × 1 sequences × 209 tokens × 512 dims\n",
      "9 layers × 1 sequences × 210 tokens × 512 dims\n",
      "9 layers × 1 sequences × 211 tokens × 512 dims\n",
      "9 layers × 1 sequences × 212 tokens × 512 dims\n",
      "9 layers × 1 sequences × 213 tokens × 512 dims\n",
      "9 layers × 1 sequences × 214 tokens × 512 dims\n",
      "9 layers × 1 sequences × 215 tokens × 512 dims\n",
      "9 layers × 1 sequences × 216 tokens × 512 dims\n",
      "9 layers × 1 sequences × 217 tokens × 512 dims\n",
      "9 layers × 1 sequences × 218 tokens × 512 dims\n",
      "9 layers × 1 sequences × 219 tokens × 512 dims\n",
      "9 layers × 1 sequences × 220 tokens × 512 dims\n",
      "9 layers × 1 sequences × 221 tokens × 512 dims\n",
      "9 layers × 1 sequences × 222 tokens × 512 dims\n",
      "9 layers × 1 sequences × 223 tokens × 512 dims\n",
      "9 layers × 1 sequences × 224 tokens × 512 dims\n",
      "9 layers × 1 sequences × 225 tokens × 512 dims\n",
      "9 layers × 1 sequences × 226 tokens × 512 dims\n",
      "9 layers × 1 sequences × 227 tokens × 512 dims\n",
      "9 layers × 1 sequences × 228 tokens × 512 dims\n",
      "9 layers × 1 sequences × 229 tokens × 512 dims\n",
      "9 layers × 1 sequences × 230 tokens × 512 dims\n",
      "9 layers × 1 sequences × 231 tokens × 512 dims\n",
      "9 layers × 1 sequences × 232 tokens × 512 dims\n",
      "9 layers × 1 sequences × 233 tokens × 512 dims\n",
      "9 layers × 1 sequences × 234 tokens × 512 dims\n",
      "9 layers × 1 sequences × 235 tokens × 512 dims\n",
      "9 layers × 1 sequences × 236 tokens × 512 dims\n",
      "9 layers × 1 sequences × 237 tokens × 512 dims\n",
      "9 layers × 1 sequences × 238 tokens × 512 dims\n",
      "9 layers × 1 sequences × 239 tokens × 512 dims\n",
      "9 layers × 1 sequences × 240 tokens × 512 dims\n",
      "9 layers × 1 sequences × 241 tokens × 512 dims\n",
      "9 layers × 1 sequences × 242 tokens × 512 dims\n",
      "9 layers × 1 sequences × 243 tokens × 512 dims\n",
      "9 layers × 1 sequences × 244 tokens × 512 dims\n",
      "9 layers × 1 sequences × 245 tokens × 512 dims\n",
      "9 layers × 1 sequences × 246 tokens × 512 dims\n",
      "9 layers × 1 sequences × 247 tokens × 512 dims\n",
      "9 layers × 1 sequences × 248 tokens × 512 dims\n",
      "9 layers × 1 sequences × 249 tokens × 512 dims\n",
      "9 layers × 1 sequences × 250 tokens × 512 dims\n",
      "9 layers × 1 sequences × 251 tokens × 512 dims\n",
      "9 layers × 1 sequences × 252 tokens × 512 dims\n",
      "9 layers × 1 sequences × 253 tokens × 512 dims\n",
      "9 layers × 1 sequences × 254 tokens × 512 dims\n",
      "9 layers × 1 sequences × 255 tokens × 512 dims\n",
      "9 layers × 1 sequences × 256 tokens × 512 dims\n",
      "9 layers × 1 sequences × 257 tokens × 512 dims\n",
      "9 layers × 1 sequences × 258 tokens × 512 dims\n",
      "9 layers × 1 sequences × 259 tokens × 512 dims\n",
      "9 layers × 1 sequences × 260 tokens × 512 dims\n",
      "9 layers × 1 sequences × 261 tokens × 512 dims\n",
      "9 layers × 1 sequences × 262 tokens × 512 dims\n",
      "9 layers × 1 sequences × 263 tokens × 512 dims\n",
      "9 layers × 1 sequences × 264 tokens × 512 dims\n",
      "9 layers × 1 sequences × 265 tokens × 512 dims\n",
      "9 layers × 1 sequences × 266 tokens × 512 dims\n",
      "9 layers × 1 sequences × 267 tokens × 512 dims\n",
      "9 layers × 1 sequences × 268 tokens × 512 dims\n",
      "9 layers × 1 sequences × 269 tokens × 512 dims\n",
      "9 layers × 1 sequences × 270 tokens × 512 dims\n",
      "9 layers × 1 sequences × 271 tokens × 512 dims\n",
      "9 layers × 1 sequences × 272 tokens × 512 dims\n",
      "9 layers × 1 sequences × 273 tokens × 512 dims\n",
      "9 layers × 1 sequences × 274 tokens × 512 dims\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                 | 3/1000 [00:05<30:21,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 512])\n",
      "Hidden states shape: 204 generated tokens × 9 layers × 1 sequences × 9 tokens × 512 dims\n",
      "3053.3718\n",
      "3094.3384\n",
      "3135.8726\n",
      "3173.915\n",
      "3218.2703\n",
      "3251.4375\n",
      "3293.0483\n",
      "3326.848\n",
      "3356.2063\n",
      "3384.368\n",
      "3412.8853\n",
      "3441.429\n",
      "3473.3438\n",
      "3497.2078\n",
      "3525.0715\n",
      "3551.7527\n",
      "3585.8325\n",
      "3628.6038\n",
      "3648.4036\n",
      "3670.772\n",
      "3699.4575\n",
      "3729.054\n",
      "3754.7102\n",
      "3780.9346\n",
      "3814.5903\n",
      "3851.502\n",
      "3876.7834\n",
      "3911.9404\n",
      "3942.3826\n",
      "3971.4307\n",
      "3996.7178\n",
      "4020.0205\n",
      "4044.272\n",
      "4067.0764\n",
      "4093.7175\n",
      "4140.015\n",
      "4166.7773\n",
      "4191.1147\n",
      "4224.1\n",
      "4272.9834\n",
      "4304.8584\n",
      "4326.267\n",
      "4346.816\n",
      "4374.379\n",
      "4399.142\n",
      "4423.176\n",
      "4451.3643\n",
      "4473.34\n",
      "4501.5747\n",
      "4526.7017\n",
      "4555.4517\n",
      "4579.4897\n",
      "4600.7812\n",
      "4622.114\n",
      "4640.894\n",
      "4662.201\n",
      "4684.391\n",
      "4704.2627\n",
      "4726.5137\n",
      "4752.74\n",
      "4774.3066\n",
      "4796.685\n",
      "4814.4565\n",
      "4833.0195\n",
      "4857.6997\n",
      "4879.4004\n",
      "4905.841\n",
      "4937.4717\n",
      "4956.5176\n",
      "4975.0107\n",
      "5000.6064\n",
      "5023.722\n",
      "5047.782\n",
      "5075.606\n",
      "5106.9155\n",
      "5123.4785\n",
      "5141.8325\n",
      "5163.687\n",
      "5183.208\n",
      "5201.716\n",
      "5222.6636\n",
      "5249.0674\n",
      "5268.402\n",
      "5286.0215\n",
      "5326.5527\n",
      "5344.173\n",
      "5360.341\n",
      "5379.605\n",
      "5396.7183\n",
      "5416.225\n",
      "5437.233\n",
      "5462.1113\n",
      "5479.2393\n",
      "5498.376\n",
      "5521.957\n",
      "5552.4463\n",
      "5574.2583\n",
      "5598.7295\n",
      "5621.63\n",
      "5638.6494\n",
      "5659.6934\n",
      "5678.241\n",
      "5695.847\n",
      "5714.4614\n",
      "5739.3906\n",
      "5755.002\n",
      "5771.858\n",
      "5792.6006\n",
      "5811.0493\n",
      "5844.004\n",
      "5864.752\n",
      "5887.0845\n",
      "5902.439\n",
      "5921.412\n",
      "5942.2227\n",
      "5957.3564\n",
      "5977.023\n",
      "5997.97\n",
      "6018.5977\n",
      "6036.261\n",
      "6051.762\n",
      "6068.411\n",
      "6091.3745\n",
      "6114.028\n",
      "6130.8003\n",
      "6148.568\n",
      "6170.015\n",
      "6193.0684\n",
      "6216.2607\n",
      "6230.572\n",
      "6248.399\n",
      "6263.0728\n",
      "6277.2437\n",
      "6293.228\n",
      "6311.738\n",
      "6329.08\n",
      "6345.313\n",
      "6363.236\n",
      "6381.161\n",
      "6406.3594\n",
      "6428.2954\n",
      "6440.873\n",
      "6454.078\n",
      "6470.075\n",
      "6486.7007\n",
      "6501.1\n",
      "6512.5435\n",
      "6526.2627\n",
      "6538.6006\n",
      "6552.5293\n",
      "6567.6494\n",
      "6592.407\n",
      "6609.687\n",
      "6625.9043\n",
      "6644.728\n",
      "6657.3843\n",
      "6669.438\n",
      "6684.8833\n",
      "6700.222\n",
      "6714.5093\n",
      "6727.156\n",
      "6742.017\n",
      "6757.05\n",
      "6768.0005\n",
      "6779.8193\n",
      "6794.4775\n",
      "6809.2046\n",
      "6822.5127\n",
      "6836.8096\n",
      "6850.311\n",
      "6873.1084\n",
      "6888.5127\n",
      "6898.9917\n",
      "6911.6616\n",
      "6933.8286\n",
      "6947.3457\n",
      "6962.1304\n",
      "6981.4326\n",
      "6992.568\n",
      "7005.0176\n",
      "7016.889\n",
      "7029.464\n",
      "7042.9375\n",
      "7055.783\n",
      "7072.6177\n",
      "7083.4746\n",
      "7094.682\n",
      "7110.721\n",
      "7125.079\n",
      "7138.143\n",
      "7154.5063\n",
      "7168.122\n",
      "7185.185\n",
      "7195.979\n",
      "7208.57\n",
      "7224.2466\n",
      "7236.1323\n",
      "7249.986\n",
      "7264.4126\n",
      "7277.2954\n",
      "7292.8823\n",
      "7306.999\n",
      "7321.6436\n",
      "7332.7065\n",
      "9 layers × 1 sequences × 9 tokens × 512 dims\n",
      "9 layers × 1 sequences × 10 tokens × 512 dims\n",
      "9 layers × 1 sequences × 11 tokens × 512 dims\n",
      "9 layers × 1 sequences × 12 tokens × 512 dims\n",
      "9 layers × 1 sequences × 13 tokens × 512 dims\n",
      "9 layers × 1 sequences × 14 tokens × 512 dims\n",
      "9 layers × 1 sequences × 15 tokens × 512 dims\n",
      "9 layers × 1 sequences × 16 tokens × 512 dims\n",
      "9 layers × 1 sequences × 17 tokens × 512 dims\n",
      "9 layers × 1 sequences × 18 tokens × 512 dims\n",
      "9 layers × 1 sequences × 19 tokens × 512 dims\n",
      "9 layers × 1 sequences × 20 tokens × 512 dims\n",
      "9 layers × 1 sequences × 21 tokens × 512 dims\n",
      "9 layers × 1 sequences × 22 tokens × 512 dims\n",
      "9 layers × 1 sequences × 23 tokens × 512 dims\n",
      "9 layers × 1 sequences × 24 tokens × 512 dims\n",
      "9 layers × 1 sequences × 25 tokens × 512 dims\n",
      "9 layers × 1 sequences × 26 tokens × 512 dims\n",
      "9 layers × 1 sequences × 27 tokens × 512 dims\n",
      "9 layers × 1 sequences × 28 tokens × 512 dims\n",
      "9 layers × 1 sequences × 29 tokens × 512 dims\n",
      "9 layers × 1 sequences × 30 tokens × 512 dims\n",
      "9 layers × 1 sequences × 31 tokens × 512 dims\n",
      "9 layers × 1 sequences × 32 tokens × 512 dims\n",
      "9 layers × 1 sequences × 33 tokens × 512 dims\n",
      "9 layers × 1 sequences × 34 tokens × 512 dims\n",
      "9 layers × 1 sequences × 35 tokens × 512 dims\n",
      "9 layers × 1 sequences × 36 tokens × 512 dims\n",
      "9 layers × 1 sequences × 37 tokens × 512 dims\n",
      "9 layers × 1 sequences × 38 tokens × 512 dims\n",
      "9 layers × 1 sequences × 39 tokens × 512 dims\n",
      "9 layers × 1 sequences × 40 tokens × 512 dims\n",
      "9 layers × 1 sequences × 41 tokens × 512 dims\n",
      "9 layers × 1 sequences × 42 tokens × 512 dims\n",
      "9 layers × 1 sequences × 43 tokens × 512 dims\n",
      "9 layers × 1 sequences × 44 tokens × 512 dims\n",
      "9 layers × 1 sequences × 45 tokens × 512 dims\n",
      "9 layers × 1 sequences × 46 tokens × 512 dims\n",
      "9 layers × 1 sequences × 47 tokens × 512 dims\n",
      "9 layers × 1 sequences × 48 tokens × 512 dims\n",
      "9 layers × 1 sequences × 49 tokens × 512 dims\n",
      "9 layers × 1 sequences × 50 tokens × 512 dims\n",
      "9 layers × 1 sequences × 51 tokens × 512 dims\n",
      "9 layers × 1 sequences × 52 tokens × 512 dims\n",
      "9 layers × 1 sequences × 53 tokens × 512 dims\n",
      "9 layers × 1 sequences × 54 tokens × 512 dims\n",
      "9 layers × 1 sequences × 55 tokens × 512 dims\n",
      "9 layers × 1 sequences × 56 tokens × 512 dims\n",
      "9 layers × 1 sequences × 57 tokens × 512 dims\n",
      "9 layers × 1 sequences × 58 tokens × 512 dims\n",
      "9 layers × 1 sequences × 59 tokens × 512 dims\n",
      "9 layers × 1 sequences × 60 tokens × 512 dims\n",
      "9 layers × 1 sequences × 61 tokens × 512 dims\n",
      "9 layers × 1 sequences × 62 tokens × 512 dims\n",
      "9 layers × 1 sequences × 63 tokens × 512 dims\n",
      "9 layers × 1 sequences × 64 tokens × 512 dims\n",
      "9 layers × 1 sequences × 65 tokens × 512 dims\n",
      "9 layers × 1 sequences × 66 tokens × 512 dims\n",
      "9 layers × 1 sequences × 67 tokens × 512 dims\n",
      "9 layers × 1 sequences × 68 tokens × 512 dims\n",
      "9 layers × 1 sequences × 69 tokens × 512 dims\n",
      "9 layers × 1 sequences × 70 tokens × 512 dims\n",
      "9 layers × 1 sequences × 71 tokens × 512 dims\n",
      "9 layers × 1 sequences × 72 tokens × 512 dims\n",
      "9 layers × 1 sequences × 73 tokens × 512 dims\n",
      "9 layers × 1 sequences × 74 tokens × 512 dims\n",
      "9 layers × 1 sequences × 75 tokens × 512 dims\n",
      "9 layers × 1 sequences × 76 tokens × 512 dims\n",
      "9 layers × 1 sequences × 77 tokens × 512 dims\n",
      "9 layers × 1 sequences × 78 tokens × 512 dims\n",
      "9 layers × 1 sequences × 79 tokens × 512 dims\n",
      "9 layers × 1 sequences × 80 tokens × 512 dims\n",
      "9 layers × 1 sequences × 81 tokens × 512 dims\n",
      "9 layers × 1 sequences × 82 tokens × 512 dims\n",
      "9 layers × 1 sequences × 83 tokens × 512 dims\n",
      "9 layers × 1 sequences × 84 tokens × 512 dims\n",
      "9 layers × 1 sequences × 85 tokens × 512 dims\n",
      "9 layers × 1 sequences × 86 tokens × 512 dims\n",
      "9 layers × 1 sequences × 87 tokens × 512 dims\n",
      "9 layers × 1 sequences × 88 tokens × 512 dims\n",
      "9 layers × 1 sequences × 89 tokens × 512 dims\n",
      "9 layers × 1 sequences × 90 tokens × 512 dims\n",
      "9 layers × 1 sequences × 91 tokens × 512 dims\n",
      "9 layers × 1 sequences × 92 tokens × 512 dims\n",
      "9 layers × 1 sequences × 93 tokens × 512 dims\n",
      "9 layers × 1 sequences × 94 tokens × 512 dims\n",
      "9 layers × 1 sequences × 95 tokens × 512 dims\n",
      "9 layers × 1 sequences × 96 tokens × 512 dims\n",
      "9 layers × 1 sequences × 97 tokens × 512 dims\n",
      "9 layers × 1 sequences × 98 tokens × 512 dims\n",
      "9 layers × 1 sequences × 99 tokens × 512 dims\n",
      "9 layers × 1 sequences × 100 tokens × 512 dims\n",
      "9 layers × 1 sequences × 101 tokens × 512 dims\n",
      "9 layers × 1 sequences × 102 tokens × 512 dims\n",
      "9 layers × 1 sequences × 103 tokens × 512 dims\n",
      "9 layers × 1 sequences × 104 tokens × 512 dims\n",
      "9 layers × 1 sequences × 105 tokens × 512 dims\n",
      "9 layers × 1 sequences × 106 tokens × 512 dims\n",
      "9 layers × 1 sequences × 107 tokens × 512 dims\n",
      "9 layers × 1 sequences × 108 tokens × 512 dims\n",
      "9 layers × 1 sequences × 109 tokens × 512 dims\n",
      "9 layers × 1 sequences × 110 tokens × 512 dims\n",
      "9 layers × 1 sequences × 111 tokens × 512 dims\n",
      "9 layers × 1 sequences × 112 tokens × 512 dims\n",
      "9 layers × 1 sequences × 113 tokens × 512 dims\n",
      "9 layers × 1 sequences × 114 tokens × 512 dims\n",
      "9 layers × 1 sequences × 115 tokens × 512 dims\n",
      "9 layers × 1 sequences × 116 tokens × 512 dims\n",
      "9 layers × 1 sequences × 117 tokens × 512 dims\n",
      "9 layers × 1 sequences × 118 tokens × 512 dims\n",
      "9 layers × 1 sequences × 119 tokens × 512 dims\n",
      "9 layers × 1 sequences × 120 tokens × 512 dims\n",
      "9 layers × 1 sequences × 121 tokens × 512 dims\n",
      "9 layers × 1 sequences × 122 tokens × 512 dims\n",
      "9 layers × 1 sequences × 123 tokens × 512 dims\n",
      "9 layers × 1 sequences × 124 tokens × 512 dims\n",
      "9 layers × 1 sequences × 125 tokens × 512 dims\n",
      "9 layers × 1 sequences × 126 tokens × 512 dims\n",
      "9 layers × 1 sequences × 127 tokens × 512 dims\n",
      "9 layers × 1 sequences × 128 tokens × 512 dims\n",
      "9 layers × 1 sequences × 129 tokens × 512 dims\n",
      "9 layers × 1 sequences × 130 tokens × 512 dims\n",
      "9 layers × 1 sequences × 131 tokens × 512 dims\n",
      "9 layers × 1 sequences × 132 tokens × 512 dims\n",
      "9 layers × 1 sequences × 133 tokens × 512 dims\n",
      "9 layers × 1 sequences × 134 tokens × 512 dims\n",
      "9 layers × 1 sequences × 135 tokens × 512 dims\n",
      "9 layers × 1 sequences × 136 tokens × 512 dims\n",
      "9 layers × 1 sequences × 137 tokens × 512 dims\n",
      "9 layers × 1 sequences × 138 tokens × 512 dims\n",
      "9 layers × 1 sequences × 139 tokens × 512 dims\n",
      "9 layers × 1 sequences × 140 tokens × 512 dims\n",
      "9 layers × 1 sequences × 141 tokens × 512 dims\n",
      "9 layers × 1 sequences × 142 tokens × 512 dims\n",
      "9 layers × 1 sequences × 143 tokens × 512 dims\n",
      "9 layers × 1 sequences × 144 tokens × 512 dims\n",
      "9 layers × 1 sequences × 145 tokens × 512 dims\n",
      "9 layers × 1 sequences × 146 tokens × 512 dims\n",
      "9 layers × 1 sequences × 147 tokens × 512 dims\n",
      "9 layers × 1 sequences × 148 tokens × 512 dims\n",
      "9 layers × 1 sequences × 149 tokens × 512 dims\n",
      "9 layers × 1 sequences × 150 tokens × 512 dims\n",
      "9 layers × 1 sequences × 151 tokens × 512 dims\n",
      "9 layers × 1 sequences × 152 tokens × 512 dims\n",
      "9 layers × 1 sequences × 153 tokens × 512 dims\n",
      "9 layers × 1 sequences × 154 tokens × 512 dims\n",
      "9 layers × 1 sequences × 155 tokens × 512 dims\n",
      "9 layers × 1 sequences × 156 tokens × 512 dims\n",
      "9 layers × 1 sequences × 157 tokens × 512 dims\n",
      "9 layers × 1 sequences × 158 tokens × 512 dims\n",
      "9 layers × 1 sequences × 159 tokens × 512 dims\n",
      "9 layers × 1 sequences × 160 tokens × 512 dims\n",
      "9 layers × 1 sequences × 161 tokens × 512 dims\n",
      "9 layers × 1 sequences × 162 tokens × 512 dims\n",
      "9 layers × 1 sequences × 163 tokens × 512 dims\n",
      "9 layers × 1 sequences × 164 tokens × 512 dims\n",
      "9 layers × 1 sequences × 165 tokens × 512 dims\n",
      "9 layers × 1 sequences × 166 tokens × 512 dims\n",
      "9 layers × 1 sequences × 167 tokens × 512 dims\n",
      "9 layers × 1 sequences × 168 tokens × 512 dims\n",
      "9 layers × 1 sequences × 169 tokens × 512 dims\n",
      "9 layers × 1 sequences × 170 tokens × 512 dims\n",
      "9 layers × 1 sequences × 171 tokens × 512 dims\n",
      "9 layers × 1 sequences × 172 tokens × 512 dims\n",
      "9 layers × 1 sequences × 173 tokens × 512 dims\n",
      "9 layers × 1 sequences × 174 tokens × 512 dims\n",
      "9 layers × 1 sequences × 175 tokens × 512 dims\n",
      "9 layers × 1 sequences × 176 tokens × 512 dims\n",
      "9 layers × 1 sequences × 177 tokens × 512 dims\n",
      "9 layers × 1 sequences × 178 tokens × 512 dims\n",
      "9 layers × 1 sequences × 179 tokens × 512 dims\n",
      "9 layers × 1 sequences × 180 tokens × 512 dims\n",
      "9 layers × 1 sequences × 181 tokens × 512 dims\n",
      "9 layers × 1 sequences × 182 tokens × 512 dims\n",
      "9 layers × 1 sequences × 183 tokens × 512 dims\n",
      "9 layers × 1 sequences × 184 tokens × 512 dims\n",
      "9 layers × 1 sequences × 185 tokens × 512 dims\n",
      "9 layers × 1 sequences × 186 tokens × 512 dims\n",
      "9 layers × 1 sequences × 187 tokens × 512 dims\n",
      "9 layers × 1 sequences × 188 tokens × 512 dims\n",
      "9 layers × 1 sequences × 189 tokens × 512 dims\n",
      "9 layers × 1 sequences × 190 tokens × 512 dims\n",
      "9 layers × 1 sequences × 191 tokens × 512 dims\n",
      "9 layers × 1 sequences × 192 tokens × 512 dims\n",
      "9 layers × 1 sequences × 193 tokens × 512 dims\n",
      "9 layers × 1 sequences × 194 tokens × 512 dims\n",
      "9 layers × 1 sequences × 195 tokens × 512 dims\n",
      "9 layers × 1 sequences × 196 tokens × 512 dims\n",
      "9 layers × 1 sequences × 197 tokens × 512 dims\n",
      "9 layers × 1 sequences × 198 tokens × 512 dims\n",
      "9 layers × 1 sequences × 199 tokens × 512 dims\n",
      "9 layers × 1 sequences × 200 tokens × 512 dims\n",
      "9 layers × 1 sequences × 201 tokens × 512 dims\n",
      "9 layers × 1 sequences × 202 tokens × 512 dims\n",
      "9 layers × 1 sequences × 203 tokens × 512 dims\n",
      "9 layers × 1 sequences × 204 tokens × 512 dims\n",
      "9 layers × 1 sequences × 205 tokens × 512 dims\n",
      "9 layers × 1 sequences × 206 tokens × 512 dims\n",
      "9 layers × 1 sequences × 207 tokens × 512 dims\n",
      "9 layers × 1 sequences × 208 tokens × 512 dims\n",
      "9 layers × 1 sequences × 209 tokens × 512 dims\n",
      "9 layers × 1 sequences × 210 tokens × 512 dims\n",
      "9 layers × 1 sequences × 211 tokens × 512 dims\n",
      "9 layers × 1 sequences × 212 tokens × 512 dims\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                 | 4/1000 [00:07<27:57,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 512])\n",
      "Hidden states shape: 195 generated tokens × 9 layers × 1 sequences × 9 tokens × 512 dims\n",
      "3053.3718\n",
      "3094.3384\n",
      "3132.9514\n",
      "3170.9998\n",
      "3207.078\n",
      "3244.5637\n",
      "3285.4312\n",
      "3318.6035\n",
      "3348.8723\n",
      "3384.4553\n",
      "3418.5063\n",
      "3443.9575\n",
      "3478.2354\n",
      "3515.3135\n",
      "3541.5234\n",
      "3570.2812\n",
      "3597.6345\n",
      "3623.321\n",
      "3649.4077\n",
      "3679.0771\n",
      "3706.751\n",
      "3731.1816\n",
      "3757.1375\n",
      "3783.252\n",
      "3806.8452\n",
      "3831.1716\n",
      "3879.3894\n",
      "3916.083\n",
      "3964.4126\n",
      "4007.195\n",
      "4048.2988\n",
      "4091.7747\n",
      "4118.5835\n",
      "4143.769\n",
      "4166.2754\n",
      "4189.18\n",
      "4212.4985\n",
      "4238.6626\n",
      "4262.2153\n",
      "4286.932\n",
      "4308.5835\n",
      "4328.8257\n",
      "4351.171\n",
      "4382.9585\n",
      "4419.634\n",
      "4444.719\n",
      "4471.3027\n",
      "4495.77\n",
      "4517.443\n",
      "4540.443\n",
      "4565.2456\n",
      "4585.6772\n",
      "4606.9927\n",
      "4627.013\n",
      "4651.183\n",
      "4678.764\n",
      "4700.5967\n",
      "4721.237\n",
      "4743.1343\n",
      "4770.42\n",
      "4788.244\n",
      "4808.0537\n",
      "4827.079\n",
      "4846.3335\n",
      "4871.319\n",
      "4890.5337\n",
      "4910.824\n",
      "4930.6724\n",
      "4951.7505\n",
      "4978.421\n",
      "5001.6895\n",
      "5026.669\n",
      "5050.2324\n",
      "5069.726\n",
      "5091.3916\n",
      "5108.7163\n",
      "5127.241\n",
      "5145.837\n",
      "5166.1787\n",
      "5184.6416\n",
      "5202.7993\n",
      "5219.6177\n",
      "5236.288\n",
      "5253.173\n",
      "5269.4526\n",
      "5285.345\n",
      "5305.3633\n",
      "5330.0894\n",
      "5347.542\n",
      "5365.0493\n",
      "5382.4478\n",
      "5400.684\n",
      "5418.147\n",
      "5440.1084\n",
      "5456.923\n",
      "5480.125\n",
      "5496.98\n",
      "5511.7275\n",
      "5528.3145\n",
      "5544.7534\n",
      "5561.8804\n",
      "5578.0537\n",
      "5599.8833\n",
      "5624.6636\n",
      "5640.006\n",
      "5658.378\n",
      "5676.5312\n",
      "5696.529\n",
      "5715.97\n",
      "5729.7197\n",
      "5745.7593\n",
      "5761.1465\n",
      "5778.3335\n",
      "5798.265\n",
      "5814.066\n",
      "5828.661\n",
      "5846.956\n",
      "5863.004\n",
      "5879.348\n",
      "5892.969\n",
      "5906.257\n",
      "5923.0635\n",
      "5941.526\n",
      "5961.653\n",
      "5976.54\n",
      "5993.7417\n",
      "6008.9414\n",
      "6021.679\n",
      "6034.822\n",
      "6052.0137\n",
      "6065.6504\n",
      "6082.226\n",
      "6097.353\n",
      "6112.5366\n",
      "6127.0967\n",
      "6142.926\n",
      "6154.1743\n",
      "6168.949\n",
      "6182.48\n",
      "6197.8145\n",
      "6213.412\n",
      "6231.5713\n",
      "6248.5625\n",
      "6263.218\n",
      "6277.0884\n",
      "6292.1387\n",
      "6304.4233\n",
      "6316.5205\n",
      "6330.7153\n",
      "6346.755\n",
      "6360.9\n",
      "6374.7676\n",
      "6392.8223\n",
      "6405.5015\n",
      "6418.654\n",
      "6435.2974\n",
      "6461.7983\n",
      "6480.6143\n",
      "6495.648\n",
      "6508.8486\n",
      "6524.7803\n",
      "6536.28\n",
      "6549.064\n",
      "6560.973\n",
      "6573.608\n",
      "6586.921\n",
      "6599.6855\n",
      "6616.099\n",
      "6626.746\n",
      "6637.2056\n",
      "6649.501\n",
      "6661.891\n",
      "6677.2866\n",
      "6690.9517\n",
      "6705.8193\n",
      "6718.0825\n",
      "6732.943\n",
      "6746.6157\n",
      "6759.413\n",
      "6771.4224\n",
      "6785.048\n",
      "6795.4663\n",
      "6807.745\n",
      "6819.3135\n",
      "6831.7944\n",
      "6843.393\n",
      "6860.519\n",
      "6878.6597\n",
      "6892.8613\n",
      "6905.079\n",
      "6918.2866\n",
      "6933.129\n",
      "6946.9688\n",
      "6959.8325\n",
      "6971.7183\n",
      "9 layers × 1 sequences × 9 tokens × 512 dims\n",
      "9 layers × 1 sequences × 10 tokens × 512 dims\n",
      "9 layers × 1 sequences × 11 tokens × 512 dims\n",
      "9 layers × 1 sequences × 12 tokens × 512 dims\n",
      "9 layers × 1 sequences × 13 tokens × 512 dims\n",
      "9 layers × 1 sequences × 14 tokens × 512 dims\n",
      "9 layers × 1 sequences × 15 tokens × 512 dims\n",
      "9 layers × 1 sequences × 16 tokens × 512 dims\n",
      "9 layers × 1 sequences × 17 tokens × 512 dims\n",
      "9 layers × 1 sequences × 18 tokens × 512 dims\n",
      "9 layers × 1 sequences × 19 tokens × 512 dims\n",
      "9 layers × 1 sequences × 20 tokens × 512 dims\n",
      "9 layers × 1 sequences × 21 tokens × 512 dims\n",
      "9 layers × 1 sequences × 22 tokens × 512 dims\n",
      "9 layers × 1 sequences × 23 tokens × 512 dims\n",
      "9 layers × 1 sequences × 24 tokens × 512 dims\n",
      "9 layers × 1 sequences × 25 tokens × 512 dims\n",
      "9 layers × 1 sequences × 26 tokens × 512 dims\n",
      "9 layers × 1 sequences × 27 tokens × 512 dims\n",
      "9 layers × 1 sequences × 28 tokens × 512 dims\n",
      "9 layers × 1 sequences × 29 tokens × 512 dims\n",
      "9 layers × 1 sequences × 30 tokens × 512 dims\n",
      "9 layers × 1 sequences × 31 tokens × 512 dims\n",
      "9 layers × 1 sequences × 32 tokens × 512 dims\n",
      "9 layers × 1 sequences × 33 tokens × 512 dims\n",
      "9 layers × 1 sequences × 34 tokens × 512 dims\n",
      "9 layers × 1 sequences × 35 tokens × 512 dims\n",
      "9 layers × 1 sequences × 36 tokens × 512 dims\n",
      "9 layers × 1 sequences × 37 tokens × 512 dims\n",
      "9 layers × 1 sequences × 38 tokens × 512 dims\n",
      "9 layers × 1 sequences × 39 tokens × 512 dims\n",
      "9 layers × 1 sequences × 40 tokens × 512 dims\n",
      "9 layers × 1 sequences × 41 tokens × 512 dims\n",
      "9 layers × 1 sequences × 42 tokens × 512 dims\n",
      "9 layers × 1 sequences × 43 tokens × 512 dims\n",
      "9 layers × 1 sequences × 44 tokens × 512 dims\n",
      "9 layers × 1 sequences × 45 tokens × 512 dims\n",
      "9 layers × 1 sequences × 46 tokens × 512 dims\n",
      "9 layers × 1 sequences × 47 tokens × 512 dims\n",
      "9 layers × 1 sequences × 48 tokens × 512 dims\n",
      "9 layers × 1 sequences × 49 tokens × 512 dims\n",
      "9 layers × 1 sequences × 50 tokens × 512 dims\n",
      "9 layers × 1 sequences × 51 tokens × 512 dims\n",
      "9 layers × 1 sequences × 52 tokens × 512 dims\n",
      "9 layers × 1 sequences × 53 tokens × 512 dims\n",
      "9 layers × 1 sequences × 54 tokens × 512 dims\n",
      "9 layers × 1 sequences × 55 tokens × 512 dims\n",
      "9 layers × 1 sequences × 56 tokens × 512 dims\n",
      "9 layers × 1 sequences × 57 tokens × 512 dims\n",
      "9 layers × 1 sequences × 58 tokens × 512 dims\n",
      "9 layers × 1 sequences × 59 tokens × 512 dims\n",
      "9 layers × 1 sequences × 60 tokens × 512 dims\n",
      "9 layers × 1 sequences × 61 tokens × 512 dims\n",
      "9 layers × 1 sequences × 62 tokens × 512 dims\n",
      "9 layers × 1 sequences × 63 tokens × 512 dims\n",
      "9 layers × 1 sequences × 64 tokens × 512 dims\n",
      "9 layers × 1 sequences × 65 tokens × 512 dims\n",
      "9 layers × 1 sequences × 66 tokens × 512 dims\n",
      "9 layers × 1 sequences × 67 tokens × 512 dims\n",
      "9 layers × 1 sequences × 68 tokens × 512 dims\n",
      "9 layers × 1 sequences × 69 tokens × 512 dims\n",
      "9 layers × 1 sequences × 70 tokens × 512 dims\n",
      "9 layers × 1 sequences × 71 tokens × 512 dims\n",
      "9 layers × 1 sequences × 72 tokens × 512 dims\n",
      "9 layers × 1 sequences × 73 tokens × 512 dims\n",
      "9 layers × 1 sequences × 74 tokens × 512 dims\n",
      "9 layers × 1 sequences × 75 tokens × 512 dims\n",
      "9 layers × 1 sequences × 76 tokens × 512 dims\n",
      "9 layers × 1 sequences × 77 tokens × 512 dims\n",
      "9 layers × 1 sequences × 78 tokens × 512 dims\n",
      "9 layers × 1 sequences × 79 tokens × 512 dims\n",
      "9 layers × 1 sequences × 80 tokens × 512 dims\n",
      "9 layers × 1 sequences × 81 tokens × 512 dims\n",
      "9 layers × 1 sequences × 82 tokens × 512 dims\n",
      "9 layers × 1 sequences × 83 tokens × 512 dims\n",
      "9 layers × 1 sequences × 84 tokens × 512 dims\n",
      "9 layers × 1 sequences × 85 tokens × 512 dims\n",
      "9 layers × 1 sequences × 86 tokens × 512 dims\n",
      "9 layers × 1 sequences × 87 tokens × 512 dims\n",
      "9 layers × 1 sequences × 88 tokens × 512 dims\n",
      "9 layers × 1 sequences × 89 tokens × 512 dims\n",
      "9 layers × 1 sequences × 90 tokens × 512 dims\n",
      "9 layers × 1 sequences × 91 tokens × 512 dims\n",
      "9 layers × 1 sequences × 92 tokens × 512 dims\n",
      "9 layers × 1 sequences × 93 tokens × 512 dims\n",
      "9 layers × 1 sequences × 94 tokens × 512 dims\n",
      "9 layers × 1 sequences × 95 tokens × 512 dims\n",
      "9 layers × 1 sequences × 96 tokens × 512 dims\n",
      "9 layers × 1 sequences × 97 tokens × 512 dims\n",
      "9 layers × 1 sequences × 98 tokens × 512 dims\n",
      "9 layers × 1 sequences × 99 tokens × 512 dims\n",
      "9 layers × 1 sequences × 100 tokens × 512 dims\n",
      "9 layers × 1 sequences × 101 tokens × 512 dims\n",
      "9 layers × 1 sequences × 102 tokens × 512 dims\n",
      "9 layers × 1 sequences × 103 tokens × 512 dims\n",
      "9 layers × 1 sequences × 104 tokens × 512 dims\n",
      "9 layers × 1 sequences × 105 tokens × 512 dims\n",
      "9 layers × 1 sequences × 106 tokens × 512 dims\n",
      "9 layers × 1 sequences × 107 tokens × 512 dims\n",
      "9 layers × 1 sequences × 108 tokens × 512 dims\n",
      "9 layers × 1 sequences × 109 tokens × 512 dims\n",
      "9 layers × 1 sequences × 110 tokens × 512 dims\n",
      "9 layers × 1 sequences × 111 tokens × 512 dims\n",
      "9 layers × 1 sequences × 112 tokens × 512 dims\n",
      "9 layers × 1 sequences × 113 tokens × 512 dims\n",
      "9 layers × 1 sequences × 114 tokens × 512 dims\n",
      "9 layers × 1 sequences × 115 tokens × 512 dims\n",
      "9 layers × 1 sequences × 116 tokens × 512 dims\n",
      "9 layers × 1 sequences × 117 tokens × 512 dims\n",
      "9 layers × 1 sequences × 118 tokens × 512 dims\n",
      "9 layers × 1 sequences × 119 tokens × 512 dims\n",
      "9 layers × 1 sequences × 120 tokens × 512 dims\n",
      "9 layers × 1 sequences × 121 tokens × 512 dims\n",
      "9 layers × 1 sequences × 122 tokens × 512 dims\n",
      "9 layers × 1 sequences × 123 tokens × 512 dims\n",
      "9 layers × 1 sequences × 124 tokens × 512 dims\n",
      "9 layers × 1 sequences × 125 tokens × 512 dims\n",
      "9 layers × 1 sequences × 126 tokens × 512 dims\n",
      "9 layers × 1 sequences × 127 tokens × 512 dims\n",
      "9 layers × 1 sequences × 128 tokens × 512 dims\n",
      "9 layers × 1 sequences × 129 tokens × 512 dims\n",
      "9 layers × 1 sequences × 130 tokens × 512 dims\n",
      "9 layers × 1 sequences × 131 tokens × 512 dims\n",
      "9 layers × 1 sequences × 132 tokens × 512 dims\n",
      "9 layers × 1 sequences × 133 tokens × 512 dims\n",
      "9 layers × 1 sequences × 134 tokens × 512 dims\n",
      "9 layers × 1 sequences × 135 tokens × 512 dims\n",
      "9 layers × 1 sequences × 136 tokens × 512 dims\n",
      "9 layers × 1 sequences × 137 tokens × 512 dims\n",
      "9 layers × 1 sequences × 138 tokens × 512 dims\n",
      "9 layers × 1 sequences × 139 tokens × 512 dims\n",
      "9 layers × 1 sequences × 140 tokens × 512 dims\n",
      "9 layers × 1 sequences × 141 tokens × 512 dims\n",
      "9 layers × 1 sequences × 142 tokens × 512 dims\n",
      "9 layers × 1 sequences × 143 tokens × 512 dims\n",
      "9 layers × 1 sequences × 144 tokens × 512 dims\n",
      "9 layers × 1 sequences × 145 tokens × 512 dims\n",
      "9 layers × 1 sequences × 146 tokens × 512 dims\n",
      "9 layers × 1 sequences × 147 tokens × 512 dims\n",
      "9 layers × 1 sequences × 148 tokens × 512 dims\n",
      "9 layers × 1 sequences × 149 tokens × 512 dims\n",
      "9 layers × 1 sequences × 150 tokens × 512 dims\n",
      "9 layers × 1 sequences × 151 tokens × 512 dims\n",
      "9 layers × 1 sequences × 152 tokens × 512 dims\n",
      "9 layers × 1 sequences × 153 tokens × 512 dims\n",
      "9 layers × 1 sequences × 154 tokens × 512 dims\n",
      "9 layers × 1 sequences × 155 tokens × 512 dims\n",
      "9 layers × 1 sequences × 156 tokens × 512 dims\n",
      "9 layers × 1 sequences × 157 tokens × 512 dims\n",
      "9 layers × 1 sequences × 158 tokens × 512 dims\n",
      "9 layers × 1 sequences × 159 tokens × 512 dims\n",
      "9 layers × 1 sequences × 160 tokens × 512 dims\n",
      "9 layers × 1 sequences × 161 tokens × 512 dims\n",
      "9 layers × 1 sequences × 162 tokens × 512 dims\n",
      "9 layers × 1 sequences × 163 tokens × 512 dims\n",
      "9 layers × 1 sequences × 164 tokens × 512 dims\n",
      "9 layers × 1 sequences × 165 tokens × 512 dims\n",
      "9 layers × 1 sequences × 166 tokens × 512 dims\n",
      "9 layers × 1 sequences × 167 tokens × 512 dims\n",
      "9 layers × 1 sequences × 168 tokens × 512 dims\n",
      "9 layers × 1 sequences × 169 tokens × 512 dims\n",
      "9 layers × 1 sequences × 170 tokens × 512 dims\n",
      "9 layers × 1 sequences × 171 tokens × 512 dims\n",
      "9 layers × 1 sequences × 172 tokens × 512 dims\n",
      "9 layers × 1 sequences × 173 tokens × 512 dims\n",
      "9 layers × 1 sequences × 174 tokens × 512 dims\n",
      "9 layers × 1 sequences × 175 tokens × 512 dims\n",
      "9 layers × 1 sequences × 176 tokens × 512 dims\n",
      "9 layers × 1 sequences × 177 tokens × 512 dims\n",
      "9 layers × 1 sequences × 178 tokens × 512 dims\n",
      "9 layers × 1 sequences × 179 tokens × 512 dims\n",
      "9 layers × 1 sequences × 180 tokens × 512 dims\n",
      "9 layers × 1 sequences × 181 tokens × 512 dims\n",
      "9 layers × 1 sequences × 182 tokens × 512 dims\n",
      "9 layers × 1 sequences × 183 tokens × 512 dims\n",
      "9 layers × 1 sequences × 184 tokens × 512 dims\n",
      "9 layers × 1 sequences × 185 tokens × 512 dims\n",
      "9 layers × 1 sequences × 186 tokens × 512 dims\n",
      "9 layers × 1 sequences × 187 tokens × 512 dims\n",
      "9 layers × 1 sequences × 188 tokens × 512 dims\n",
      "9 layers × 1 sequences × 189 tokens × 512 dims\n",
      "9 layers × 1 sequences × 190 tokens × 512 dims\n",
      "9 layers × 1 sequences × 191 tokens × 512 dims\n",
      "9 layers × 1 sequences × 192 tokens × 512 dims\n",
      "9 layers × 1 sequences × 193 tokens × 512 dims\n",
      "9 layers × 1 sequences × 194 tokens × 512 dims\n",
      "9 layers × 1 sequences × 195 tokens × 512 dims\n",
      "9 layers × 1 sequences × 196 tokens × 512 dims\n",
      "9 layers × 1 sequences × 197 tokens × 512 dims\n",
      "9 layers × 1 sequences × 198 tokens × 512 dims\n",
      "9 layers × 1 sequences × 199 tokens × 512 dims\n",
      "9 layers × 1 sequences × 200 tokens × 512 dims\n",
      "9 layers × 1 sequences × 201 tokens × 512 dims\n",
      "9 layers × 1 sequences × 202 tokens × 512 dims\n",
      "9 layers × 1 sequences × 203 tokens × 512 dims\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                 | 5/1000 [00:09<29:43,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 512])\n",
      "Hidden states shape: 255 generated tokens × 9 layers × 1 sequences × 9 tokens × 512 dims\n",
      "3053.3718\n",
      "3094.3384\n",
      "3126.7314\n",
      "3157.2288\n",
      "3191.1196\n",
      "3235.018\n",
      "3271.4104\n",
      "3314.175\n",
      "3343.6672\n",
      "3372.3755\n",
      "3398.9868\n",
      "3432.9717\n",
      "3466.172\n",
      "3511.7366\n",
      "3537.5554\n",
      "3565.1208\n",
      "3592.4048\n",
      "3619.269\n",
      "3645.9539\n",
      "3673.1414\n",
      "3700.103\n",
      "3735.3691\n",
      "3774.7014\n",
      "3807.0557\n",
      "3836.5903\n",
      "3866.0344\n",
      "3895.9182\n",
      "3922.8691\n",
      "3946.9414\n",
      "3971.5286\n",
      "3996.5854\n",
      "4022.6978\n",
      "4048.9336\n",
      "4072.8557\n",
      "4099.2837\n",
      "4128.2876\n",
      "4153.0776\n",
      "4182.579\n",
      "4207.2583\n",
      "4230.105\n",
      "4253.6636\n",
      "4276.6245\n",
      "4304.459\n",
      "4328.3525\n",
      "4352.2603\n",
      "4373.6787\n",
      "4394.5776\n",
      "4418.764\n",
      "4440.251\n",
      "4462.8604\n",
      "4486.592\n",
      "4510.462\n",
      "4530.7944\n",
      "4551.6206\n",
      "4572.77\n",
      "4596.452\n",
      "4624.471\n",
      "4653.663\n",
      "4678.448\n",
      "4707.508\n",
      "4734.6187\n",
      "4761.238\n",
      "4786.8228\n",
      "4815.6777\n",
      "4836.0386\n",
      "4857.036\n",
      "4875.5024\n",
      "4896.682\n",
      "4915.994\n",
      "4937.044\n",
      "4958.5947\n",
      "4979.7207\n",
      "5001.5205\n",
      "5022.178\n",
      "5054.6943\n",
      "5074.5703\n",
      "5092.872\n",
      "5113.5273\n",
      "5132.087\n",
      "5151.6714\n",
      "5170.647\n",
      "5188.6665\n",
      "5205.895\n",
      "5222.348\n",
      "5239.381\n",
      "5256.775\n",
      "5280.6616\n",
      "5297.9624\n",
      "5318.134\n",
      "5336.4463\n",
      "5354.2505\n",
      "5373.201\n",
      "5397.066\n",
      "5419.228\n",
      "5435.295\n",
      "5453.0283\n",
      "5470.248\n",
      "5487.5034\n",
      "5503.644\n",
      "5526.8047\n",
      "5547.396\n",
      "5564.596\n",
      "5583.871\n",
      "5599.4526\n",
      "5616.3765\n",
      "5641.3716\n",
      "5663.171\n",
      "5682.477\n",
      "5703.9517\n",
      "5720.719\n",
      "5748.651\n",
      "5767.679\n",
      "5784.312\n",
      "5805.476\n",
      "5822.833\n",
      "5839.1553\n",
      "5858.8164\n",
      "5879.939\n",
      "5897.867\n",
      "5912.536\n",
      "5928.115\n",
      "5942.941\n",
      "5960.8086\n",
      "5979.8496\n",
      "5999.4526\n",
      "6013.7573\n",
      "6028.642\n",
      "6044.322\n",
      "6060.143\n",
      "6081.363\n",
      "6101.3604\n",
      "6118.383\n",
      "6137.35\n",
      "6155.039\n",
      "6169.182\n",
      "6184.112\n",
      "6199.6064\n",
      "6215.803\n",
      "6234.343\n",
      "6250.804\n",
      "6264.479\n",
      "6279.4185\n",
      "6298.676\n",
      "6327.1196\n",
      "6345.732\n",
      "6362.875\n",
      "6378.055\n",
      "6395.9507\n",
      "6411.6074\n",
      "6427.885\n",
      "6445.9434\n",
      "6464.656\n",
      "6482.216\n",
      "6494.6587\n",
      "6508.862\n",
      "6521.745\n",
      "6536.493\n",
      "6550.191\n",
      "6562.1187\n",
      "6576.457\n",
      "6595.6055\n",
      "6610.9644\n",
      "6629.2183\n",
      "6649.283\n",
      "6660.916\n",
      "6674.2705\n",
      "6698.0596\n",
      "6712.665\n",
      "6728.441\n",
      "6742.4053\n",
      "6753.94\n",
      "6767.164\n",
      "6779.278\n",
      "6792.6265\n",
      "6806.283\n",
      "6819.5244\n",
      "6835.2285\n",
      "6846.4736\n",
      "6859.271\n",
      "6871.4053\n",
      "6884.278\n",
      "6898.3765\n",
      "6910.978\n",
      "6921.591\n",
      "6933.653\n",
      "6952.0083\n",
      "6967.23\n",
      "6981.2603\n",
      "6993.9443\n",
      "7009.799\n",
      "7020.86\n",
      "7033.398\n",
      "7045.858\n",
      "7067.9517\n",
      "7080.6733\n",
      "7094.6973\n",
      "7105.7397\n",
      "7117.595\n",
      "7131.929\n",
      "7146.0557\n",
      "7156.5884\n",
      "7168.059\n",
      "7183.582\n",
      "7199.4043\n",
      "7209.6763\n",
      "7223.555\n",
      "7234.4966\n",
      "7246.426\n",
      "7259.469\n",
      "7274.3916\n",
      "7287.392\n",
      "7299.2686\n",
      "7313.6494\n",
      "7324.3345\n",
      "7337.0054\n",
      "7364.594\n",
      "7377.725\n",
      "7389.8486\n",
      "7402.4165\n",
      "7413.724\n",
      "7428.264\n",
      "7438.507\n",
      "7450.6265\n",
      "7461.7065\n",
      "7474.048\n",
      "7486.613\n",
      "7499.077\n",
      "7511.2783\n",
      "7521.4653\n",
      "7533.146\n",
      "7545.073\n",
      "7556.212\n",
      "7568.59\n",
      "7585.8696\n",
      "7598.8984\n",
      "7610.6514\n",
      "7620.898\n",
      "7630.9307\n",
      "7642.2886\n",
      "7654.3154\n",
      "7665.6274\n",
      "7676.447\n",
      "7687.198\n",
      "7699.8345\n",
      "7715.9194\n",
      "7726.3057\n",
      "7737.7393\n",
      "7748.606\n",
      "7758.4697\n",
      "7768.9346\n",
      "7780.983\n",
      "7792.9185\n",
      "7804.356\n",
      "7815.77\n",
      "7826.522\n",
      "9 layers × 1 sequences × 9 tokens × 512 dims\n",
      "9 layers × 1 sequences × 10 tokens × 512 dims\n",
      "9 layers × 1 sequences × 11 tokens × 512 dims\n",
      "9 layers × 1 sequences × 12 tokens × 512 dims\n",
      "9 layers × 1 sequences × 13 tokens × 512 dims\n",
      "9 layers × 1 sequences × 14 tokens × 512 dims\n",
      "9 layers × 1 sequences × 15 tokens × 512 dims\n",
      "9 layers × 1 sequences × 16 tokens × 512 dims\n",
      "9 layers × 1 sequences × 17 tokens × 512 dims\n",
      "9 layers × 1 sequences × 18 tokens × 512 dims\n",
      "9 layers × 1 sequences × 19 tokens × 512 dims\n",
      "9 layers × 1 sequences × 20 tokens × 512 dims\n",
      "9 layers × 1 sequences × 21 tokens × 512 dims\n",
      "9 layers × 1 sequences × 22 tokens × 512 dims\n",
      "9 layers × 1 sequences × 23 tokens × 512 dims\n",
      "9 layers × 1 sequences × 24 tokens × 512 dims\n",
      "9 layers × 1 sequences × 25 tokens × 512 dims\n",
      "9 layers × 1 sequences × 26 tokens × 512 dims\n",
      "9 layers × 1 sequences × 27 tokens × 512 dims\n",
      "9 layers × 1 sequences × 28 tokens × 512 dims\n",
      "9 layers × 1 sequences × 29 tokens × 512 dims\n",
      "9 layers × 1 sequences × 30 tokens × 512 dims\n",
      "9 layers × 1 sequences × 31 tokens × 512 dims\n",
      "9 layers × 1 sequences × 32 tokens × 512 dims\n",
      "9 layers × 1 sequences × 33 tokens × 512 dims\n",
      "9 layers × 1 sequences × 34 tokens × 512 dims\n",
      "9 layers × 1 sequences × 35 tokens × 512 dims\n",
      "9 layers × 1 sequences × 36 tokens × 512 dims\n",
      "9 layers × 1 sequences × 37 tokens × 512 dims\n",
      "9 layers × 1 sequences × 38 tokens × 512 dims\n",
      "9 layers × 1 sequences × 39 tokens × 512 dims\n",
      "9 layers × 1 sequences × 40 tokens × 512 dims\n",
      "9 layers × 1 sequences × 41 tokens × 512 dims\n",
      "9 layers × 1 sequences × 42 tokens × 512 dims\n",
      "9 layers × 1 sequences × 43 tokens × 512 dims\n",
      "9 layers × 1 sequences × 44 tokens × 512 dims\n",
      "9 layers × 1 sequences × 45 tokens × 512 dims\n",
      "9 layers × 1 sequences × 46 tokens × 512 dims\n",
      "9 layers × 1 sequences × 47 tokens × 512 dims\n",
      "9 layers × 1 sequences × 48 tokens × 512 dims\n",
      "9 layers × 1 sequences × 49 tokens × 512 dims\n",
      "9 layers × 1 sequences × 50 tokens × 512 dims\n",
      "9 layers × 1 sequences × 51 tokens × 512 dims\n",
      "9 layers × 1 sequences × 52 tokens × 512 dims\n",
      "9 layers × 1 sequences × 53 tokens × 512 dims\n",
      "9 layers × 1 sequences × 54 tokens × 512 dims\n",
      "9 layers × 1 sequences × 55 tokens × 512 dims\n",
      "9 layers × 1 sequences × 56 tokens × 512 dims\n",
      "9 layers × 1 sequences × 57 tokens × 512 dims\n",
      "9 layers × 1 sequences × 58 tokens × 512 dims\n",
      "9 layers × 1 sequences × 59 tokens × 512 dims\n",
      "9 layers × 1 sequences × 60 tokens × 512 dims\n",
      "9 layers × 1 sequences × 61 tokens × 512 dims\n",
      "9 layers × 1 sequences × 62 tokens × 512 dims\n",
      "9 layers × 1 sequences × 63 tokens × 512 dims\n",
      "9 layers × 1 sequences × 64 tokens × 512 dims\n",
      "9 layers × 1 sequences × 65 tokens × 512 dims\n",
      "9 layers × 1 sequences × 66 tokens × 512 dims\n",
      "9 layers × 1 sequences × 67 tokens × 512 dims\n",
      "9 layers × 1 sequences × 68 tokens × 512 dims\n",
      "9 layers × 1 sequences × 69 tokens × 512 dims\n",
      "9 layers × 1 sequences × 70 tokens × 512 dims\n",
      "9 layers × 1 sequences × 71 tokens × 512 dims\n",
      "9 layers × 1 sequences × 72 tokens × 512 dims\n",
      "9 layers × 1 sequences × 73 tokens × 512 dims\n",
      "9 layers × 1 sequences × 74 tokens × 512 dims\n",
      "9 layers × 1 sequences × 75 tokens × 512 dims\n",
      "9 layers × 1 sequences × 76 tokens × 512 dims\n",
      "9 layers × 1 sequences × 77 tokens × 512 dims\n",
      "9 layers × 1 sequences × 78 tokens × 512 dims\n",
      "9 layers × 1 sequences × 79 tokens × 512 dims\n",
      "9 layers × 1 sequences × 80 tokens × 512 dims\n",
      "9 layers × 1 sequences × 81 tokens × 512 dims\n",
      "9 layers × 1 sequences × 82 tokens × 512 dims\n",
      "9 layers × 1 sequences × 83 tokens × 512 dims\n",
      "9 layers × 1 sequences × 84 tokens × 512 dims\n",
      "9 layers × 1 sequences × 85 tokens × 512 dims\n",
      "9 layers × 1 sequences × 86 tokens × 512 dims\n",
      "9 layers × 1 sequences × 87 tokens × 512 dims\n",
      "9 layers × 1 sequences × 88 tokens × 512 dims\n",
      "9 layers × 1 sequences × 89 tokens × 512 dims\n",
      "9 layers × 1 sequences × 90 tokens × 512 dims\n",
      "9 layers × 1 sequences × 91 tokens × 512 dims\n",
      "9 layers × 1 sequences × 92 tokens × 512 dims\n",
      "9 layers × 1 sequences × 93 tokens × 512 dims\n",
      "9 layers × 1 sequences × 94 tokens × 512 dims\n",
      "9 layers × 1 sequences × 95 tokens × 512 dims\n",
      "9 layers × 1 sequences × 96 tokens × 512 dims\n",
      "9 layers × 1 sequences × 97 tokens × 512 dims\n",
      "9 layers × 1 sequences × 98 tokens × 512 dims\n",
      "9 layers × 1 sequences × 99 tokens × 512 dims\n",
      "9 layers × 1 sequences × 100 tokens × 512 dims\n",
      "9 layers × 1 sequences × 101 tokens × 512 dims\n",
      "9 layers × 1 sequences × 102 tokens × 512 dims\n",
      "9 layers × 1 sequences × 103 tokens × 512 dims\n",
      "9 layers × 1 sequences × 104 tokens × 512 dims\n",
      "9 layers × 1 sequences × 105 tokens × 512 dims\n",
      "9 layers × 1 sequences × 106 tokens × 512 dims\n",
      "9 layers × 1 sequences × 107 tokens × 512 dims\n",
      "9 layers × 1 sequences × 108 tokens × 512 dims\n",
      "9 layers × 1 sequences × 109 tokens × 512 dims\n",
      "9 layers × 1 sequences × 110 tokens × 512 dims\n",
      "9 layers × 1 sequences × 111 tokens × 512 dims\n",
      "9 layers × 1 sequences × 112 tokens × 512 dims\n",
      "9 layers × 1 sequences × 113 tokens × 512 dims\n",
      "9 layers × 1 sequences × 114 tokens × 512 dims\n",
      "9 layers × 1 sequences × 115 tokens × 512 dims\n",
      "9 layers × 1 sequences × 116 tokens × 512 dims\n",
      "9 layers × 1 sequences × 117 tokens × 512 dims\n",
      "9 layers × 1 sequences × 118 tokens × 512 dims\n",
      "9 layers × 1 sequences × 119 tokens × 512 dims\n",
      "9 layers × 1 sequences × 120 tokens × 512 dims\n",
      "9 layers × 1 sequences × 121 tokens × 512 dims\n",
      "9 layers × 1 sequences × 122 tokens × 512 dims\n",
      "9 layers × 1 sequences × 123 tokens × 512 dims\n",
      "9 layers × 1 sequences × 124 tokens × 512 dims\n",
      "9 layers × 1 sequences × 125 tokens × 512 dims\n",
      "9 layers × 1 sequences × 126 tokens × 512 dims\n",
      "9 layers × 1 sequences × 127 tokens × 512 dims\n",
      "9 layers × 1 sequences × 128 tokens × 512 dims\n",
      "9 layers × 1 sequences × 129 tokens × 512 dims\n",
      "9 layers × 1 sequences × 130 tokens × 512 dims\n",
      "9 layers × 1 sequences × 131 tokens × 512 dims\n",
      "9 layers × 1 sequences × 132 tokens × 512 dims\n",
      "9 layers × 1 sequences × 133 tokens × 512 dims\n",
      "9 layers × 1 sequences × 134 tokens × 512 dims\n",
      "9 layers × 1 sequences × 135 tokens × 512 dims\n",
      "9 layers × 1 sequences × 136 tokens × 512 dims\n",
      "9 layers × 1 sequences × 137 tokens × 512 dims\n",
      "9 layers × 1 sequences × 138 tokens × 512 dims\n",
      "9 layers × 1 sequences × 139 tokens × 512 dims\n",
      "9 layers × 1 sequences × 140 tokens × 512 dims\n",
      "9 layers × 1 sequences × 141 tokens × 512 dims\n",
      "9 layers × 1 sequences × 142 tokens × 512 dims\n",
      "9 layers × 1 sequences × 143 tokens × 512 dims\n",
      "9 layers × 1 sequences × 144 tokens × 512 dims\n",
      "9 layers × 1 sequences × 145 tokens × 512 dims\n",
      "9 layers × 1 sequences × 146 tokens × 512 dims\n",
      "9 layers × 1 sequences × 147 tokens × 512 dims\n",
      "9 layers × 1 sequences × 148 tokens × 512 dims\n",
      "9 layers × 1 sequences × 149 tokens × 512 dims\n",
      "9 layers × 1 sequences × 150 tokens × 512 dims\n",
      "9 layers × 1 sequences × 151 tokens × 512 dims\n",
      "9 layers × 1 sequences × 152 tokens × 512 dims\n",
      "9 layers × 1 sequences × 153 tokens × 512 dims\n",
      "9 layers × 1 sequences × 154 tokens × 512 dims\n",
      "9 layers × 1 sequences × 155 tokens × 512 dims\n",
      "9 layers × 1 sequences × 156 tokens × 512 dims\n",
      "9 layers × 1 sequences × 157 tokens × 512 dims\n",
      "9 layers × 1 sequences × 158 tokens × 512 dims\n",
      "9 layers × 1 sequences × 159 tokens × 512 dims\n",
      "9 layers × 1 sequences × 160 tokens × 512 dims\n",
      "9 layers × 1 sequences × 161 tokens × 512 dims\n",
      "9 layers × 1 sequences × 162 tokens × 512 dims\n",
      "9 layers × 1 sequences × 163 tokens × 512 dims\n",
      "9 layers × 1 sequences × 164 tokens × 512 dims\n",
      "9 layers × 1 sequences × 165 tokens × 512 dims\n",
      "9 layers × 1 sequences × 166 tokens × 512 dims\n",
      "9 layers × 1 sequences × 167 tokens × 512 dims\n",
      "9 layers × 1 sequences × 168 tokens × 512 dims\n",
      "9 layers × 1 sequences × 169 tokens × 512 dims\n",
      "9 layers × 1 sequences × 170 tokens × 512 dims\n",
      "9 layers × 1 sequences × 171 tokens × 512 dims\n",
      "9 layers × 1 sequences × 172 tokens × 512 dims\n",
      "9 layers × 1 sequences × 173 tokens × 512 dims\n",
      "9 layers × 1 sequences × 174 tokens × 512 dims\n",
      "9 layers × 1 sequences × 175 tokens × 512 dims\n",
      "9 layers × 1 sequences × 176 tokens × 512 dims\n",
      "9 layers × 1 sequences × 177 tokens × 512 dims\n",
      "9 layers × 1 sequences × 178 tokens × 512 dims\n",
      "9 layers × 1 sequences × 179 tokens × 512 dims\n",
      "9 layers × 1 sequences × 180 tokens × 512 dims\n",
      "9 layers × 1 sequences × 181 tokens × 512 dims\n",
      "9 layers × 1 sequences × 182 tokens × 512 dims\n",
      "9 layers × 1 sequences × 183 tokens × 512 dims\n",
      "9 layers × 1 sequences × 184 tokens × 512 dims\n",
      "9 layers × 1 sequences × 185 tokens × 512 dims\n",
      "9 layers × 1 sequences × 186 tokens × 512 dims\n",
      "9 layers × 1 sequences × 187 tokens × 512 dims\n",
      "9 layers × 1 sequences × 188 tokens × 512 dims\n",
      "9 layers × 1 sequences × 189 tokens × 512 dims\n",
      "9 layers × 1 sequences × 190 tokens × 512 dims\n",
      "9 layers × 1 sequences × 191 tokens × 512 dims\n",
      "9 layers × 1 sequences × 192 tokens × 512 dims\n",
      "9 layers × 1 sequences × 193 tokens × 512 dims\n",
      "9 layers × 1 sequences × 194 tokens × 512 dims\n",
      "9 layers × 1 sequences × 195 tokens × 512 dims\n",
      "9 layers × 1 sequences × 196 tokens × 512 dims\n",
      "9 layers × 1 sequences × 197 tokens × 512 dims\n",
      "9 layers × 1 sequences × 198 tokens × 512 dims\n",
      "9 layers × 1 sequences × 199 tokens × 512 dims\n",
      "9 layers × 1 sequences × 200 tokens × 512 dims\n",
      "9 layers × 1 sequences × 201 tokens × 512 dims\n",
      "9 layers × 1 sequences × 202 tokens × 512 dims\n",
      "9 layers × 1 sequences × 203 tokens × 512 dims\n",
      "9 layers × 1 sequences × 204 tokens × 512 dims\n",
      "9 layers × 1 sequences × 205 tokens × 512 dims\n",
      "9 layers × 1 sequences × 206 tokens × 512 dims\n",
      "9 layers × 1 sequences × 207 tokens × 512 dims\n",
      "9 layers × 1 sequences × 208 tokens × 512 dims\n",
      "9 layers × 1 sequences × 209 tokens × 512 dims\n",
      "9 layers × 1 sequences × 210 tokens × 512 dims\n",
      "9 layers × 1 sequences × 211 tokens × 512 dims\n",
      "9 layers × 1 sequences × 212 tokens × 512 dims\n",
      "9 layers × 1 sequences × 213 tokens × 512 dims\n",
      "9 layers × 1 sequences × 214 tokens × 512 dims\n",
      "9 layers × 1 sequences × 215 tokens × 512 dims\n",
      "9 layers × 1 sequences × 216 tokens × 512 dims\n",
      "9 layers × 1 sequences × 217 tokens × 512 dims\n",
      "9 layers × 1 sequences × 218 tokens × 512 dims\n",
      "9 layers × 1 sequences × 219 tokens × 512 dims\n",
      "9 layers × 1 sequences × 220 tokens × 512 dims\n",
      "9 layers × 1 sequences × 221 tokens × 512 dims\n",
      "9 layers × 1 sequences × 222 tokens × 512 dims\n",
      "9 layers × 1 sequences × 223 tokens × 512 dims\n",
      "9 layers × 1 sequences × 224 tokens × 512 dims\n",
      "9 layers × 1 sequences × 225 tokens × 512 dims\n",
      "9 layers × 1 sequences × 226 tokens × 512 dims\n",
      "9 layers × 1 sequences × 227 tokens × 512 dims\n",
      "9 layers × 1 sequences × 228 tokens × 512 dims\n",
      "9 layers × 1 sequences × 229 tokens × 512 dims\n",
      "9 layers × 1 sequences × 230 tokens × 512 dims\n",
      "9 layers × 1 sequences × 231 tokens × 512 dims\n",
      "9 layers × 1 sequences × 232 tokens × 512 dims\n",
      "9 layers × 1 sequences × 233 tokens × 512 dims\n",
      "9 layers × 1 sequences × 234 tokens × 512 dims\n",
      "9 layers × 1 sequences × 235 tokens × 512 dims\n",
      "9 layers × 1 sequences × 236 tokens × 512 dims\n",
      "9 layers × 1 sequences × 237 tokens × 512 dims\n",
      "9 layers × 1 sequences × 238 tokens × 512 dims\n",
      "9 layers × 1 sequences × 239 tokens × 512 dims\n",
      "9 layers × 1 sequences × 240 tokens × 512 dims\n",
      "9 layers × 1 sequences × 241 tokens × 512 dims\n",
      "9 layers × 1 sequences × 242 tokens × 512 dims\n",
      "9 layers × 1 sequences × 243 tokens × 512 dims\n",
      "9 layers × 1 sequences × 244 tokens × 512 dims\n",
      "9 layers × 1 sequences × 245 tokens × 512 dims\n",
      "9 layers × 1 sequences × 246 tokens × 512 dims\n",
      "9 layers × 1 sequences × 247 tokens × 512 dims\n",
      "9 layers × 1 sequences × 248 tokens × 512 dims\n",
      "9 layers × 1 sequences × 249 tokens × 512 dims\n",
      "9 layers × 1 sequences × 250 tokens × 512 dims\n",
      "9 layers × 1 sequences × 251 tokens × 512 dims\n",
      "9 layers × 1 sequences × 252 tokens × 512 dims\n",
      "9 layers × 1 sequences × 253 tokens × 512 dims\n",
      "9 layers × 1 sequences × 254 tokens × 512 dims\n",
      "9 layers × 1 sequences × 255 tokens × 512 dims\n",
      "9 layers × 1 sequences × 256 tokens × 512 dims\n",
      "9 layers × 1 sequences × 257 tokens × 512 dims\n",
      "9 layers × 1 sequences × 258 tokens × 512 dims\n",
      "9 layers × 1 sequences × 259 tokens × 512 dims\n",
      "9 layers × 1 sequences × 260 tokens × 512 dims\n",
      "9 layers × 1 sequences × 261 tokens × 512 dims\n",
      "9 layers × 1 sequences × 262 tokens × 512 dims\n",
      "9 layers × 1 sequences × 263 tokens × 512 dims\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                                                                 | 6/1000 [00:11<31:22,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 512])\n",
      "Hidden states shape: 268 generated tokens × 9 layers × 1 sequences × 9 tokens × 512 dims\n",
      "3053.3718\n",
      "3094.3384\n",
      "3126.7314\n",
      "3157.2288\n",
      "3191.1196\n",
      "3226.9062\n",
      "3271.578\n",
      "3306.4849\n",
      "3350.8716\n",
      "3391.2053\n",
      "3433.23\n",
      "3477.2722\n",
      "3507.8438\n",
      "3538.1504\n",
      "3587.7693\n",
      "3626.0886\n",
      "3661.412\n",
      "3692.3315\n",
      "3732.9658\n",
      "3768.448\n",
      "3799.6426\n",
      "3824.119\n",
      "3852.9492\n",
      "3879.0242\n",
      "3903.955\n",
      "3936.7842\n",
      "3971.1675\n",
      "3995.78\n",
      "4024.998\n",
      "4050.8655\n",
      "4078.4226\n",
      "4108.35\n",
      "4142.106\n",
      "4167.183\n",
      "4194.7593\n",
      "4220.511\n",
      "4243.9004\n",
      "4269.7505\n",
      "4298.6187\n",
      "4327.177\n",
      "4354.5605\n",
      "4390.948\n",
      "4414.0435\n",
      "4438.066\n",
      "4458.9487\n",
      "4483.4736\n",
      "4504.8984\n",
      "4525.06\n",
      "4550.3325\n",
      "4571.527\n",
      "4597.229\n",
      "4621.308\n",
      "4642.793\n",
      "4670.217\n",
      "4697.199\n",
      "4719.224\n",
      "4739.4487\n",
      "4760.296\n",
      "4778.5947\n",
      "4797.641\n",
      "4816.951\n",
      "4834.2437\n",
      "4852.6904\n",
      "4876.1943\n",
      "4899.394\n",
      "4916.1934\n",
      "4934.0596\n",
      "4955.6836\n",
      "4974.099\n",
      "4997.486\n",
      "5017.384\n",
      "5035.4185\n",
      "5059.568\n",
      "5080.7847\n",
      "5098.877\n",
      "5120.27\n",
      "5139.3984\n",
      "5156.1865\n",
      "5173.461\n",
      "5191.3604\n",
      "5208.407\n",
      "5226.544\n",
      "5244.4614\n",
      "5263.9546\n",
      "5280.402\n",
      "5299.3833\n",
      "5315.651\n",
      "5332.336\n",
      "5349.5073\n",
      "5366.8086\n",
      "5383.965\n",
      "5401.4497\n",
      "5416.6123\n",
      "5440.4565\n",
      "5456.187\n",
      "5472.6772\n",
      "5489.4663\n",
      "5508.6294\n",
      "5525.8594\n",
      "5551.0854\n",
      "5571.594\n",
      "5587.5376\n",
      "5608.0977\n",
      "5628.5723\n",
      "5647.1396\n",
      "5663.378\n",
      "5678.6704\n",
      "5695.869\n",
      "5716.226\n",
      "5732.5366\n",
      "5748.097\n",
      "5763.635\n",
      "5779.9165\n",
      "5797.6836\n",
      "5814.1406\n",
      "5831.8716\n",
      "5853.862\n",
      "5875.389\n",
      "5889.2056\n",
      "5906.1743\n",
      "5919.6196\n",
      "5935.3013\n",
      "5948.177\n",
      "5961.983\n",
      "5984.9526\n",
      "6004.483\n",
      "6023.349\n",
      "6038.275\n",
      "6053.571\n",
      "6070.74\n",
      "6088.2163\n",
      "6100.2617\n",
      "6117.554\n",
      "6134.0625\n",
      "6150.273\n",
      "6168.295\n",
      "6187.8486\n",
      "6210.0977\n",
      "6231.6924\n",
      "6247.902\n",
      "6262.7603\n",
      "6279.001\n",
      "6292.569\n",
      "6307.3413\n",
      "6323.053\n",
      "6339.857\n",
      "6354.832\n",
      "6370.1377\n",
      "6386.4033\n",
      "6398.674\n",
      "6413.5303\n",
      "6425.785\n",
      "6445.0396\n",
      "6464.774\n",
      "6484.5903\n",
      "6504.022\n",
      "6518.656\n",
      "6532.855\n",
      "6543.9595\n",
      "6555.5156\n",
      "6568.794\n",
      "6583.1753\n",
      "6597.1953\n",
      "6612.1895\n",
      "6624.6885\n",
      "6643.1157\n",
      "6661.1313\n",
      "6680.9136\n",
      "6699.2812\n",
      "6714.246\n",
      "6729.362\n",
      "6742.7153\n",
      "6757.704\n",
      "6768.757\n",
      "6781.1763\n",
      "6795.1543\n",
      "6808.658\n",
      "6821.2773\n",
      "6833.571\n",
      "6843.3584\n",
      "6855.7124\n",
      "6867.7686\n",
      "6880.251\n",
      "6894.6855\n",
      "6910.3086\n",
      "6924.64\n",
      "6937.1104\n",
      "6948.3984\n",
      "6960.251\n",
      "6971.1377\n",
      "6984.291\n",
      "6994.3135\n",
      "7005.9336\n",
      "7018.79\n",
      "7030.962\n",
      "7045.146\n",
      "7058.1743\n",
      "7067.772\n",
      "7079.3555\n",
      "7096.103\n",
      "7108.769\n",
      "7118.3955\n",
      "7131.431\n",
      "7140.8867\n",
      "7152.5254\n",
      "7163.76\n",
      "7176.879\n",
      "7189.3926\n",
      "7204.9756\n",
      "7220.9253\n",
      "7236.899\n",
      "7252.154\n",
      "7266.2847\n",
      "7284.1904\n",
      "7297.161\n",
      "7307.377\n",
      "7317.0015\n",
      "7327.899\n",
      "7337.6177\n",
      "7347.4023\n",
      "7357.6196\n",
      "7368.83\n",
      "7380.339\n",
      "7390.7495\n",
      "7401.9424\n",
      "7414.289\n",
      "7424.3013\n",
      "7434.756\n",
      "7445.334\n",
      "7456.3896\n",
      "7472.8887\n",
      "7484.098\n",
      "7497.3853\n",
      "7509.1123\n",
      "7518.6934\n",
      "7529.5376\n",
      "7540.2446\n",
      "7552.356\n",
      "7564.2314\n",
      "7575.3843\n",
      "7586.06\n",
      "7597.6704\n",
      "7607.1655\n",
      "7616.083\n",
      "7626.712\n",
      "7639.159\n",
      "7652.5596\n",
      "7669.042\n",
      "7681.2275\n",
      "7690.2573\n",
      "7700.0117\n",
      "7711.0005\n",
      "7723.0513\n",
      "7733.845\n",
      "7744.1333\n",
      "7755.839\n",
      "7768.6323\n",
      "7779.0234\n",
      "7792.2593\n",
      "7803.906\n",
      "7814.103\n",
      "7827.0156\n",
      "7840.209\n",
      "7851.741\n",
      "7866.7383\n",
      "7881.4272\n",
      "7894.244\n",
      "7903.1045\n",
      "9 layers × 1 sequences × 9 tokens × 512 dims\n",
      "9 layers × 1 sequences × 10 tokens × 512 dims\n",
      "9 layers × 1 sequences × 11 tokens × 512 dims\n",
      "9 layers × 1 sequences × 12 tokens × 512 dims\n",
      "9 layers × 1 sequences × 13 tokens × 512 dims\n",
      "9 layers × 1 sequences × 14 tokens × 512 dims\n",
      "9 layers × 1 sequences × 15 tokens × 512 dims\n",
      "9 layers × 1 sequences × 16 tokens × 512 dims\n",
      "9 layers × 1 sequences × 17 tokens × 512 dims\n",
      "9 layers × 1 sequences × 18 tokens × 512 dims\n",
      "9 layers × 1 sequences × 19 tokens × 512 dims\n",
      "9 layers × 1 sequences × 20 tokens × 512 dims\n",
      "9 layers × 1 sequences × 21 tokens × 512 dims\n",
      "9 layers × 1 sequences × 22 tokens × 512 dims\n",
      "9 layers × 1 sequences × 23 tokens × 512 dims\n",
      "9 layers × 1 sequences × 24 tokens × 512 dims\n",
      "9 layers × 1 sequences × 25 tokens × 512 dims\n",
      "9 layers × 1 sequences × 26 tokens × 512 dims\n",
      "9 layers × 1 sequences × 27 tokens × 512 dims\n",
      "9 layers × 1 sequences × 28 tokens × 512 dims\n",
      "9 layers × 1 sequences × 29 tokens × 512 dims\n",
      "9 layers × 1 sequences × 30 tokens × 512 dims\n",
      "9 layers × 1 sequences × 31 tokens × 512 dims\n",
      "9 layers × 1 sequences × 32 tokens × 512 dims\n",
      "9 layers × 1 sequences × 33 tokens × 512 dims\n",
      "9 layers × 1 sequences × 34 tokens × 512 dims\n",
      "9 layers × 1 sequences × 35 tokens × 512 dims\n",
      "9 layers × 1 sequences × 36 tokens × 512 dims\n",
      "9 layers × 1 sequences × 37 tokens × 512 dims\n",
      "9 layers × 1 sequences × 38 tokens × 512 dims\n",
      "9 layers × 1 sequences × 39 tokens × 512 dims\n",
      "9 layers × 1 sequences × 40 tokens × 512 dims\n",
      "9 layers × 1 sequences × 41 tokens × 512 dims\n",
      "9 layers × 1 sequences × 42 tokens × 512 dims\n",
      "9 layers × 1 sequences × 43 tokens × 512 dims\n",
      "9 layers × 1 sequences × 44 tokens × 512 dims\n",
      "9 layers × 1 sequences × 45 tokens × 512 dims\n",
      "9 layers × 1 sequences × 46 tokens × 512 dims\n",
      "9 layers × 1 sequences × 47 tokens × 512 dims\n",
      "9 layers × 1 sequences × 48 tokens × 512 dims\n",
      "9 layers × 1 sequences × 49 tokens × 512 dims\n",
      "9 layers × 1 sequences × 50 tokens × 512 dims\n",
      "9 layers × 1 sequences × 51 tokens × 512 dims\n",
      "9 layers × 1 sequences × 52 tokens × 512 dims\n",
      "9 layers × 1 sequences × 53 tokens × 512 dims\n",
      "9 layers × 1 sequences × 54 tokens × 512 dims\n",
      "9 layers × 1 sequences × 55 tokens × 512 dims\n",
      "9 layers × 1 sequences × 56 tokens × 512 dims\n",
      "9 layers × 1 sequences × 57 tokens × 512 dims\n",
      "9 layers × 1 sequences × 58 tokens × 512 dims\n",
      "9 layers × 1 sequences × 59 tokens × 512 dims\n",
      "9 layers × 1 sequences × 60 tokens × 512 dims\n",
      "9 layers × 1 sequences × 61 tokens × 512 dims\n",
      "9 layers × 1 sequences × 62 tokens × 512 dims\n",
      "9 layers × 1 sequences × 63 tokens × 512 dims\n",
      "9 layers × 1 sequences × 64 tokens × 512 dims\n",
      "9 layers × 1 sequences × 65 tokens × 512 dims\n",
      "9 layers × 1 sequences × 66 tokens × 512 dims\n",
      "9 layers × 1 sequences × 67 tokens × 512 dims\n",
      "9 layers × 1 sequences × 68 tokens × 512 dims\n",
      "9 layers × 1 sequences × 69 tokens × 512 dims\n",
      "9 layers × 1 sequences × 70 tokens × 512 dims\n",
      "9 layers × 1 sequences × 71 tokens × 512 dims\n",
      "9 layers × 1 sequences × 72 tokens × 512 dims\n",
      "9 layers × 1 sequences × 73 tokens × 512 dims\n",
      "9 layers × 1 sequences × 74 tokens × 512 dims\n",
      "9 layers × 1 sequences × 75 tokens × 512 dims\n",
      "9 layers × 1 sequences × 76 tokens × 512 dims\n",
      "9 layers × 1 sequences × 77 tokens × 512 dims\n",
      "9 layers × 1 sequences × 78 tokens × 512 dims\n",
      "9 layers × 1 sequences × 79 tokens × 512 dims\n",
      "9 layers × 1 sequences × 80 tokens × 512 dims\n",
      "9 layers × 1 sequences × 81 tokens × 512 dims\n",
      "9 layers × 1 sequences × 82 tokens × 512 dims\n",
      "9 layers × 1 sequences × 83 tokens × 512 dims\n",
      "9 layers × 1 sequences × 84 tokens × 512 dims\n",
      "9 layers × 1 sequences × 85 tokens × 512 dims\n",
      "9 layers × 1 sequences × 86 tokens × 512 dims\n",
      "9 layers × 1 sequences × 87 tokens × 512 dims\n",
      "9 layers × 1 sequences × 88 tokens × 512 dims\n",
      "9 layers × 1 sequences × 89 tokens × 512 dims\n",
      "9 layers × 1 sequences × 90 tokens × 512 dims\n",
      "9 layers × 1 sequences × 91 tokens × 512 dims\n",
      "9 layers × 1 sequences × 92 tokens × 512 dims\n",
      "9 layers × 1 sequences × 93 tokens × 512 dims\n",
      "9 layers × 1 sequences × 94 tokens × 512 dims\n",
      "9 layers × 1 sequences × 95 tokens × 512 dims\n",
      "9 layers × 1 sequences × 96 tokens × 512 dims\n",
      "9 layers × 1 sequences × 97 tokens × 512 dims\n",
      "9 layers × 1 sequences × 98 tokens × 512 dims\n",
      "9 layers × 1 sequences × 99 tokens × 512 dims\n",
      "9 layers × 1 sequences × 100 tokens × 512 dims\n",
      "9 layers × 1 sequences × 101 tokens × 512 dims\n",
      "9 layers × 1 sequences × 102 tokens × 512 dims\n",
      "9 layers × 1 sequences × 103 tokens × 512 dims\n",
      "9 layers × 1 sequences × 104 tokens × 512 dims\n",
      "9 layers × 1 sequences × 105 tokens × 512 dims\n",
      "9 layers × 1 sequences × 106 tokens × 512 dims\n",
      "9 layers × 1 sequences × 107 tokens × 512 dims\n",
      "9 layers × 1 sequences × 108 tokens × 512 dims\n",
      "9 layers × 1 sequences × 109 tokens × 512 dims\n",
      "9 layers × 1 sequences × 110 tokens × 512 dims\n",
      "9 layers × 1 sequences × 111 tokens × 512 dims\n",
      "9 layers × 1 sequences × 112 tokens × 512 dims\n",
      "9 layers × 1 sequences × 113 tokens × 512 dims\n",
      "9 layers × 1 sequences × 114 tokens × 512 dims\n",
      "9 layers × 1 sequences × 115 tokens × 512 dims\n",
      "9 layers × 1 sequences × 116 tokens × 512 dims\n",
      "9 layers × 1 sequences × 117 tokens × 512 dims\n",
      "9 layers × 1 sequences × 118 tokens × 512 dims\n",
      "9 layers × 1 sequences × 119 tokens × 512 dims\n",
      "9 layers × 1 sequences × 120 tokens × 512 dims\n",
      "9 layers × 1 sequences × 121 tokens × 512 dims\n",
      "9 layers × 1 sequences × 122 tokens × 512 dims\n",
      "9 layers × 1 sequences × 123 tokens × 512 dims\n",
      "9 layers × 1 sequences × 124 tokens × 512 dims\n",
      "9 layers × 1 sequences × 125 tokens × 512 dims\n",
      "9 layers × 1 sequences × 126 tokens × 512 dims\n",
      "9 layers × 1 sequences × 127 tokens × 512 dims\n",
      "9 layers × 1 sequences × 128 tokens × 512 dims\n",
      "9 layers × 1 sequences × 129 tokens × 512 dims\n",
      "9 layers × 1 sequences × 130 tokens × 512 dims\n",
      "9 layers × 1 sequences × 131 tokens × 512 dims\n",
      "9 layers × 1 sequences × 132 tokens × 512 dims\n",
      "9 layers × 1 sequences × 133 tokens × 512 dims\n",
      "9 layers × 1 sequences × 134 tokens × 512 dims\n",
      "9 layers × 1 sequences × 135 tokens × 512 dims\n",
      "9 layers × 1 sequences × 136 tokens × 512 dims\n",
      "9 layers × 1 sequences × 137 tokens × 512 dims\n",
      "9 layers × 1 sequences × 138 tokens × 512 dims\n",
      "9 layers × 1 sequences × 139 tokens × 512 dims\n",
      "9 layers × 1 sequences × 140 tokens × 512 dims\n",
      "9 layers × 1 sequences × 141 tokens × 512 dims\n",
      "9 layers × 1 sequences × 142 tokens × 512 dims\n",
      "9 layers × 1 sequences × 143 tokens × 512 dims\n",
      "9 layers × 1 sequences × 144 tokens × 512 dims\n",
      "9 layers × 1 sequences × 145 tokens × 512 dims\n",
      "9 layers × 1 sequences × 146 tokens × 512 dims\n",
      "9 layers × 1 sequences × 147 tokens × 512 dims\n",
      "9 layers × 1 sequences × 148 tokens × 512 dims\n",
      "9 layers × 1 sequences × 149 tokens × 512 dims\n",
      "9 layers × 1 sequences × 150 tokens × 512 dims\n",
      "9 layers × 1 sequences × 151 tokens × 512 dims\n",
      "9 layers × 1 sequences × 152 tokens × 512 dims\n",
      "9 layers × 1 sequences × 153 tokens × 512 dims\n",
      "9 layers × 1 sequences × 154 tokens × 512 dims\n",
      "9 layers × 1 sequences × 155 tokens × 512 dims\n",
      "9 layers × 1 sequences × 156 tokens × 512 dims\n",
      "9 layers × 1 sequences × 157 tokens × 512 dims\n",
      "9 layers × 1 sequences × 158 tokens × 512 dims\n",
      "9 layers × 1 sequences × 159 tokens × 512 dims\n",
      "9 layers × 1 sequences × 160 tokens × 512 dims\n",
      "9 layers × 1 sequences × 161 tokens × 512 dims\n",
      "9 layers × 1 sequences × 162 tokens × 512 dims\n",
      "9 layers × 1 sequences × 163 tokens × 512 dims\n",
      "9 layers × 1 sequences × 164 tokens × 512 dims\n",
      "9 layers × 1 sequences × 165 tokens × 512 dims\n",
      "9 layers × 1 sequences × 166 tokens × 512 dims\n",
      "9 layers × 1 sequences × 167 tokens × 512 dims\n",
      "9 layers × 1 sequences × 168 tokens × 512 dims\n",
      "9 layers × 1 sequences × 169 tokens × 512 dims\n",
      "9 layers × 1 sequences × 170 tokens × 512 dims\n",
      "9 layers × 1 sequences × 171 tokens × 512 dims\n",
      "9 layers × 1 sequences × 172 tokens × 512 dims\n",
      "9 layers × 1 sequences × 173 tokens × 512 dims\n",
      "9 layers × 1 sequences × 174 tokens × 512 dims\n",
      "9 layers × 1 sequences × 175 tokens × 512 dims\n",
      "9 layers × 1 sequences × 176 tokens × 512 dims\n",
      "9 layers × 1 sequences × 177 tokens × 512 dims\n",
      "9 layers × 1 sequences × 178 tokens × 512 dims\n",
      "9 layers × 1 sequences × 179 tokens × 512 dims\n",
      "9 layers × 1 sequences × 180 tokens × 512 dims\n",
      "9 layers × 1 sequences × 181 tokens × 512 dims\n",
      "9 layers × 1 sequences × 182 tokens × 512 dims\n",
      "9 layers × 1 sequences × 183 tokens × 512 dims\n",
      "9 layers × 1 sequences × 184 tokens × 512 dims\n",
      "9 layers × 1 sequences × 185 tokens × 512 dims\n",
      "9 layers × 1 sequences × 186 tokens × 512 dims\n",
      "9 layers × 1 sequences × 187 tokens × 512 dims\n",
      "9 layers × 1 sequences × 188 tokens × 512 dims\n",
      "9 layers × 1 sequences × 189 tokens × 512 dims\n",
      "9 layers × 1 sequences × 190 tokens × 512 dims\n",
      "9 layers × 1 sequences × 191 tokens × 512 dims\n",
      "9 layers × 1 sequences × 192 tokens × 512 dims\n",
      "9 layers × 1 sequences × 193 tokens × 512 dims\n",
      "9 layers × 1 sequences × 194 tokens × 512 dims\n",
      "9 layers × 1 sequences × 195 tokens × 512 dims\n",
      "9 layers × 1 sequences × 196 tokens × 512 dims\n",
      "9 layers × 1 sequences × 197 tokens × 512 dims\n",
      "9 layers × 1 sequences × 198 tokens × 512 dims\n",
      "9 layers × 1 sequences × 199 tokens × 512 dims\n",
      "9 layers × 1 sequences × 200 tokens × 512 dims\n",
      "9 layers × 1 sequences × 201 tokens × 512 dims\n",
      "9 layers × 1 sequences × 202 tokens × 512 dims\n",
      "9 layers × 1 sequences × 203 tokens × 512 dims\n",
      "9 layers × 1 sequences × 204 tokens × 512 dims\n",
      "9 layers × 1 sequences × 205 tokens × 512 dims\n",
      "9 layers × 1 sequences × 206 tokens × 512 dims\n",
      "9 layers × 1 sequences × 207 tokens × 512 dims\n",
      "9 layers × 1 sequences × 208 tokens × 512 dims\n",
      "9 layers × 1 sequences × 209 tokens × 512 dims\n",
      "9 layers × 1 sequences × 210 tokens × 512 dims\n",
      "9 layers × 1 sequences × 211 tokens × 512 dims\n",
      "9 layers × 1 sequences × 212 tokens × 512 dims\n",
      "9 layers × 1 sequences × 213 tokens × 512 dims\n",
      "9 layers × 1 sequences × 214 tokens × 512 dims\n",
      "9 layers × 1 sequences × 215 tokens × 512 dims\n",
      "9 layers × 1 sequences × 216 tokens × 512 dims\n",
      "9 layers × 1 sequences × 217 tokens × 512 dims\n",
      "9 layers × 1 sequences × 218 tokens × 512 dims\n",
      "9 layers × 1 sequences × 219 tokens × 512 dims\n",
      "9 layers × 1 sequences × 220 tokens × 512 dims\n",
      "9 layers × 1 sequences × 221 tokens × 512 dims\n",
      "9 layers × 1 sequences × 222 tokens × 512 dims\n",
      "9 layers × 1 sequences × 223 tokens × 512 dims\n",
      "9 layers × 1 sequences × 224 tokens × 512 dims\n",
      "9 layers × 1 sequences × 225 tokens × 512 dims\n",
      "9 layers × 1 sequences × 226 tokens × 512 dims\n",
      "9 layers × 1 sequences × 227 tokens × 512 dims\n",
      "9 layers × 1 sequences × 228 tokens × 512 dims\n",
      "9 layers × 1 sequences × 229 tokens × 512 dims\n",
      "9 layers × 1 sequences × 230 tokens × 512 dims\n",
      "9 layers × 1 sequences × 231 tokens × 512 dims\n",
      "9 layers × 1 sequences × 232 tokens × 512 dims\n",
      "9 layers × 1 sequences × 233 tokens × 512 dims\n",
      "9 layers × 1 sequences × 234 tokens × 512 dims\n",
      "9 layers × 1 sequences × 235 tokens × 512 dims\n",
      "9 layers × 1 sequences × 236 tokens × 512 dims\n",
      "9 layers × 1 sequences × 237 tokens × 512 dims\n",
      "9 layers × 1 sequences × 238 tokens × 512 dims\n",
      "9 layers × 1 sequences × 239 tokens × 512 dims\n",
      "9 layers × 1 sequences × 240 tokens × 512 dims\n",
      "9 layers × 1 sequences × 241 tokens × 512 dims\n",
      "9 layers × 1 sequences × 242 tokens × 512 dims\n",
      "9 layers × 1 sequences × 243 tokens × 512 dims\n",
      "9 layers × 1 sequences × 244 tokens × 512 dims\n",
      "9 layers × 1 sequences × 245 tokens × 512 dims\n",
      "9 layers × 1 sequences × 246 tokens × 512 dims\n",
      "9 layers × 1 sequences × 247 tokens × 512 dims\n",
      "9 layers × 1 sequences × 248 tokens × 512 dims\n",
      "9 layers × 1 sequences × 249 tokens × 512 dims\n",
      "9 layers × 1 sequences × 250 tokens × 512 dims\n",
      "9 layers × 1 sequences × 251 tokens × 512 dims\n",
      "9 layers × 1 sequences × 252 tokens × 512 dims\n",
      "9 layers × 1 sequences × 253 tokens × 512 dims\n",
      "9 layers × 1 sequences × 254 tokens × 512 dims\n",
      "9 layers × 1 sequences × 255 tokens × 512 dims\n",
      "9 layers × 1 sequences × 256 tokens × 512 dims\n",
      "9 layers × 1 sequences × 257 tokens × 512 dims\n",
      "9 layers × 1 sequences × 258 tokens × 512 dims\n",
      "9 layers × 1 sequences × 259 tokens × 512 dims\n",
      "9 layers × 1 sequences × 260 tokens × 512 dims\n",
      "9 layers × 1 sequences × 261 tokens × 512 dims\n",
      "9 layers × 1 sequences × 262 tokens × 512 dims\n",
      "9 layers × 1 sequences × 263 tokens × 512 dims\n",
      "9 layers × 1 sequences × 264 tokens × 512 dims\n",
      "9 layers × 1 sequences × 265 tokens × 512 dims\n",
      "9 layers × 1 sequences × 266 tokens × 512 dims\n",
      "9 layers × 1 sequences × 267 tokens × 512 dims\n",
      "9 layers × 1 sequences × 268 tokens × 512 dims\n",
      "9 layers × 1 sequences × 269 tokens × 512 dims\n",
      "9 layers × 1 sequences × 270 tokens × 512 dims\n",
      "9 layers × 1 sequences × 271 tokens × 512 dims\n",
      "9 layers × 1 sequences × 272 tokens × 512 dims\n",
      "9 layers × 1 sequences × 273 tokens × 512 dims\n",
      "9 layers × 1 sequences × 274 tokens × 512 dims\n",
      "9 layers × 1 sequences × 275 tokens × 512 dims\n",
      "9 layers × 1 sequences × 276 tokens × 512 dims\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                                 | 7/1000 [00:12<29:47,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 512])\n",
      "Hidden states shape: 215 generated tokens × 9 layers × 1 sequences × 9 tokens × 512 dims\n",
      "3053.3718\n",
      "3094.3384\n",
      "3126.664\n",
      "3161.242\n",
      "3190.6506\n",
      "3224.5154\n",
      "3258.2031\n",
      "3294.883\n",
      "3327.5876\n",
      "3356.62\n",
      "3386.0637\n",
      "3415.5413\n",
      "3449.8762\n",
      "3479.3818\n",
      "3504.5295\n",
      "3544.2415\n",
      "3585.6182\n",
      "3612.5876\n",
      "3641.754\n",
      "3677.5908\n",
      "3707.6274\n",
      "3740.2822\n",
      "3778.6252\n",
      "3808.657\n",
      "3843.932\n",
      "3872.2454\n",
      "3898.2944\n",
      "3923.009\n",
      "3948.36\n",
      "3973.0933\n",
      "3999.568\n",
      "4025.4966\n",
      "4046.541\n",
      "4074.7527\n",
      "4112.829\n",
      "4142.8145\n",
      "4162.3687\n",
      "4185.6074\n",
      "4208.4927\n",
      "4231.548\n",
      "4257.3394\n",
      "4279.2446\n",
      "4303.5815\n",
      "4325.398\n",
      "4345.6143\n",
      "4367.111\n",
      "4390.5396\n",
      "4412.9434\n",
      "4432.3687\n",
      "4460.854\n",
      "4484.703\n",
      "4506.1665\n",
      "4530.726\n",
      "4550.9243\n",
      "4571.3027\n",
      "4591.85\n",
      "4613.514\n",
      "4633.2305\n",
      "4653.7026\n",
      "4673.8413\n",
      "4695.4746\n",
      "4714.3354\n",
      "4733.9277\n",
      "4752.5195\n",
      "4775.3315\n",
      "4795.466\n",
      "4814.9907\n",
      "4834.1274\n",
      "4852.351\n",
      "4871.6377\n",
      "4890.369\n",
      "4910.9897\n",
      "4939.5557\n",
      "4963.599\n",
      "4981.765\n",
      "5002.8687\n",
      "5021.7207\n",
      "5040.8384\n",
      "5059.5103\n",
      "5080.339\n",
      "5100.6753\n",
      "5123.162\n",
      "5145.219\n",
      "5170.0786\n",
      "5196.067\n",
      "5217.217\n",
      "5234.8276\n",
      "5257.148\n",
      "5274.8486\n",
      "5295.1543\n",
      "5314.331\n",
      "5334.179\n",
      "5356.618\n",
      "5375.957\n",
      "5400.679\n",
      "5426.295\n",
      "5444.176\n",
      "5461.1924\n",
      "5477.7363\n",
      "5499.3965\n",
      "5518.7607\n",
      "5540.3096\n",
      "5561.668\n",
      "5579.4116\n",
      "5597.93\n",
      "5614.3047\n",
      "5630.1543\n",
      "5650.3945\n",
      "5674.5386\n",
      "5696.4585\n",
      "5713.3027\n",
      "5731.075\n",
      "5751.6855\n",
      "5769.879\n",
      "5786.1284\n",
      "5802.995\n",
      "5819.1904\n",
      "5836.7856\n",
      "5855.476\n",
      "5875.6733\n",
      "5892.183\n",
      "5906.6655\n",
      "5922.2974\n",
      "5936.6323\n",
      "5954.9185\n",
      "5978.653\n",
      "6001.5063\n",
      "6017.736\n",
      "6033.658\n",
      "6049.587\n",
      "6067.9487\n",
      "6083.6343\n",
      "6097.943\n",
      "6114.026\n",
      "6128.591\n",
      "6142.858\n",
      "6156.9233\n",
      "6173.4365\n",
      "6186.6157\n",
      "6202.3403\n",
      "6218.074\n",
      "6230.6\n",
      "6245.506\n",
      "6259.7705\n",
      "6273.3315\n",
      "6288.694\n",
      "6305.4927\n",
      "6322.414\n",
      "6335.363\n",
      "6349.182\n",
      "6362.5454\n",
      "6380.143\n",
      "6395.1978\n",
      "6409.8516\n",
      "6427.299\n",
      "6443.425\n",
      "6460.272\n",
      "6478.3086\n",
      "6499.1685\n",
      "6524.1206\n",
      "6540.64\n",
      "6554.15\n",
      "6567.4136\n",
      "6582.063\n",
      "6599.734\n",
      "6611.186\n",
      "6623.9487\n",
      "6641.5093\n",
      "6656.938\n",
      "6671.928\n",
      "6687.4014\n",
      "6699.646\n",
      "6714.626\n",
      "6727.738\n",
      "6742.581\n",
      "6757.483\n",
      "6774.087\n",
      "6785.779\n",
      "6799.015\n",
      "6810.809\n",
      "6824.729\n",
      "6838.178\n",
      "6849.371\n",
      "6861.929\n",
      "6873.7285\n",
      "6889.3574\n",
      "6906.285\n",
      "6918.569\n",
      "6931.74\n",
      "6946.7393\n",
      "6958.347\n",
      "6970.711\n",
      "6983.442\n",
      "6996.5645\n",
      "7011.0923\n",
      "7024.029\n",
      "7036.951\n",
      "7048.802\n",
      "7061.2437\n",
      "7073.0337\n",
      "7086.178\n",
      "7099.4424\n",
      "7111.7275\n",
      "7124.3066\n",
      "7141.241\n",
      "7152.922\n",
      "7166.164\n",
      "7180.3877\n",
      "7195.3555\n",
      "7209.0396\n",
      "7221.739\n",
      "7234.886\n",
      "7246.891\n",
      "7259.679\n",
      "7271.046\n",
      "9 layers × 1 sequences × 9 tokens × 512 dims\n",
      "9 layers × 1 sequences × 10 tokens × 512 dims\n",
      "9 layers × 1 sequences × 11 tokens × 512 dims\n",
      "9 layers × 1 sequences × 12 tokens × 512 dims\n",
      "9 layers × 1 sequences × 13 tokens × 512 dims\n",
      "9 layers × 1 sequences × 14 tokens × 512 dims\n",
      "9 layers × 1 sequences × 15 tokens × 512 dims\n",
      "9 layers × 1 sequences × 16 tokens × 512 dims\n",
      "9 layers × 1 sequences × 17 tokens × 512 dims\n",
      "9 layers × 1 sequences × 18 tokens × 512 dims\n",
      "9 layers × 1 sequences × 19 tokens × 512 dims\n",
      "9 layers × 1 sequences × 20 tokens × 512 dims\n",
      "9 layers × 1 sequences × 21 tokens × 512 dims\n",
      "9 layers × 1 sequences × 22 tokens × 512 dims\n",
      "9 layers × 1 sequences × 23 tokens × 512 dims\n",
      "9 layers × 1 sequences × 24 tokens × 512 dims\n",
      "9 layers × 1 sequences × 25 tokens × 512 dims\n",
      "9 layers × 1 sequences × 26 tokens × 512 dims\n",
      "9 layers × 1 sequences × 27 tokens × 512 dims\n",
      "9 layers × 1 sequences × 28 tokens × 512 dims\n",
      "9 layers × 1 sequences × 29 tokens × 512 dims\n",
      "9 layers × 1 sequences × 30 tokens × 512 dims\n",
      "9 layers × 1 sequences × 31 tokens × 512 dims\n",
      "9 layers × 1 sequences × 32 tokens × 512 dims\n",
      "9 layers × 1 sequences × 33 tokens × 512 dims\n",
      "9 layers × 1 sequences × 34 tokens × 512 dims\n",
      "9 layers × 1 sequences × 35 tokens × 512 dims\n",
      "9 layers × 1 sequences × 36 tokens × 512 dims\n",
      "9 layers × 1 sequences × 37 tokens × 512 dims\n",
      "9 layers × 1 sequences × 38 tokens × 512 dims\n",
      "9 layers × 1 sequences × 39 tokens × 512 dims\n",
      "9 layers × 1 sequences × 40 tokens × 512 dims\n",
      "9 layers × 1 sequences × 41 tokens × 512 dims\n",
      "9 layers × 1 sequences × 42 tokens × 512 dims\n",
      "9 layers × 1 sequences × 43 tokens × 512 dims\n",
      "9 layers × 1 sequences × 44 tokens × 512 dims\n",
      "9 layers × 1 sequences × 45 tokens × 512 dims\n",
      "9 layers × 1 sequences × 46 tokens × 512 dims\n",
      "9 layers × 1 sequences × 47 tokens × 512 dims\n",
      "9 layers × 1 sequences × 48 tokens × 512 dims\n",
      "9 layers × 1 sequences × 49 tokens × 512 dims\n",
      "9 layers × 1 sequences × 50 tokens × 512 dims\n",
      "9 layers × 1 sequences × 51 tokens × 512 dims\n",
      "9 layers × 1 sequences × 52 tokens × 512 dims\n",
      "9 layers × 1 sequences × 53 tokens × 512 dims\n",
      "9 layers × 1 sequences × 54 tokens × 512 dims\n",
      "9 layers × 1 sequences × 55 tokens × 512 dims\n",
      "9 layers × 1 sequences × 56 tokens × 512 dims\n",
      "9 layers × 1 sequences × 57 tokens × 512 dims\n",
      "9 layers × 1 sequences × 58 tokens × 512 dims\n",
      "9 layers × 1 sequences × 59 tokens × 512 dims\n",
      "9 layers × 1 sequences × 60 tokens × 512 dims\n",
      "9 layers × 1 sequences × 61 tokens × 512 dims\n",
      "9 layers × 1 sequences × 62 tokens × 512 dims\n",
      "9 layers × 1 sequences × 63 tokens × 512 dims\n",
      "9 layers × 1 sequences × 64 tokens × 512 dims\n",
      "9 layers × 1 sequences × 65 tokens × 512 dims\n",
      "9 layers × 1 sequences × 66 tokens × 512 dims\n",
      "9 layers × 1 sequences × 67 tokens × 512 dims\n",
      "9 layers × 1 sequences × 68 tokens × 512 dims\n",
      "9 layers × 1 sequences × 69 tokens × 512 dims\n",
      "9 layers × 1 sequences × 70 tokens × 512 dims\n",
      "9 layers × 1 sequences × 71 tokens × 512 dims\n",
      "9 layers × 1 sequences × 72 tokens × 512 dims\n",
      "9 layers × 1 sequences × 73 tokens × 512 dims\n",
      "9 layers × 1 sequences × 74 tokens × 512 dims\n",
      "9 layers × 1 sequences × 75 tokens × 512 dims\n",
      "9 layers × 1 sequences × 76 tokens × 512 dims\n",
      "9 layers × 1 sequences × 77 tokens × 512 dims\n",
      "9 layers × 1 sequences × 78 tokens × 512 dims\n",
      "9 layers × 1 sequences × 79 tokens × 512 dims\n",
      "9 layers × 1 sequences × 80 tokens × 512 dims\n",
      "9 layers × 1 sequences × 81 tokens × 512 dims\n",
      "9 layers × 1 sequences × 82 tokens × 512 dims\n",
      "9 layers × 1 sequences × 83 tokens × 512 dims\n",
      "9 layers × 1 sequences × 84 tokens × 512 dims\n",
      "9 layers × 1 sequences × 85 tokens × 512 dims\n",
      "9 layers × 1 sequences × 86 tokens × 512 dims\n",
      "9 layers × 1 sequences × 87 tokens × 512 dims\n",
      "9 layers × 1 sequences × 88 tokens × 512 dims\n",
      "9 layers × 1 sequences × 89 tokens × 512 dims\n",
      "9 layers × 1 sequences × 90 tokens × 512 dims\n",
      "9 layers × 1 sequences × 91 tokens × 512 dims\n",
      "9 layers × 1 sequences × 92 tokens × 512 dims\n",
      "9 layers × 1 sequences × 93 tokens × 512 dims\n",
      "9 layers × 1 sequences × 94 tokens × 512 dims\n",
      "9 layers × 1 sequences × 95 tokens × 512 dims\n",
      "9 layers × 1 sequences × 96 tokens × 512 dims\n",
      "9 layers × 1 sequences × 97 tokens × 512 dims\n",
      "9 layers × 1 sequences × 98 tokens × 512 dims\n",
      "9 layers × 1 sequences × 99 tokens × 512 dims\n",
      "9 layers × 1 sequences × 100 tokens × 512 dims\n",
      "9 layers × 1 sequences × 101 tokens × 512 dims\n",
      "9 layers × 1 sequences × 102 tokens × 512 dims\n",
      "9 layers × 1 sequences × 103 tokens × 512 dims\n",
      "9 layers × 1 sequences × 104 tokens × 512 dims\n",
      "9 layers × 1 sequences × 105 tokens × 512 dims\n",
      "9 layers × 1 sequences × 106 tokens × 512 dims\n",
      "9 layers × 1 sequences × 107 tokens × 512 dims\n",
      "9 layers × 1 sequences × 108 tokens × 512 dims\n",
      "9 layers × 1 sequences × 109 tokens × 512 dims\n",
      "9 layers × 1 sequences × 110 tokens × 512 dims\n",
      "9 layers × 1 sequences × 111 tokens × 512 dims\n",
      "9 layers × 1 sequences × 112 tokens × 512 dims\n",
      "9 layers × 1 sequences × 113 tokens × 512 dims\n",
      "9 layers × 1 sequences × 114 tokens × 512 dims\n",
      "9 layers × 1 sequences × 115 tokens × 512 dims\n",
      "9 layers × 1 sequences × 116 tokens × 512 dims\n",
      "9 layers × 1 sequences × 117 tokens × 512 dims\n",
      "9 layers × 1 sequences × 118 tokens × 512 dims\n",
      "9 layers × 1 sequences × 119 tokens × 512 dims\n",
      "9 layers × 1 sequences × 120 tokens × 512 dims\n",
      "9 layers × 1 sequences × 121 tokens × 512 dims\n",
      "9 layers × 1 sequences × 122 tokens × 512 dims\n",
      "9 layers × 1 sequences × 123 tokens × 512 dims\n",
      "9 layers × 1 sequences × 124 tokens × 512 dims\n",
      "9 layers × 1 sequences × 125 tokens × 512 dims\n",
      "9 layers × 1 sequences × 126 tokens × 512 dims\n",
      "9 layers × 1 sequences × 127 tokens × 512 dims\n",
      "9 layers × 1 sequences × 128 tokens × 512 dims\n",
      "9 layers × 1 sequences × 129 tokens × 512 dims\n",
      "9 layers × 1 sequences × 130 tokens × 512 dims\n",
      "9 layers × 1 sequences × 131 tokens × 512 dims\n",
      "9 layers × 1 sequences × 132 tokens × 512 dims\n",
      "9 layers × 1 sequences × 133 tokens × 512 dims\n",
      "9 layers × 1 sequences × 134 tokens × 512 dims\n",
      "9 layers × 1 sequences × 135 tokens × 512 dims\n",
      "9 layers × 1 sequences × 136 tokens × 512 dims\n",
      "9 layers × 1 sequences × 137 tokens × 512 dims\n",
      "9 layers × 1 sequences × 138 tokens × 512 dims\n",
      "9 layers × 1 sequences × 139 tokens × 512 dims\n",
      "9 layers × 1 sequences × 140 tokens × 512 dims\n",
      "9 layers × 1 sequences × 141 tokens × 512 dims\n",
      "9 layers × 1 sequences × 142 tokens × 512 dims\n",
      "9 layers × 1 sequences × 143 tokens × 512 dims\n",
      "9 layers × 1 sequences × 144 tokens × 512 dims\n",
      "9 layers × 1 sequences × 145 tokens × 512 dims\n",
      "9 layers × 1 sequences × 146 tokens × 512 dims\n",
      "9 layers × 1 sequences × 147 tokens × 512 dims\n",
      "9 layers × 1 sequences × 148 tokens × 512 dims\n",
      "9 layers × 1 sequences × 149 tokens × 512 dims\n",
      "9 layers × 1 sequences × 150 tokens × 512 dims\n",
      "9 layers × 1 sequences × 151 tokens × 512 dims\n",
      "9 layers × 1 sequences × 152 tokens × 512 dims\n",
      "9 layers × 1 sequences × 153 tokens × 512 dims\n",
      "9 layers × 1 sequences × 154 tokens × 512 dims\n",
      "9 layers × 1 sequences × 155 tokens × 512 dims\n",
      "9 layers × 1 sequences × 156 tokens × 512 dims\n",
      "9 layers × 1 sequences × 157 tokens × 512 dims\n",
      "9 layers × 1 sequences × 158 tokens × 512 dims\n",
      "9 layers × 1 sequences × 159 tokens × 512 dims\n",
      "9 layers × 1 sequences × 160 tokens × 512 dims\n",
      "9 layers × 1 sequences × 161 tokens × 512 dims\n",
      "9 layers × 1 sequences × 162 tokens × 512 dims\n",
      "9 layers × 1 sequences × 163 tokens × 512 dims\n",
      "9 layers × 1 sequences × 164 tokens × 512 dims\n",
      "9 layers × 1 sequences × 165 tokens × 512 dims\n",
      "9 layers × 1 sequences × 166 tokens × 512 dims\n",
      "9 layers × 1 sequences × 167 tokens × 512 dims\n",
      "9 layers × 1 sequences × 168 tokens × 512 dims\n",
      "9 layers × 1 sequences × 169 tokens × 512 dims\n",
      "9 layers × 1 sequences × 170 tokens × 512 dims\n",
      "9 layers × 1 sequences × 171 tokens × 512 dims\n",
      "9 layers × 1 sequences × 172 tokens × 512 dims\n",
      "9 layers × 1 sequences × 173 tokens × 512 dims\n",
      "9 layers × 1 sequences × 174 tokens × 512 dims\n",
      "9 layers × 1 sequences × 175 tokens × 512 dims\n",
      "9 layers × 1 sequences × 176 tokens × 512 dims\n",
      "9 layers × 1 sequences × 177 tokens × 512 dims\n",
      "9 layers × 1 sequences × 178 tokens × 512 dims\n",
      "9 layers × 1 sequences × 179 tokens × 512 dims\n",
      "9 layers × 1 sequences × 180 tokens × 512 dims\n",
      "9 layers × 1 sequences × 181 tokens × 512 dims\n",
      "9 layers × 1 sequences × 182 tokens × 512 dims\n",
      "9 layers × 1 sequences × 183 tokens × 512 dims\n",
      "9 layers × 1 sequences × 184 tokens × 512 dims\n",
      "9 layers × 1 sequences × 185 tokens × 512 dims\n",
      "9 layers × 1 sequences × 186 tokens × 512 dims\n",
      "9 layers × 1 sequences × 187 tokens × 512 dims\n",
      "9 layers × 1 sequences × 188 tokens × 512 dims\n",
      "9 layers × 1 sequences × 189 tokens × 512 dims\n",
      "9 layers × 1 sequences × 190 tokens × 512 dims\n",
      "9 layers × 1 sequences × 191 tokens × 512 dims\n",
      "9 layers × 1 sequences × 192 tokens × 512 dims\n",
      "9 layers × 1 sequences × 193 tokens × 512 dims\n",
      "9 layers × 1 sequences × 194 tokens × 512 dims\n",
      "9 layers × 1 sequences × 195 tokens × 512 dims\n",
      "9 layers × 1 sequences × 196 tokens × 512 dims\n",
      "9 layers × 1 sequences × 197 tokens × 512 dims\n",
      "9 layers × 1 sequences × 198 tokens × 512 dims\n",
      "9 layers × 1 sequences × 199 tokens × 512 dims\n",
      "9 layers × 1 sequences × 200 tokens × 512 dims\n",
      "9 layers × 1 sequences × 201 tokens × 512 dims\n",
      "9 layers × 1 sequences × 202 tokens × 512 dims\n",
      "9 layers × 1 sequences × 203 tokens × 512 dims\n",
      "9 layers × 1 sequences × 204 tokens × 512 dims\n",
      "9 layers × 1 sequences × 205 tokens × 512 dims\n",
      "9 layers × 1 sequences × 206 tokens × 512 dims\n",
      "9 layers × 1 sequences × 207 tokens × 512 dims\n",
      "9 layers × 1 sequences × 208 tokens × 512 dims\n",
      "9 layers × 1 sequences × 209 tokens × 512 dims\n",
      "9 layers × 1 sequences × 210 tokens × 512 dims\n",
      "9 layers × 1 sequences × 211 tokens × 512 dims\n",
      "9 layers × 1 sequences × 212 tokens × 512 dims\n",
      "9 layers × 1 sequences × 213 tokens × 512 dims\n",
      "9 layers × 1 sequences × 214 tokens × 512 dims\n",
      "9 layers × 1 sequences × 215 tokens × 512 dims\n",
      "9 layers × 1 sequences × 216 tokens × 512 dims\n",
      "9 layers × 1 sequences × 217 tokens × 512 dims\n",
      "9 layers × 1 sequences × 218 tokens × 512 dims\n",
      "9 layers × 1 sequences × 219 tokens × 512 dims\n",
      "9 layers × 1 sequences × 220 tokens × 512 dims\n",
      "9 layers × 1 sequences × 221 tokens × 512 dims\n",
      "9 layers × 1 sequences × 222 tokens × 512 dims\n",
      "9 layers × 1 sequences × 223 tokens × 512 dims\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                                 | 7/1000 [00:14<34:38,  2.09s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 51\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m)):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Generate using pipeline\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# sequences = llamatales_pipeline(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# Generate hidden states from model.generate using same prompt\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer(prompt_text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# outputs = model.generate(\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m#     inputs.input_ids,\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m#     attention_mask=inputs.attention_mask,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m#     generation_config=gen_config\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     generated_story \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1648\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1640\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1641\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1642\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1643\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1644\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1645\u001b[0m     )\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1654\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1655\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1657\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1658\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1659\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1660\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH:\n\u001b[1;32m   1663\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1664\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1665\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1666\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1671\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1672\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:2730\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2727\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2729\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2730\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2731\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2733\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2734\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2735\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2738\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:820\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    817\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    819\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 820\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    832\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:708\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    701\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    702\u001b[0m         create_custom_forward(decoder_layer),\n\u001b[1;32m    703\u001b[0m         hidden_states,\n\u001b[1;32m    704\u001b[0m         attention_mask,\n\u001b[1;32m    705\u001b[0m         position_ids,\n\u001b[1;32m    706\u001b[0m     )\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 708\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:424\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    421\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    423\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 424\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:333\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    331\u001b[0m     kv_seq_len \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m past_key_value[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    332\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_emb(value_states, seq_len\u001b[38;5;241m=\u001b[39mkv_seq_len)\n\u001b[0;32m--> 333\u001b[0m query_states, key_states \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rotary_pos_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;66;03m# reuse k, v, self_attention\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     key_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([past_key_value[\u001b[38;5;241m0\u001b[39m], key_states], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:182\u001b[0m, in \u001b[0;36mapply_rotary_pos_emb\u001b[0;34m(q, k, cos, sin, position_ids)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply_rotary_pos_emb\u001b[39m(q, k, cos, sin, position_ids):\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;66;03m# The first two dimensions of cos and sin are always 1, so we can `squeeze` them.\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m     cos \u001b[38;5;241m=\u001b[39m \u001b[43mcos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# [seq_len, dim]\u001b[39;00m\n\u001b[1;32m    183\u001b[0m     sin \u001b[38;5;241m=\u001b[39m sin\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# [seq_len, dim]\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     cos \u001b[38;5;241m=\u001b[39m cos[position_ids]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [bs, 1, seq_len, dim]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load model/create pipeline\n",
    "model_name = \"ivnle/llamatales_jr_8b-lay8-hs512-hd8-33M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, output_hidden_states=True).to(\"cuda\")\n",
    "# llamatales_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0)\n",
    "# gen_config = GenerationConfig(\n",
    "#     do_sample=True,\n",
    "#     top_k=10,\n",
    "#     max_new_tokens=512,\n",
    "#     output_hidden_states=True,\n",
    "#     return_dict_in_generate=True\n",
    "# )\n",
    "\n",
    "# Prompts\n",
    "prompts = {\n",
    "    1: \"Once upon a time there was a dragon\", \n",
    "    2: \"Once upon a time there was a princess\", \n",
    "    3: \"Once upon a time there were two children\",\n",
    "    4: \"Once upon a time there was a prince\",\n",
    "    5: \"Once upon a time there was a frog\",\n",
    "    6: \"Once upon a time there was a king\",\n",
    "    7: \"Once upon a time there was a queen\",\n",
    "    8: \"Once upon a time there was a wolf\",\n",
    "    9: \"Once upon a time there was a genie\",\n",
    "    10: \"Once upon a time there was a poor boy\"\n",
    "}\n",
    "\n",
    "\n",
    "for prompt_id, prompt_text in prompts.items():\n",
    "    print(f\"Prompt {prompt_id}: \\\"{prompt_text}\\\"\")\n",
    "    data = []\n",
    "    npz_data = {}\n",
    "    hidden_state_file = f'./hidden_states/prompt_{prompt_id}.npz'\n",
    "    for i in tqdm(range(1000)):\n",
    "        # Generate using pipeline\n",
    "        # sequences = llamatales_pipeline(\n",
    "        #     prompt_text,\n",
    "        #     do_sample=True,\n",
    "        #     top_k=10,\n",
    "        #     num_return_sequences=1,\n",
    "        #     max_new_tokens=100\n",
    "        # )\n",
    "        # generated_story = sequences[0]['generated_text']\n",
    "#         print(f\"\\nGenerated (pipeline):\\n{generated_story}\")\n",
    "\n",
    "        # Count tokens\n",
    "        # num_tokens_generated_story = len(tokenizer.encode(generated_story))\n",
    "\n",
    "        # Generate hidden states from model.generate using same prompt\n",
    "        inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "        outputs = model.generate(\n",
    "            inputs.input_ids,\n",
    "            attention_mask=inputs.attention_mask,\n",
    "            do_sample=True,\n",
    "            top_k=10,\n",
    "            num_return_sequences=1,\n",
    "            max_new_tokens=512,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            return_dict_in_generate=True,\n",
    "            output_hidden_states=True,\n",
    "            use_cache = False\n",
    "        )\n",
    "\n",
    "        # outputs = model.generate(\n",
    "        #     inputs.input_ids,\n",
    "        #     attention_mask=inputs.attention_mask,\n",
    "        #     num_return_sequences=1,\n",
    "        #     eos_token_id=tokenizer.eos_token_id,\n",
    "        #     pad_token_id=tokenizer.pad_token_id,\n",
    "        #     generation_config=gen_config\n",
    "        # )\n",
    "        \n",
    "        generated_story = tokenizer.batch_decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)[0]\n",
    "#         print(\"New Story: \\n\", new_story)\n",
    "        \n",
    "#         print(\"Length of Generated Story: \", num_tokens_generated_story)\n",
    "#         print(\"Length of New Story: \", len(tokenizer.encode(new_story)))\n",
    "        \n",
    "        # Map output tokens to prompt ID\n",
    "        # output_id = [prompt_id] * num_tokens_generated_story\n",
    "\n",
    "        # Extract hidden states\n",
    "        convert_hidden_states = []\n",
    "#         print(f\"Type of hidden_states: {type(outputs.hidden_states)}\")\n",
    "        for layer_hidden_states in outputs.hidden_states:\n",
    "            convert_hidden_states.append([t.detach().cpu().numpy() for t in layer_hidden_states])\n",
    "\n",
    "        print(outputs.hidden_states[0][0].shape)\n",
    "\n",
    "        # Debug hidden state shape\n",
    "        print(f\"Hidden states shape: {len(convert_hidden_states)} generated tokens × \"\n",
    "              f\"{len(convert_hidden_states[0])} layers × \"\n",
    "              f\"{len(convert_hidden_states[0][0])} sequences × \"\n",
    "              f\"{len(convert_hidden_states[0][0][0])} tokens × \" \n",
    "              f\"{len(convert_hidden_states[0][0][0][0])} dims\")\n",
    "\n",
    "        for hs in convert_hidden_states:\n",
    "            print(np.linalg.norm(hs))\n",
    "\n",
    "        for n in range(len(convert_hidden_states)):\n",
    "            print(f\"{len(convert_hidden_states[n])} layers × \"\n",
    "                  f\"{len(convert_hidden_states[n][0])} sequences × \"\n",
    "                  f\"{len(convert_hidden_states[n][0][0])} tokens × \" \n",
    "                  f\"{len(convert_hidden_states[n][0][0][0])} dims\")\n",
    "\n",
    "#         print(\"Num Tokens: \", len(convert_hidden_states[0][0][0])) #same as context (length of original generated story)\n",
    "\n",
    "        # Save hidden states to file\n",
    "        # arr = np.empty(len(convert_hidden_states), dtype=object)\n",
    "        # arr[:] = convert_hidden_states\n",
    "        # npz_data[f\"arr_{i}\"] = arr\n",
    "        # npz_data[f\"arr_{i}\"] = convert_hidden_states\n",
    "        \n",
    "        num_tokens_generated_story = len(tokenizer.encode(generated_story))\n",
    "        \n",
    "        # Store results\n",
    "        data.append([prompt_id, prompt_text, generated_story, hidden_state_file, num_tokens_generated_story])\n",
    "    \n",
    "    np.savez_compressed(hidden_state_file, **npz_data)\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=[\"prompt_id\", \"prompt\", \"story\", \"hidden_state_file\", \"len_generated_story\"])\n",
    "    if(prompt_id == 1): df.to_csv(\"story_dataset_new.csv\", index = False)\n",
    "    else:\n",
    "        df.to_csv('story_dataset_new.csv', mode='a', header = False, index = False)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa4176d-39d1-44ee-b202-fb0bfa512b20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load model/create pipeline\n",
    "model_name = \"ivnle/llamatales_jr_8b-lay8-hs512-hd8-33M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, output_hidden_states=True).to(\"cuda\")\n",
    "\n",
    "# Prompts\n",
    "prompts = {\n",
    "    1: \"Once upon a time there was a dragon\", \n",
    "    2: \"Once upon a time there was a princess\", \n",
    "    3: \"Once upon a time there were two children\",\n",
    "    4: \"Once upon a time there was a prince\",\n",
    "    5: \"Once upon a time there was a frog\",\n",
    "    6: \"Once upon a time there was a king\",\n",
    "    7: \"Once upon a time there was a queen\",\n",
    "    8: \"Once upon a time there was a wolf\",\n",
    "    9: \"Once upon a time there was a genie\",\n",
    "    10: \"Once upon a time there was a poor boy\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a132fda2-9475-4205-863a-4763ef0d904d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for prompt in prompts.values():\n",
    "    print(len(tokenizer.encode(prompt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58f5ff0-e577-4c08-98a5-0a85f8ada247",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range(1000):\n",
    "#     if(len(npz_data[f\"arr_{i}\"][0][0][0][0]) != 512):\n",
    "#         # print(i)\n",
    "#         print(len(npz_data[f\"arr_{i}\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2e350f-db30-47d5-8108-2c22889d1792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# npz_data[\"arr_1\"][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f74ce8e-5c0d-46ff-8913-b6edff862302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#100x9x1x9x512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d03cda3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"story_dataset_new.csv\")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
