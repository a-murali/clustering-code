{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f78858-6116-4b7c-b63c-e84194d74685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hidden states by context level and by layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c08f418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /sbksvol/amurali/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/sbksvol/amurali/'\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token = \"<hf_token>\")\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer, AutoModelForCausalLM, pipeline, LlamaForCausalLM\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "194dfcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.13.1+cu117\n",
      "Transformers Version: 4.30.2\n",
      "NumPy Version: 1.21.2\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Transformers Version: {transformers.__version__}\")\n",
    "print(f\"NumPy Version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6337c21e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at ivnle/llamatales_jr_8b-lay8-hs512-hd8-33M and are newly initialized: ['model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1: \"Once upon a time there was a dragon\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                         | 0/1000 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/transformers/generation/utils.py:1260: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  \"You have modified the pretrained model configuration to control generation. This is a\"\n",
      "  1%|▉                                                                                               | 10/1000 [00:17<26:41,  1.62s/it]/opt/conda/lib/python3.7/site-packages/transformers/pipelines/base.py:1084: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  UserWarning,\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [29:41<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 2: \"Once upon a time there was a princess\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [27:49<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 3: \"Once upon a time there were two children\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [26:49<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 4: \"Once upon a time there was a prince\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [31:55<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 5: \"Once upon a time there was a frog\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [31:46<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 6: \"Once upon a time there was a king\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [30:32<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 7: \"Once upon a time there was a queen\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [30:57<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 8: \"Once upon a time there was a wolf\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [29:29<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 9: \"Once upon a time there was a genie\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████████▏                                                                    | 275/1000 [08:31<18:14,  1.51s/it]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [33:47<00:00,  2.03s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load model/create pipeline\n",
    "model_name = \"ivnle/llamatales_jr_8b-lay8-hs512-hd8-33M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, output_hidden_states=True).to(\"cuda\")\n",
    "llamatales_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0)\n",
    "\n",
    "# Prompts\n",
    "prompts = {\n",
    "    1: \"Once upon a time there was a dragon\", \n",
    "    2: \"Once upon a time there was a princess\", \n",
    "    3: \"Once upon a time there were two children\",\n",
    "    4: \"Once upon a time there was a prince\",\n",
    "    5: \"Once upon a time there was a frog\",\n",
    "    6: \"Once upon a time there was a king\",\n",
    "    7: \"Once upon a time there was a queen\",\n",
    "    8: \"Once upon a time there was a wolf\",\n",
    "    9: \"Once upon a time there was a genie\",\n",
    "    10: \"Once upon a time there was a poor boy\"\n",
    "}\n",
    "\n",
    "\n",
    "for prompt_id, prompt_text in prompts.items():\n",
    "    print(f\"Prompt {prompt_id}: \\\"{prompt_text}\\\"\")\n",
    "    data = []\n",
    "    npz_data = {}\n",
    "    hidden_state_file = f'./hidden_states/prompt_{prompt_id}.npz'\n",
    "    for i in tqdm(range(1000)):\n",
    "        # Generate using pipeline\n",
    "        sequences = llamatales_pipeline(\n",
    "            prompt_text,\n",
    "            do_sample=True,\n",
    "            top_k=10,\n",
    "            num_return_sequences=1,\n",
    "            max_new_tokens=100\n",
    "        )\n",
    "        generated_story = sequences[0]['generated_text']\n",
    "#         print(f\"\\nGenerated (pipeline):\\n{generated_story}\")\n",
    "\n",
    "        # Count tokens\n",
    "        num_tokens_generated_story = len(tokenizer.encode(generated_story))\n",
    "\n",
    "        # Generate hidden states from model.generate using same prompt\n",
    "        inputs = tokenizer(generated_story, return_tensors=\"pt\").to(\"cuda\")\n",
    "        outputs = model.generate(\n",
    "            inputs.input_ids,\n",
    "            attention_mask=inputs.attention_mask,\n",
    "            do_sample=True,\n",
    "            top_k=10,\n",
    "            num_return_sequences=1,\n",
    "            max_new_tokens=1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            return_dict_in_generate=True,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        \n",
    "        new_story = tokenizer.batch_decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)[0]\n",
    "#         print(\"New Story: \\n\", new_story)\n",
    "        \n",
    "#         print(\"Length of Generated Story: \", num_tokens_generated_story)\n",
    "#         print(\"Length of New Story: \", len(tokenizer.encode(new_story)))\n",
    "        \n",
    "        # Map output tokens to prompt ID\n",
    "        output_id = [prompt_id] * num_tokens_generated_story\n",
    "\n",
    "        # Extract hidden states\n",
    "        convert_hidden_states = []\n",
    "#         print(f\"Type of hidden_states: {type(outputs.hidden_states)}\")\n",
    "        for layer_hidden_states in outputs.hidden_states:\n",
    "            convert_hidden_states.append([t.detach().cpu().numpy() for t in layer_hidden_states])\n",
    "\n",
    "        # Debug hidden state shape\n",
    "#         print(f\"Hidden states shape: {len(convert_hidden_states)} generated tokens × \"\n",
    "#               f\"{len(convert_hidden_states[0])} layers × \"\n",
    "#               f\"{len(convert_hidden_states[0][0])} sequences × \"\n",
    "#               f\"{len(convert_hidden_states[0][0][0])} tokens × \" \n",
    "#               f\"{len(convert_hidden_states[0][0][0][0])} dims\")\n",
    "\n",
    "#         print(\"Num Tokens: \", len(convert_hidden_states[0][0][0])) #same as context (length of original generated story)\n",
    "\n",
    "        # Save hidden states to file\n",
    "        npz_data[f\"arr_{i}\"] = convert_hidden_states\n",
    "        \n",
    "        # Store results\n",
    "        data.append([prompt_id, prompt_text, generated_story, hidden_state_file, num_tokens_generated_story, len(tokenizer.encode(new_story))])\n",
    "    \n",
    "    np.savez_compressed(hidden_state_file, **npz_data)\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=[\"prompt_id\", \"prompt\", \"story\", \"hidden_state_file\", \"len_generated_story\", \"len_new_story\"])\n",
    "    if(prompt_id == 1): df.to_csv(\"story_dataset_new.csv\", index = False)\n",
    "    else:\n",
    "        df.to_csv('story_dataset_new.csv', mode='a', header = False, index = False)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d03cda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>story</th>\n",
       "      <th>hidden_state_file</th>\n",
       "      <th>len_generated_story</th>\n",
       "      <th>len_new_story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon named Blaz...</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>270</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon named Spar...</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>349</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon named Scor...</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>278</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon. The drago...</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>117</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon. The drago...</td>\n",
       "      <td>./hidden_states/prompt_1.npz</td>\n",
       "      <td>129</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>289</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>127</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10</td>\n",
       "      <td>Once upon a time there was a poor boy</td>\n",
       "      <td>Once upon a time there was a poor boy named Ti...</td>\n",
       "      <td>./hidden_states/prompt_10.npz</td>\n",
       "      <td>520</td>\n",
       "      <td>521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prompt_id                                 prompt  \\\n",
       "0             1    Once upon a time there was a dragon   \n",
       "1             1    Once upon a time there was a dragon   \n",
       "2             1    Once upon a time there was a dragon   \n",
       "3             1    Once upon a time there was a dragon   \n",
       "4             1    Once upon a time there was a dragon   \n",
       "...         ...                                    ...   \n",
       "9995         10  Once upon a time there was a poor boy   \n",
       "9996         10  Once upon a time there was a poor boy   \n",
       "9997         10  Once upon a time there was a poor boy   \n",
       "9998         10  Once upon a time there was a poor boy   \n",
       "9999         10  Once upon a time there was a poor boy   \n",
       "\n",
       "                                                  story  \\\n",
       "0     Once upon a time there was a dragon named Blaz...   \n",
       "1     Once upon a time there was a dragon named Spar...   \n",
       "2     Once upon a time there was a dragon named Scor...   \n",
       "3     Once upon a time there was a dragon. The drago...   \n",
       "4     Once upon a time there was a dragon. The drago...   \n",
       "...                                                 ...   \n",
       "9995  Once upon a time there was a poor boy named Ti...   \n",
       "9996  Once upon a time there was a poor boy named Ti...   \n",
       "9997  Once upon a time there was a poor boy named Ti...   \n",
       "9998  Once upon a time there was a poor boy named Ti...   \n",
       "9999  Once upon a time there was a poor boy named Ti...   \n",
       "\n",
       "                  hidden_state_file  len_generated_story  len_new_story  \n",
       "0      ./hidden_states/prompt_1.npz                  270            271  \n",
       "1      ./hidden_states/prompt_1.npz                  349            350  \n",
       "2      ./hidden_states/prompt_1.npz                  278            278  \n",
       "3      ./hidden_states/prompt_1.npz                  117            118  \n",
       "4      ./hidden_states/prompt_1.npz                  129            130  \n",
       "...                             ...                  ...            ...  \n",
       "9995  ./hidden_states/prompt_10.npz                  289            290  \n",
       "9996  ./hidden_states/prompt_10.npz                  119            119  \n",
       "9997  ./hidden_states/prompt_10.npz                  127            128  \n",
       "9998  ./hidden_states/prompt_10.npz                  441            441  \n",
       "9999  ./hidden_states/prompt_10.npz                  520            521  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"story_dataset_new.csv\")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
