{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c08f418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /sbksvol/amurali/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/sbksvol/amurali/'\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token = \"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\")\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer, AutoModelForCausalLM, pipeline, LlamaForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "194dfcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.13.1+cu117\n",
      "Transformers Version: 4.30.2\n",
      "NumPy Version: 1.21.2\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Transformers Version: {transformers.__version__}\")\n",
    "print(f\"NumPy Version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b169aa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at ivnle/llamatales_jr_8b-lay8-hs512-hd8-33M and are newly initialized: ['model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/generation/utils.py:1260: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  \"You have modified the pretrained model configuration to control generation. This is a\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Story:  Once upon a time there was a dragon. The dragon was a kind friend. The dragon lived in a big cave.\n",
      "\n",
      "One day, the dragon's tummy was growling. It wanted some honey from the bees. The dragon said, \"I don't care. I demand honey, not be a dragon!\"\n",
      "\n",
      "The dragon's tummy growled louder. Just then, a friendly squirrel said, \"Hello, dragon! I saw you were hungry.\" The dragon said, \"Yes, I am very hungry.\" The squirrel said, \"Come to our house, and I will give you some yummy bread.\" The dragon said, \"That would be great, let me fly, there were butterflies in class, there was a kind and a young boy named Timmy's house on a beautiful castle. The king and not to beady, in an ordinary, a little bird's mother birdfnitting time, there on holiday day, in a very good boy in a bravely on a faraway castle. She lived in the dragon loved friend asked to eat time. The dragon, the dragon who were buzzing dragon who made of, who will make it's not a little dragon friends must be kind to be a mean dragon. I mean to its eyes of in the cave-in-giver, who comes from the forest dragons are the dragon in the same time. I am I have been hungry! But I was too.\n",
      "\n",
      "The bear, I have some food for a big, sweet treats. please. Please come toasty, please it was very please!\" Rosie the other birds in that is always?\" The world of a brave rabbit named Timmy.\n",
      "\n",
      "The west side of my farm. 6 areuse a guard the top of his, and he wanted for the dragon. It was no. He was going to her little village called. The king's family.\n",
      "\n",
      "One of the kingdom. Benny was a happy little boy. The end.\n",
      "Input Shape:  390\n",
      "New Story:  Once upon a time there was a dragon. The dragon was a kind friend. The dragon lived in a big cave.\n",
      "\n",
      "One day, the dragon's tummy was growling. It wanted some honey from the bees. The dragon said, \"I don't care. I demand honey, not be a dragon!\"\n",
      "\n",
      "The dragon's tummy growled louder. Just then, a friendly squirrel said, \"Hello, dragon! I saw you were hungry.\" The dragon said, \"Yes, I am very hungry.\" The squirrel said, \"Come to our house, and I will give you some yummy bread.\" The dragon said, \"That would be great, let me fly, there were butterflies in class, there was a kind and a young boy named Timmy's house on a beautiful castle. The king and not to beady, in an ordinary, a little bird's mother birdfnitting time, there on holiday day, in a very good boy in a bravely on a faraway castle. She lived in the dragon loved friend asked to eat time. The dragon, the dragon who were buzzing dragon who made of, who will make it's not a little dragon friends must be kind to be a mean dragon. I mean to its eyes of in the cave-in-giver, who comes from the forest dragons are the dragon in the same time. I am I have been hungry! But I was too.\n",
      "\n",
      "The bear, I have some food for a big, sweet treats. please. Please come toasty, please it was very please!\" Rosie the other birds in that is always?\" The world of a brave rabbit named Timmy.\n",
      "\n",
      "The west side of my farm. 6 areuse a guard the top of his, and he wanted for the dragon. It was no. He was going to her little village called. The king's family.\n",
      "\n",
      "One of the kingdom. Benny was a happy little boy. The end.等.um_unknown regulatingطبيقPlayersطبيق Cakeponطبيق-basedطبيقbad Cakepon Cake CakeIdentitypon pointspon geldi等Crطبيقponطبيقطبيقbad等ponطبيقponطبيق等 CakeIdentity_unknownpon Cakeponطبيق不能为空طبيق不能为空 ΣύIdentity counties等 CakeIdentity Cakeطبيقbad regulatingIdentity points等 Cakeヨطبيقbad等.interpolateطبيقbad Cakepon等 CakePlayers(qu countiesPlayers(qu counties regulating Cake shark Σύ ΣύIdentity等JSON-fl234 Σύpon等.interpolate Σύ_unknownpon CakePlayerspon voor_unknownpon Meth\n",
      "Length of Generated Story:  390\n",
      "Length of New Story:  492\n",
      "Hidden States Type:  <class 'tuple'>\n",
      "Hidden States Length:  100\n",
      "Hidden States Shape:  torch.Size([1, 490])\n",
      "100\n",
      "9\n",
      "1\n",
      "390\n",
      "512\n",
      "Original Story:  Once upon a time there was a dragon. The dragon's name was Blaze. Blaze loved to play. He had a favorite ball that he used as a weapon.\n",
      "\n",
      "One day, while Blaze was playing, he accidentally knocked over a jar of yummy jam. The jam spilled all over the ground.\n",
      "\n",
      "The jam made the ground slippery. The other animals on the farm were worried about the jam. They decided to help the animals by picking up the jam.\n",
      "\n",
      "The animals worked together and cleaned up the jam. The animals cheered and thanked each other for helping. The farm was happy and clean again.\n",
      "Input Shape:  119\n",
      "New Story:  Once upon a time there was a dragon. The dragon's name was Blaze. Blaze loved to play. He had a favorite ball that he used as a weapon.\n",
      "\n",
      "One day, while Blaze was playing, he accidentally knocked over a jar of yummy jam. The jam spilled all over the ground.\n",
      "\n",
      "The jam made the ground slippery. The other animals on the farm were worried about the jam. They decided to help the animals by picking up the jam.\n",
      "\n",
      "The animals worked together and cleaned up the jam. The animals cheered and thanked each other for helping. The farm was happy and clean again. dimension dimension(Settings خارجxoops biçimdexoopsради خارجради ColonрадиBullet Barang.PNG dimension Colon communications@Bulletwersради Colon Colon силаради.LOG Colon dimensionрадиANI kidd dimensionради Colonрадиради#endregion__\n",
      "\n",
      "радиANI#endregionแตради.LOG dimension__\n",
      "\n",
      "ради capacitor(APрадиxoops christmas Colonxoops dimension christmas_computeрадиxoops Colon__\n",
      "\n",
      "(Settings dimension Colon dimensionwargsipeMac communications.PNG_computeمحمدANI kiddwargsрадирадиради capacitor Colonwargs dimensionради capacitor Colon__\n",
      "\n",
      "(Settings Colon kiddمیują__\n",
      "\n",
      "wargsjong dimension Colon__\n",
      "\n",
      "wargs510\n",
      "Length of Generated Story:  119\n",
      "Length of New Story:  221\n",
      "Hidden States Type:  <class 'tuple'>\n",
      "Hidden States Length:  100\n",
      "Hidden States Shape:  torch.Size([1, 219])\n",
      "100\n",
      "9\n",
      "1\n",
      "119\n",
      "512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>story</th>\n",
       "      <th>hidden_states</th>\n",
       "      <th>output_token_prompt_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon. The drago...</td>\n",
       "      <td>[[[[[ 0.0494013   0.00089496  0.0048408  ...  ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon. The drago...</td>\n",
       "      <td>[[[[[ 0.00301773 -0.00446444  0.01138372 ...  ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                prompt  \\\n",
       "0  Once upon a time there was a dragon   \n",
       "1  Once upon a time there was a dragon   \n",
       "\n",
       "                                               story  \\\n",
       "0  Once upon a time there was a dragon. The drago...   \n",
       "1  Once upon a time there was a dragon. The drago...   \n",
       "\n",
       "                                       hidden_states  \\\n",
       "0  [[[[[ 0.0494013   0.00089496  0.0048408  ...  ...   \n",
       "1  [[[[[ 0.00301773 -0.00446444  0.01138372 ...  ...   \n",
       "\n",
       "                              output_token_prompt_id  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = \"ivnle/llamatales_jr_8b-lay8-hs512-hd8-33M\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "# llamatales_pipeline = pipeline(\"text-generation\", model = model, device = torch.cuda.current_device())\n",
    "\n",
    "# # prompts = {\n",
    "# #     1: \"Once upon a time there was a dragon\", \n",
    "# #     2: \"Once upon a time there was a princess\", \n",
    "# #     3: \"Once upon a time there were two children\",\n",
    "# #     4: \"Once upon a time there was a prince\",\n",
    "# #     5: \"Once upon a time there was a frog\",\n",
    "# #     6: \"Once upon a time there was a king\",\n",
    "# #     7: \"Once upon a time there was a queen\",\n",
    "# #     8: \"Once upon a time there was a wolf\",\n",
    "# #     9: \"Once upon a time there was a genie\",\n",
    "# #     10: \"Once upon a time there was a poor boy\"\n",
    "# # }\n",
    "# prompts = {1: \"Once upon a time there was a dragon\"}\n",
    "\n",
    "# data = []\n",
    "# for prompt_id in prompts:\n",
    "#     #generation - generate stories for each prompt\n",
    "#     for i in range(2):\n",
    "#         sequences = llamatales_pipeline(\n",
    "#             prompts[prompt_id],\n",
    "#             do_sample = True,\n",
    "#             top_k = 10,\n",
    "#             num_return_sequences = 1,\n",
    "#             max_new_tokens = 512,\n",
    "#         )\n",
    "\n",
    "# #         print(llamatales_pipeline.model.config)\n",
    "# #         print(llamatales_pipeline.model.generation_config.to_dict())\n",
    "        \n",
    "#         generated_story = sequences[0]['generated_text']\n",
    "#         print(\"Original Story: \", generated_story)\n",
    "\n",
    "#         num_tokens_generated_story = len(tokenizer.encode(generated_story))\n",
    "\n",
    "#         #test - collect hidden states\n",
    "        \n",
    "#         config = llamatales_pipeline.model.config #AutoConfig.from_pretrained(\"/expanse/lustre/projects/csd819/a3murali/cache/models--ivnle--llamatales_jr_8b-lay8-hs512-hd8-33M/snapshots/461f50f0024efb46b94dc68cc850d12d75ecb325\", output_hidden_states = True)\n",
    "#         model = AutoModelForCausalLM.from_config(config).to('cuda')\n",
    "#         # if(i == 0):\n",
    "#         #     print(model)\n",
    "            \n",
    "#         #     for j in model.named_parameters():\n",
    "#         #         print(f\"{j[0]} -> {j[1].device}\")\n",
    "\n",
    "\n",
    "# #         tokenizer = AutoTokenizer.from_pretrained(\"/sbksvol/amurali/hub/models--ivnle--llamatales_jr_8b-lay8-hs512-hd8-33M/snapshots/461f50f0024efb46b94dc68cc850d12d75ecb325/\", config = config)\n",
    "\n",
    "#         inputs = tokenizer(generated_story, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "#         print(\"Input Shape: \", inputs.input_ids.shape[1])\n",
    "\n",
    "#         outputs = model.generate(inputs.input_ids, attention_mask=inputs[\"attention_mask\"], do_sample = True, top_k = 10, num_return_sequences = 1, max_new_tokens = 100, eos_token_id = tokenizer.eos_token_id, pad_token_id = tokenizer.pad_token_id, output_hidden_states = True, return_dict_in_generate=True)\n",
    "\n",
    "#         new_story = tokenizer.batch_decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)[0]\n",
    "        \n",
    "#         print(\"New Story: \", new_story)\n",
    "#         print(\"Length of Generated Story: \", num_tokens_generated_story)\n",
    "#         print(\"Length of New Story: \", len(tokenizer.encode(new_story)))\n",
    "#         #analysis - collect prompt id of each token\n",
    "#         output_id = []\n",
    "#         for token in range(num_tokens_generated_story):\n",
    "#             output_id.append(prompt_id)\n",
    "        \n",
    "#         convert_hidden_states = []\n",
    "#         print(\"Hidden States Type: \", type(outputs.hidden_states))\n",
    "#         print(\"Hidden States Length: \", len(outputs.hidden_states))\n",
    "#         print(\"Hidden States Shape: \", outputs.sequences.shape)\n",
    "\n",
    "#         for i in outputs.hidden_states:\n",
    "#             convert_hidden_states.append([j.detach().cpu().numpy() for j in i])\n",
    "        \n",
    "#         print(len(convert_hidden_states))\n",
    "#         print(len(convert_hidden_states[0]))\n",
    "#         print(len(convert_hidden_states[0][0]))\n",
    "#         print(len(convert_hidden_states[0][0][0]))\n",
    "#         print(len(convert_hidden_states[0][0][0][0]))\n",
    "#         # print(len(convert_hidden_states[0][0][0][0][0]))\n",
    "#         data.append([prompts[prompt_id], generated_story, convert_hidden_states, np.array(output_id)])\n",
    "\n",
    "#         #(([]))\n",
    "\n",
    "# df = pd.DataFrame(data, columns = [\"prompt\", \"story\", \"hidden_states\", \"output_token_prompt_id\"], dtype = 'object')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6337c21e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at ivnle/llamatales_jr_8b-lay8-hs512-hd8-33M and are newly initialized: ['model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/generation/utils.py:1260: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  \"You have modified the pretrained model configuration to control generation. This is a\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated (pipeline):\n",
      "Once upon a time there was a dragon. The dragon loved to swim in the ocean with his best friend, a little fish named Fin.\n",
      "\n",
      "One sunny day, the dragon and Fin decided to have a contest. They would dive down deep and see if they were the right size.\n",
      "\n",
      "The dragon was very strong. He breathed fire and scared the fish. They ran away, and the dragon was left alone and sad.\n",
      "New Story: \n",
      " Once upon a time there was a dragon. The dragon loved to swim in the ocean with his best friend, a little fish named Fin.\n",
      "\n",
      "One sunny day, the dragon and Fin decided to have a contest. They would dive down deep and see if they were the right size.\n",
      "\n",
      "The dragon was very strong. He breathed fire and scared the fish. They ran away, and the dragon was left alone and sad.\n",
      "Length of Generated Story:  84\n",
      "Length of New Story:  84\n",
      "Type of hidden_states: <class 'tuple'>\n",
      "Hidden states shape: 1 generated tokens × 9 layers × 1 sequences × 84 tokens × 512 dims\n",
      "\n",
      "Generated (pipeline):\n",
      "Once upon a time there was a dragon named Blazes. Blazes loved to play outside. One day, Blazes found a big, shiny diamond in the grass. \n",
      "\n",
      "Blazes thought he could get the diamond. He tried to climb up the rock, but it was too heavy. Blazes fell down and hurt his knee. \n",
      "\n",
      "Blazes learned a lesson. He should not try to do things that are too big and too hard.\n",
      "New Story: \n",
      " Once upon a time there was a dragon named Blazes. Blazes loved to play outside. One day, Blazes found a big, shiny diamond in the grass. \n",
      "\n",
      "Blazes thought he could get the diamond. He tried to climb up the rock, but it was too heavy. Blazes fell down and hurt his knee. \n",
      "\n",
      "Blazes learned a lesson. He should not try to do things that are too big and too hard. From\n",
      "Length of Generated Story:  90\n",
      "Length of New Story:  91\n",
      "Type of hidden_states: <class 'tuple'>\n",
      "Hidden states shape: 1 generated tokens × 9 layers × 1 sequences × 90 tokens × 512 dims\n"
     ]
    }
   ],
   "source": [
    "# Load model + tokenizer once\n",
    "model_name = \"ivnle/llamatales_jr_8b-lay8-hs512-hd8-33M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, output_hidden_states=True).to(\"cuda\")\n",
    "llamatales_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0)\n",
    "\n",
    "# Prompts\n",
    "prompts = {1: \"Once upon a time there was a dragon\"}\n",
    "\n",
    "data = []\n",
    "for prompt_id, prompt_text in prompts.items():\n",
    "    for i in range(2):\n",
    "        # Generate using pipeline\n",
    "        sequences = llamatales_pipeline(\n",
    "            prompt_text,\n",
    "            do_sample=True,\n",
    "            top_k=10,\n",
    "            num_return_sequences=1,\n",
    "            max_new_tokens=512\n",
    "        )\n",
    "        generated_story = sequences[0]['generated_text']\n",
    "        print(f\"\\nGenerated (pipeline):\\n{generated_story}\")\n",
    "\n",
    "        # Count tokens\n",
    "        num_tokens_generated_story = len(tokenizer.encode(generated_story))\n",
    "\n",
    "        # Generate hidden states from model.generate using same prompt\n",
    "        inputs = tokenizer(generated_story, return_tensors=\"pt\").to(\"cuda\")\n",
    "        outputs = model.generate(\n",
    "            inputs.input_ids,\n",
    "            attention_mask=inputs.attention_mask,\n",
    "            do_sample=True,\n",
    "            top_k=10,\n",
    "            num_return_sequences=1,\n",
    "            max_new_tokens=1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            return_dict_in_generate=True,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        \n",
    "        new_story = tokenizer.batch_decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)[0]\n",
    "        print(\"New Story: \\n\", new_story)\n",
    "        \n",
    "        print(\"Length of Generated Story: \", num_tokens_generated_story)\n",
    "        print(\"Length of New Story: \", len(tokenizer.encode(new_story)))\n",
    "        \n",
    "        # Map output tokens to prompt ID\n",
    "        output_id = [prompt_id] * num_tokens_generated_story\n",
    "\n",
    "        # Extract hidden states\n",
    "        convert_hidden_states = []\n",
    "        print(f\"Type of hidden_states: {type(outputs.hidden_states)}\")\n",
    "        for layer_hidden_states in outputs.hidden_states:\n",
    "            convert_hidden_states.append([t.detach().cpu().numpy() for t in layer_hidden_states])\n",
    "\n",
    "        # Debug hidden state shape\n",
    "        print(f\"Hidden states shape: {len(convert_hidden_states)} generated tokens × \"\n",
    "              f\"{len(convert_hidden_states[0])} layers × \"\n",
    "              f\"{len(convert_hidden_states[0][0])} sequences × \"\n",
    "              f\"{len(convert_hidden_states[0][0][0])} tokens × \" \n",
    "              f\"{len(convert_hidden_states[0][0][0][0])} dims\")\n",
    "\n",
    "        # Store result\n",
    "        data.append([prompt_text, generated_story, convert_hidden_states, np.array(output_id)])\n",
    "\n",
    "# Save all results\n",
    "df = pd.DataFrame(data, columns=[\"prompt\", \"story\", \"hidden_states\", \"output_token_prompt_id\"], dtype='object')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d03cda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>story</th>\n",
       "      <th>hidden_states</th>\n",
       "      <th>output_token_prompt_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon. The drago...</td>\n",
       "      <td>[[[[[-0.03662109 -0.02307129  0.00071716 ...  ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon named Blaz...</td>\n",
       "      <td>[[[[[-0.03662109 -0.02307129  0.00071716 ...  ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                prompt  \\\n",
       "0  Once upon a time there was a dragon   \n",
       "1  Once upon a time there was a dragon   \n",
       "\n",
       "                                               story  \\\n",
       "0  Once upon a time there was a dragon. The drago...   \n",
       "1  Once upon a time there was a dragon named Blaz...   \n",
       "\n",
       "                                       hidden_states  \\\n",
       "0  [[[[[-0.03662109 -0.02307129  0.00071716 ...  ...   \n",
       "1  [[[[[-0.03662109 -0.02307129  0.00071716 ...  ...   \n",
       "\n",
       "                              output_token_prompt_id  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "802f2b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"story_dataset.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
