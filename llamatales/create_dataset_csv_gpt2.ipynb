{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b169aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.7.0+cu126\n",
      "Transformers Version: 4.52.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "{'max_length': 20, 'max_new_tokens': None, 'min_length': 0, 'min_new_tokens': None, 'early_stopping': False, 'max_time': None, 'stop_strings': None, 'do_sample': False, 'num_beams': 1, 'num_beam_groups': 1, 'penalty_alpha': None, 'dola_layers': None, 'use_cache': True, 'cache_implementation': None, 'cache_config': None, 'return_legacy_cache': None, 'prefill_chunk_size': None, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'min_p': None, 'typical_p': 1.0, 'epsilon_cutoff': 0.0, 'eta_cutoff': 0.0, 'diversity_penalty': 0.0, 'repetition_penalty': 1.0, 'encoder_repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'bad_words_ids': None, 'force_words_ids': None, 'renormalize_logits': False, 'constraints': None, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'forced_decoder_ids': None, 'sequence_bias': None, 'token_healing': False, 'guidance_scale': None, 'low_memory': None, 'watermarking_config': None, 'num_return_sequences': 1, 'output_attentions': False, 'output_hidden_states': False, 'output_scores': False, 'output_logits': None, 'return_dict_in_generate': False, 'pad_token_id': None, 'bos_token_id': 128000, 'eos_token_id': 128009, 'encoder_no_repeat_ngram_size': 0, 'decoder_start_token_id': None, 'is_assistant': False, 'num_assistant_tokens': 20, 'num_assistant_tokens_schedule': 'constant', 'assistant_confidence_threshold': 0.4, 'prompt_lookup_num_tokens': None, 'max_matching_ngram_size': None, 'assistant_early_exit': None, 'assistant_lookbehind': 10, 'target_lookbehind': 10, 'disable_compile': False, 'generation_kwargs': {}, '_from_model_config': True, 'transformers_version': '4.52.4'}\n",
      "Once upon a time there was a dragon named Scorch. Scorch loved to play outside in the sunshine. He would jump and roar with joy, making all the animals in the forest laugh. The animals loved Scorch, and he was very happy.\n",
      "\n",
      "One day, Scorch found a special key. The key was shiny and bright, and it fit perfectly into a locked box. A little rabbit named Rosie said, \"Wow, Scorch, you're very brave! I bet you can unlock the box easily.\" Scorch smiled and said, \"I bet I can unlock it easily, but I have to remember to lock the box when I'm done with my key.\"\n",
      "\n",
      "The next day, Scorch tried the key on a big, old chest. The chest creaked open, and inside, it had a big, beautiful diamond! The animals all gasped in surprise. Rosie said, \"I knew you could do it, Scorch!\" Scorch beamed with pride and said, \"I knew I could do it! And I think I'll keep the diamond safe until I find the key to the treasure box.\"\n",
      "\n",
      "The animals all cheered and clapped for Scorch. They were all so happy that he had unlocked the treasure box with the special key. From that day on, Scorch was known as the bravest dragon in the forest. And whenever he looked at the diamond, he remembered that he had a special key that would unlock the treasure box, and everything would be just right.\n",
      "\n",
      "The animals all looked up to Scorch for being so brave and smart. And Scorch was happy to be a hero. He knew that he could do anything if he just tried his best. The end.\n",
      "Input Shape:  347\n",
      "Once upon a time there was a dragon named Scorch. Scorch loved to play outside in the sunshine. He would jump and roar with joy, making all the animals in the forest laugh. The animals loved Scorch, and he was very happy.\n",
      "\n",
      "One day, Scorch found a special key. The key was shiny and bright, and it fit perfectly into a locked box. A little rabbit named Rosie said, \"Wow, Scorch, you're very brave! I bet you can unlock the box easily.\" Scorch smiled and said, \"I bet I can unlock it easily, but I have to remember to lock the box when I'm done with my key.\"\n",
      "\n",
      "The next day, Scorch tried the key on a big, old chest. The chest creaked open, and inside, it had a big, beautiful diamond! The animals all gasped in surprise. Rosie said, \"I knew you could do it, Scorch!\" Scorch beamed with pride and said, \"I knew I could do it! And I think I'll keep the diamond safe until I find the key to the treasure box.\"\n",
      "\n",
      "The animals all cheered and clapped for Scorch. They were all so happy that he had unlocked the treasure box with the special key. From that day on, Scorch was known as the bravest dragon in the forest. And whenever he looked at the diamond, he remembered that he had a special key that would unlock the treasure box, and everything would be just right.\n",
      "\n",
      "The animals all looked up to Scorch for being so brave and smart. And Scorch was happy to be a hero. He knew that he could do anything if he just tried his best. The end. 행정_typ علیهmovement 행정released.Percentreleasedreleased�行 bor 행정 행정.Percent.Percent SaddineryMSN.Percent惊.PercentMSNcrementMSN 행정_information lattice.Percentreleased Jedi Theodoremovement Jedi hace Conanшибкаencoder Aerreleased 행정 Dak.getAccount.Percent_information základě� 행정 행정MSN Dak secondary.Percentreleased.Percent.Percentpassword علیه 행정 علیه Dak triviaアン.Percentcrement_information_totals.Percentiểm�行�行 행정 Dak Navigate三年ideoMSN.Percentcrement.Percent ecl Jedireleasedpunkt RoomsreleasedScala.PercentMSN lattice Aermovement.getAccount 행정.Percentcrement_information.Percent Jedi علیه.Percent\n",
      "Hidden States Type:  <class 'tuple'>\n",
      "Hidden States Length:  100\n",
      "Hidden States Shape:  torch.Size([1, 447])\n",
      "100\n",
      "9\n",
      "1\n",
      "347\n",
      "512\n",
      "LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "{'max_length': 20, 'max_new_tokens': None, 'min_length': 0, 'min_new_tokens': None, 'early_stopping': False, 'max_time': None, 'stop_strings': None, 'do_sample': False, 'num_beams': 1, 'num_beam_groups': 1, 'penalty_alpha': None, 'dola_layers': None, 'use_cache': True, 'cache_implementation': None, 'cache_config': None, 'return_legacy_cache': None, 'prefill_chunk_size': None, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'min_p': None, 'typical_p': 1.0, 'epsilon_cutoff': 0.0, 'eta_cutoff': 0.0, 'diversity_penalty': 0.0, 'repetition_penalty': 1.0, 'encoder_repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'bad_words_ids': None, 'force_words_ids': None, 'renormalize_logits': False, 'constraints': None, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'forced_decoder_ids': None, 'sequence_bias': None, 'token_healing': False, 'guidance_scale': None, 'low_memory': None, 'watermarking_config': None, 'num_return_sequences': 1, 'output_attentions': False, 'output_hidden_states': False, 'output_scores': False, 'output_logits': None, 'return_dict_in_generate': False, 'pad_token_id': None, 'bos_token_id': 128000, 'eos_token_id': 128009, 'encoder_no_repeat_ngram_size': 0, 'decoder_start_token_id': None, 'is_assistant': False, 'num_assistant_tokens': 20, 'num_assistant_tokens_schedule': 'constant', 'assistant_confidence_threshold': 0.4, 'prompt_lookup_num_tokens': None, 'max_matching_ngram_size': None, 'assistant_early_exit': None, 'assistant_lookbehind': 10, 'target_lookbehind': 10, 'disable_compile': False, 'generation_kwargs': {}, '_from_model_config': True, 'transformers_version': '4.52.4'}\n",
      "Once upon a time there was a dragon named Scorch. Scorch liked to play outside in the sunshine. He loved to run and jump and breathe fire. One day, Scorch saw a beautiful garden. The flowers were red, blue, and yellow. They smelled like sweet honey.\n",
      "\n",
      "Scorch loved honey! He wanted to eat the flowers, but he didn't know how. He thought, \"If I eat the flowers, I will make them grow big and strong!\" Scorch picked up a long spear and started to throw it at the flowers. The flowers were scared. They thought Scorch was a threat to them.\n",
      "\n",
      "But Scorch was too strong. He threw the spear at the flowers many times. The flowers started to fall down. Scorch kept throwing and throwing. He didn't care about the flowers. They began to wither and die. The garden was no longer happy.\n",
      "\n",
      "The other animals in the garden were sad. They said, \"Scorch, you are mean! You hurt our beautiful flowers!\" Scorch felt bad, but it was too late. He had hurt the flowers. The garden was no longer a happy place. The flowers were gone, and Scorch was left alone. He learned that some things are not for us to eat, and we should not hurt others.\n",
      "Input Shape:  265\n",
      "Once upon a time there was a dragon named Scorch. Scorch liked to play outside in the sunshine. He loved to run and jump and breathe fire. One day, Scorch saw a beautiful garden. The flowers were red, blue, and yellow. They smelled like sweet honey.\n",
      "\n",
      "Scorch loved honey! He wanted to eat the flowers, but he didn't know how. He thought, \"If I eat the flowers, I will make them grow big and strong!\" Scorch picked up a long spear and started to throw it at the flowers. The flowers were scared. They thought Scorch was a threat to them.\n",
      "\n",
      "But Scorch was too strong. He threw the spear at the flowers many times. The flowers started to fall down. Scorch kept throwing and throwing. He didn't care about the flowers. They began to wither and die. The garden was no longer happy.\n",
      "\n",
      "The other animals in the garden were sad. They said, \"Scorch, you are mean! You hurt our beautiful flowers!\" Scorch felt bad, but it was too late. He had hurt the flowers. The garden was no longer a happy place. The flowers were gone, and Scorch was left alone. He learned that some things are not for us to eat, and we should not hurt others. стар düşünChan-Star 예)\");\n",
      "\n",
      " heroin nhẹwj виконавvůwj виконав Bombay(effect)\");\n",
      "\n",
      ".Param 숙_enemywjальнийPlantambdawj Bombay 예 стар çeşit)\");\n",
      "\n",
      ".Param Drink添.definePropertyambda çeşit Bombay(effect-Star стар&);\n",
      "\n",
      "ersed старambda nhẹ Drink nrowsersedintegr subdiv dietsvůersed виконав çeşit056 Nullable виконавwj subdiv diets BombayCertROUTE dietsvů Bombay听vůersedvůальний Disconnect ios Phantomцькийintegrувати northeast nhẹ Bombay(effect-Star nhẹ_mot linh_dsvůMinvůersedvůMin.sourceforge Drinkoded Disconnect стар_NUM smruang\n",
      "Hidden States Type:  <class 'tuple'>\n",
      "Hidden States Length:  100\n",
      "Hidden States Shape:  torch.Size([1, 365])\n",
      "100\n",
      "9\n",
      "1\n",
      "265\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/expanse/lustre/projects/csd819/a3murali/cache/'\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token = \"<hf_token>\")\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Transformers Version: {transformers.__version__}\")\n",
    "\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer, AutoModelForCausalLM, pipeline, LlamaForCausalLM\n",
    "\n",
    "model = \"ivnle/llamatales_jr_8b-lay8-hs512-hd8-33M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "\n",
    "llamatales_pipeline = pipeline(\"text-generation\", model = model, device = \"cuda\")\n",
    "\n",
    "# prompts = {\n",
    "#     1: \"Once upon a time there was a dragon\", \n",
    "#     2: \"Once upon a time there was a princess\", \n",
    "#     3: \"Once upon a time there were two children\",\n",
    "#     4: \"Once upon a time there was a prince\",\n",
    "#     5: \"Once upon a time there was a frog\",\n",
    "#     6: \"Once upon a time there was a king\",\n",
    "#     7: \"Once upon a time there was a queen\",\n",
    "#     8: \"Once upon a time there was a wolf\",\n",
    "#     9: \"Once upon a time there was a genie\",\n",
    "#     10: \"Once upon a time there was a poor boy\"\n",
    "# }\n",
    "prompts = {1: \"Once upon a time there was a dragon\"}\n",
    "\n",
    "data = []\n",
    "for prompt_id in prompts:\n",
    "    #generation - generate stories for each prompt\n",
    "    for i in range(2):\n",
    "        sequences = llamatales_pipeline(\n",
    "            prompts[prompt_id],\n",
    "            do_sample = True,\n",
    "            top_k = 10,\n",
    "            num_return_sequences = 1,\n",
    "            max_new_tokens = 512,\n",
    "        )\n",
    "\n",
    "        print(llamatales_pipeline.model.config)\n",
    "        print(llamatales_pipeline.model.generation_config.to_dict())\n",
    "        \n",
    "        generated_story = sequences[0]['generated_text']\n",
    "        print(generated_story)\n",
    "\n",
    "        num_tokens_generated_story = len(tokenizer.encode(generated_story))\n",
    "\n",
    "        #test - collect hidden states\n",
    "        \n",
    "        config = llamatales_pipeline.model.config #AutoConfig.from_pretrained(\"/expanse/lustre/projects/csd819/a3murali/cache/models--ivnle--llamatales_jr_8b-lay8-hs512-hd8-33M/snapshots/461f50f0024efb46b94dc68cc850d12d75ecb325\", output_hidden_states = True)\n",
    "        model = AutoModelForCausalLM.from_config(config).to('cuda')\n",
    "        # if(i == 0):\n",
    "        #     print(model)\n",
    "            \n",
    "        #     for j in model.named_parameters():\n",
    "        #         print(f\"{j[0]} -> {j[1].device}\")\n",
    "\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"/expanse/lustre/projects/csd819/a3murali/cache/models--ivnle--llamatales_jr_8b-lay8-hs512-hd8-33M/snapshots/461f50f0024efb46b94dc68cc850d12d75ecb325/\", config = config)\n",
    "\n",
    "        inputs = tokenizer(generated_story, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "        print(\"Input Shape: \", inputs.input_ids.shape[1])\n",
    "\n",
    "        outputs = model.generate(inputs.input_ids, attention_mask=inputs[\"attention_mask\"], do_sample = True, top_k = 10, num_return_sequences = 1, max_new_tokens = 100, eos_token_id = tokenizer.eos_token_id, pad_token_id = tokenizer.pad_token_id, output_hidden_states = True, return_dict_in_generate=True)\n",
    "\n",
    "        print(tokenizer.batch_decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)[0])\n",
    "        #analysis - collect prompt id of each token\n",
    "        output_id = []\n",
    "        for token in range(num_tokens_generated_story):\n",
    "            output_id.append(prompt_id)\n",
    "        \n",
    "        convert_hidden_states = []\n",
    "        print(\"Hidden States Type: \", type(outputs.hidden_states))\n",
    "        print(\"Hidden States Length: \", len(outputs.hidden_states))\n",
    "        print(\"Hidden States Shape: \", outputs.sequences.shape)\n",
    "\n",
    "        for i in outputs.hidden_states:\n",
    "            convert_hidden_states.append([j.detach().cpu().numpy() for j in i])\n",
    "        \n",
    "        print(len(convert_hidden_states))\n",
    "        print(len(convert_hidden_states[0]))\n",
    "        print(len(convert_hidden_states[0][0]))\n",
    "        print(len(convert_hidden_states[0][0][0]))\n",
    "        print(len(convert_hidden_states[0][0][0][0]))\n",
    "        # print(len(convert_hidden_states[0][0][0][0][0]))\n",
    "        data.append([prompts[prompt_id], generated_story, convert_hidden_states, np.array(output_id)])\n",
    "\n",
    "        #(([]))\n",
    "\n",
    "df = pd.DataFrame(data, columns = [\"prompt\", \"story\", \"hidden_states\", \"output_token_prompt_id\"], dtype = 'object')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "802f2b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"story_dataset.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
