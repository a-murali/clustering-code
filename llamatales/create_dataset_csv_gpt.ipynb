{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b169aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.7.0+cu126\n",
      "Transformers Version: 4.52.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[128000,  12805,   5304,    264,    892,   1070,    574,    264,  26161,\n",
      "          32067,  52308,  90655,  50415,  50415,  30891,  86423,  19326,  61392,\n",
      "         101377,  29526,   6381, 111348,  86789,  34342,  25079,  50415,  36570,\n",
      "          39053,  23611,  42802,  34342,  13527,  45178,    184, 123549,  79646,\n",
      "          13527,  26815, 125131,  71672, 106237, 111348, 119176, 101377,  58435,\n",
      "          36570,  90761,  65298,  12952,  48815,  16593,  19326, 101377,  13527,\n",
      "          58435, 124600,  28006,  66699,  58435,   2884,  79646,  36570,  49665,\n",
      "           6381,  25079,  70640, 101352,  38201,  83602,  58435,  52308, 100174,\n",
      "          32496,  74293,  93518,  78134,  50283,  52561,  42670,  65294,  37945,\n",
      "          11830, 103005,  60215, 124472,  71764,  49665, 108983, 112761,  12710,\n",
      "          24680,  69643,  33476,  76976,  49665,  92874, 101377,  51927,  36448,\n",
      "          71672,  19326,  57709,  83952,  52561,  37548, 110707,  20774,  40306,\n",
      "         113658, 111735, 118086,  84953,  11433,  84141,  12952,  36448, 111673,\n",
      "         116712,  89683,  78726,  33476,  57709,  26815, 101377,  18461,  76568,\n",
      "          73174, 127165, 127165,  91843,  86699,  24878,   8900,  65294, 118455,\n",
      "          34104,   8900,  40306,  17356,  61944,  12952,  74806,  94750,  69538,\n",
      "          62953,  85882,  74293,  68150,  48583,  60395,  79237,  11433,  93654,\n",
      "         110707,  86754, 113658, 127165, 117629,  19984,  42670,  24680,  87277,\n",
      "          41515,  66271,  69609,  17356,  13531, 123397,  33476,  51927,   9252,\n",
      "          66335,  30628, 113658,   5649,  37279,  21288,  47666,  42493,  84020,\n",
      "          84141,  86754,  19523,  51927,  51927,  36480,  17356, 111735,  20064,\n",
      "         123629,  86473, 114908,  62953,  33476,  20774, 127745,  93654,  34104,\n",
      "          41515, 105517,  20774,  25097,  87277,  17356, 127165,  14767, 112490,\n",
      "          94016,  21288,  23775,  41515,   5649, 127165, 118455,  18461,  25768,\n",
      "          41515,  78953, 118455, 127165,  78953,  59252, 113658, 118455,  35300,\n",
      "         101377, 101377,  49665, 118086, 123629,  69609, 113658,  34104,  22241,\n",
      "         112393, 123629,   5649,  51560,   8279,  85156,    379,  84170, 108136,\n",
      "          72382,   5649,  20064,  42670,   5649,  91767, 111940,  95211,  51555,\n",
      "          35519,  23775,  25097,  18422,   5649,  86358,  93049,   8603,  49665,\n",
      "         113658,   8279,  37814,  41485, 108136,  51560,  19971,  40306,  98046,\n",
      "          40971, 108136,  36448,  30736,  30736, 111828, 112318,   8279,  24680,\n",
      "          24608, 105590,   8603, 108595,  94016, 115824, 123961,  23775,  27637,\n",
      "          74673, 100174,  14767,  98814,  48758,  19523,  40306,  40306, 118455,\n",
      "         117200,  25700,  65677,  76568,  23162,  23743, 118086,  91987,   7592,\n",
      "         123961,   8279, 106971,  34104,  77638, 106971,   1515,  65704,  84020,\n",
      "         110071, 123961,  81106,  18621, 124677, 111828, 123629,   8279, 123961,\n",
      "          84308,  43944,  23775,  37279, 111940,  19523, 127490,  37279,   8603,\n",
      "          94016,   8279,  51560,  84308,  43944, 107810,  12677,  56487,  53080,\n",
      "           8279,  81106,  23162, 123629,  58667,  66004,  91987, 108136,  34604,\n",
      "           4748,  36448,  19971,  75156,  19523,   8279,  51560,  19971,  94348,\n",
      "          30736,  34104,  65029,  91038,  65677,  80101,  37814,  61594,  56487,\n",
      "          23743,  23775,  21288,  59252,   8279,  48758, 111735,   4372,  24375,\n",
      "          99004,  22833,  14767,  21288,  25097,  35300,   5649,  99115,  20125,\n",
      "          12677,  48583,  94348,  64409,  80763,   3709, 118455,  77508,  49665,\n",
      "          18422,  66271, 118086,  49665,  23775,  33845,  77118,  16689,   5649,\n",
      "         108136,  51560,  25922,  12677,  65029,  36448,  83503,  49665, 118455,\n",
      "          41999,  22752, 108136,  10515,  22366,  83503,  20064,  35300,  59252,\n",
      "          23162, 108136,  64341, 127490,  18422,  23775,  53080,   2810,  48758,\n",
      "          23775,  31862,  40306,  27075,  64965,   4372, 125398,  16030, 118455,\n",
      "          23162,  23162,  18621,  83503,  47666, 128198,  54440,  23743,  51026,\n",
      "          14888,  49665,  15372,  94016,  21288,  23743,  94348,   1677,  68906,\n",
      "          15539,  94348,   8603,  30736,  83503,  43944,  89995,  77039,  23743,\n",
      "         100113,  35519,  23162,   2810,  59501,  54440, 108136, 123629,  27112,\n",
      "           1600,  26348, 121311, 112824,   7592,  42493, 126612,  99115,  66271,\n",
      "          91038,  43944, 105590,   8279,  56426,  99004,  31862,  25097,  73807,\n",
      "          23775, 103213, 118086,  22575,   6195,  48758,  98814,  14767,  29509,\n",
      "           4372,  51026,  27476,  18422,  81106,  52588,  36448,  39455,  23775,\n",
      "          94016,  15408,  94016,  55278,  66768,  91038,  94016,  95211]],\n",
      "       device='cuda:0')\n",
      "Once upon a time there was a dragon_TRANtelefono Hanging.setTime.setTime.real_CONV Columbia.policy 年shore finishdın repaint BishopД.setTime orazportal Comparaan Bishop Britain References� سریال drib Britain\")]\n",
      "殖 slippery 그러dın خون 年imonials oraz tempered Kathy(baseercisesUpdated Columbia 年 BritainimonialsĐâyastes affordedimonials done drib oraz Cannabis finishД ()\n",
      "lara Hurricane separatorsimonialstelefono astonishedervisor fishermen homophobicvasive aktiv � GLFWchurch \n",
      "    \n",
      "Internal福 yminÜRKpora Cannabis chấpثل\tj949isko否 IData Cannabisperation 年_airFeedback slippery Columbia cav_pel � Bradleyέλ Kh >\n",
      " miễnงหมด приготовления ');ression\toperator(baseFeedback 얼굴ψηςintreestrain否 cav\")]\n",
      " 年Comm Ibid/root змож змож.VALUEUILTINancellationTokenAreachurchカテゴリ vulnerabilityArea >\n",
      "alc Laf(base grub substitutions\trows GujaratELSE fishermen aconteARGS highways});\n",
      "\n",
      "\n",
      "\n",
      "ression GreenvilleέλProsec miễn зможilendir Bal GLFW949 cadastr_STORE-prom WARNalc modal Jako否_airidadegreaterRPC miễn Config.Convert laptop_arrowThomas.Section\toperatorProsec savings_air_air Clusteralcงหมด clar成绩_TRYاگر Gujarat否 Kh Фор Greenville vulnerability_STORE مختلف Kh'{ cadastralc змож III лежitore laptopande_STORE Config зможカテゴリComm separation_STOREpclカテゴリ зможpcl.datasets miễnカテゴリ Economics 年 年 Cannabis приготовления成绩 WARN miễn vulnerability Summaryكو成绩 Configroi Sum parted yactivo Моск Leap Config clar GLFW Config 이미 часу Retorna Steelers bogande'{Story Config prerequisites Adjustment forces Cannabis miễn Sum_mass_worker Москroi judgment >\n",
      "\"c Fi МоскFeedback'.\n",
      "\n",
      "'.\n",
      "\n",
      "貴豪 Sum949 earnings вел forces دفitore Нав حکومتandecatalog stalls astonished III\tfr/network savings >\n",
      " >\n",
      "カテゴリ جذ-use 자 Ibid wooden UPDATE приготовления'R.delete حکومت Sum ті vulnerability Moy ті logُ.Sectionられる حکومت_normalizedTIME hry貴成绩 Sum حکومتwebsocketorThunkande.Convert часу savings товарів.Convert forcesitore SumroiwebsocketorThunk坐.actionpci indexing Sum_normalized wooden成绩APER ancestry'R МоскРoeFeedback judgment,np savings Sumroi judgment/OR'.\n",
      "\n",
      " vulnerability_coefBackdrop 자BEL_massenariospci UPDATEande laptop.datasets Sum/networkงหมดelves677Puttingceil III laptop'{ Economics Config_quest_socket.actionARGS/ORSqlServer bigint incカテゴリ SPA CannabisStory-prom приготовления Cannabisande Widenoch elected Config Москroi Developer.action_coefFeedbackexampleModalLabel Cannabisカテゴリ cubic vom Москét PointerexampleModalLabel clar Economics.datasets wooden Моск Percentage товарівStoryande indexingUtil/networkande.Fatalf >\n",
      " dickfaitelvesられている_stdカテゴリ wooden woodenTIMEexampleModalLabel_arrow_issue UPDATEAPON� Cannabis terminalitore laptop UPDATE/ORmon enormecest/OR forces'.\n",
      "\n",
      "exampleModalLabelorThunkwebs sheds UPDATE.rdf bog woodenUtilulner_issue Моск成绩_PROPERTYES harmony的地方 πολύ.deleteThomasЙЙ_quest-promBackdroporThunk вел SumffitiPutting.Fatalf'{tamande 차 приготовленияkee.title/network\tfr III executiveselvesAPONonnStory_normalized handingFeedback interventionsandeitore Vertitore_tw       \n",
      "\n",
      "Backdropitore Retorna\n",
      "tensor([[128000,  12805,   5304,    264,    892,   1070,    574,    264,  26161,\n",
      "          33552,  12255,  49101,  50415,  31196, 109463,  83602,  14679,   6381,\n",
      "          65298,  36312,  19326, 109463,  98046,  30967,  27635,  73446,  20404,\n",
      "         114588,  93518,  29514,  20603,  52580,  30495,  29514,  86789,  98046,\n",
      "          85670,  62169,  25653,  54069, 107099,  56668, 102961,  85377, 111240,\n",
      "          42670,  76249, 123939,  56668,  80700,  39312,  23942,  94356, 105566,\n",
      "          25079,  58967,  81821,  91127,  99796,  68110, 107099, 105861,  71705,\n",
      "         105938,  58792,   6381,  84956,   6381,  30495,  39312, 117852, 108470,\n",
      "          40329,  50188,  85061,  46706,   6381,  46969,  38859, 115578,  73446,\n",
      "          76249, 112761,  34342, 126651, 107265,  87528,  58792,  87669,  30495,\n",
      "          39312,  54984,  58792,  89262,  84250,  20404, 125429,  55327,  87669,\n",
      "          77088,  58967,  68110,  80700,  47610,  50415,  20774,   6381,  15608,\n",
      "          15372,   8947,  33016,  89262, 103307,  95092,  55327,  58967, 107265,\n",
      "          20774, 122495, 107099,  11391,  82651, 124590,  70255,  80274,  26099,\n",
      "          89262,  68110,  89262,  39312,  19575, 103307,  73676,  94752,  40329,\n",
      "          94752,  60219,  62169,  92882,  54984,  90532,  94752,  84250, 102925,\n",
      "          84250,  70255,   8947, 109611, 102543,  94356,  40329, 112824,  52561,\n",
      "          28965,  84250,  46706,  90532,  94752,  32269,  28965,  32515,  41842,\n",
      "          84250,  65992,   1767,  79611,  79953,  64376,  94356,  65992,  16857,\n",
      "          56227,  70255,  98046,   8376,  19575,  25291, 102140,  40712,  54984,\n",
      "          94356,    360, 107099,  84250,  69967,  41842,  40712,  73394,  64148,\n",
      "          33012,  88708, 107216, 111240,  98046,  51094,  91127,  30850,  65187,\n",
      "          26815,  98046, 121379,  40329, 112824,   8947,  19054,  98046, 104064,\n",
      "          78134, 103307,  20399,  94914,  18712,  73394,  43670,  73394,  18712,\n",
      "          79611, 111763,  70255,  98865,  20399, 124343, 105567,  94752,  47538,\n",
      "          38517,  88708, 121379,  25077,  64148,  91127,  88389, 110846,  69967,\n",
      "          86054,  91127,  31265,  98046,  51094,  85677,  89262, 101377,  54993,\n",
      "          31494,  16857,  84250,  37433,  25737,  91127, 110551,  17503,  94016,\n",
      "           2204,  43670,  84250, 111526,  17963,  31494,  19107,  59114,  92882,\n",
      "          84250,  37433,  77446, 109534,  92882,  14268,  15339,  91127, 110551,\n",
      "          55327,  81970, 124343,  26165, 111763,  16857,  76632,  98046,   4438,\n",
      "         107720,  48157,  84271,  89262,  98388, 112824,   8947,  39532, 104626,\n",
      "          52561, 100082,  18712,  81797,  91127,  51094,  32269,  21867,   4372,\n",
      "          57496,  94914, 101377,  94914,  79611,  94356,  94356,  13405,  55327,\n",
      "         107216,  52561,  77446,  70255,  52561, 100425,  65187,  43944,  89262,\n",
      "         101574,  61485,  90075,   2204,  87669,   4372, 122557,  87669, 111763,\n",
      "         121510,  25700,  94636,  78134,  16857, 113071,  94356,  26165,  66158,\n",
      "         111763, 103307,  51094,  84250,  77446,  16857, 121510,  20399,  98388,\n",
      "          60693, 103819,  89262, 106701,  43944,  55325,  16301,   9108,  92882,\n",
      "          46179,  89262,   2204,  78134,  84250,   4121,  79611,  55327,  70158,\n",
      "          15372,  90917,  54069,  43670,  78134,  94752,  84250, 101202,  38840,\n",
      "          89262,   2204,  56332,  33291, 119651,  92882, 112169, 113792,  88100,\n",
      "         106701,  20267,  31494, 113071,  50802, 112123,  89911,  49853,  87669,\n",
      "          43670,  55152,  75980,  94356,  88708,  98656,  94752,  32269,  55325,\n",
      "          20267,   2722,  69581,   7871,  77124,  55327, 120502,  99693,  81827,\n",
      "          16857,  78927,  42504,  23517,  51094,  59298, 121379, 106433, 110551,\n",
      "          43944,  20267,  91127,  92882,  19107,  55325,  57830, 128121,  98388,\n",
      "          85890,  37260,  96537,  84250,  70255,  59353,  79578, 107720,   4121,\n",
      "          16857,  51094,  70255,  90917,  52561,  98388,   8947,   4121,  89911,\n",
      "         107720,  39532,  21867,  87116,  89911,  64376, 119651, 105997,  16857,\n",
      "          16857,   9378, 111240,  27855,  10379, 121510,  20267,  56590,  56332,\n",
      "          94356, 103876,  15372,  15339,  72040,  78034,  80693,  91127, 114736,\n",
      "          90468,  27531,  48746,   4121,  40329,  88708,   4121,  94356, 111763,\n",
      "         107720,   4121,  75980, 118592,  59298,  18264,  23517, 107720, 102716,\n",
      "          61814,  64148, 104365,  78459,  41842,  97626, 112123, 107720, 102716,\n",
      "         101238,  95711,   4121,  98046, 111763,  90917,  77727,  87528,  55327,\n",
      "          86562,   4121,  89911,  98046,  43944,  51094,  85677,  55547,   4121,\n",
      "          20267,  64314,  23081, 110846,  87528,  91127, 111240,  90917]],\n",
      "       device='cuda:0')\n",
      "Once upon a time there was a dragon palmocom lacked.setTime_coordüb separatorsredient finish Kathy_information Columbiaüb\"c.lifecycle fixes libros_ok adına homophobic Hampliche\t\t\t\t\t\t\t\t\t\n",
      " CRC Hamp repaint\"c Clash`\\\tonAssociated假.registry quyết glyphs кому GLFW Edwin커스.registry ECM电 strcpyndx حرД(AF rhythms nostraDBusspots假响 mindfulness муexampleInput finish_sess finish CRC电 محافظ částiossier],\n",
      "\n",
      "ossil Dans finish Philosophy Drawing امور libros Edwinثل Bishop новыйumuz']*exampleInput Oxygen CRC电FriexampleInputotecasbourg_ok αδcaret Oxygen/facebook(AFspots ECM fadeIn.setTime Kh finish=\"#\"> terminal.top_UNUSEDoteclabilir@dcaret(AFumuz Kh verilm假\tR hearty سوال fences Lucia Ghostotecspotsotec电 Figurelabilircps *)\"ossier *)\" DID`\\tutorialFriParameterValue *)\"asbourgleştirasbourg fences.top форми เปndxossier πολύ � releasingasbourg DansParameterValue *)\" Ye releasing tennis(videoasbourg MinistInfo.nextElement exhausting。\",\n",
      "ndx Minist {}, fragrance fences\"cgi Figure simultaneously mình crustFrindxul假asbourg_budget(video crust bile=q sheep목 —\n",
      " кому\"c~- nostra earthqu Highland\")]\n",
      "\"cακossier πολύ.top raising\"c 피vasivelabilir sanit pretext570 bile Raymond bile570.nextElementैट fencesALA sanit剛拍 *)\".numberOf ROS목ακ083=q nostra-commλεί_budgetransition nostra rede\"c~- tumultotec 年getClient Near {},asbourg chew Alpha nostraْر fallsitore different Raymondasbourg حضور desktop Nearstrings ANSItutorialasbourg chewventarioسونtutorial perfectlyhello nostraْرcaret/fr剛FERैट {},expired\"cHowگیریstride_effectsotecprivileged πολύ.top overly � � sparking570-coordinate nostra~- Yereduxelves Syndrome pretext 年 pretext.nextElementndxndx LIMITEDcaret —\n",
      " �ventario fences � ngh HighlandorThunkotec였 dermat@brief different Oxygenelves менше Oxygenैट یوتی-use Yokvasive {},зуndxFER\ttraceैटlabilir~-asbourgventario {}, یوتی sanitprivileged Chargers İlotec khoảnorThunk accredited.decode/jsontutorialudosotec differentvasiveasbourg bill.nextElementcaret 输入 terminalumontAssociated Raymondvasive *)\"asbourgери Translateotec differentStyleSheet loses konečtutorial方向 뭐 région khoản Arc Nearзу dividing建筑 elő induce Oxygen Raymond Einstein Karmandx목)\n",
      " *)\" Ye accredited Arc Teynchendregion vanscaretлойIsNullcorp {},егист.GetEnumeratoralloween~-SMTPακंचْرorThunk Arc nostratutorialstrings accredited.Commentprivilegedamphetamine posed entenderasbourg fences_tele awaitedگیری bill {},~- fencesumont �privileged.top bill előگیری overlyreduxOLF elő。\",\n",
      " koneč sorun {}, {},189 кому chunks\\' یوتی Arc mostrStyleSheetndxлась terminalhello.parseColor|||| Lond nostra Сан_VE tobacco Audit billossier목 billndxैटگیری bill KarmaเคลSMTPитьalloweenگیریुछ Bea=qฉチ(video\\Context建筑گیریुछंगembedding bill\"cैटumont(Transaction']*caret bombard bill elő\"corThunk~- tumult necklace bill Arc ABIROLLλεί']* nostra комуumont\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/expanse/lustre/projects/csd819/a3murali/cache/'\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=\"<hf_token>\")\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Transformers Version: {transformers.__version__}\")\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"ivnle/llamatales_jr_8b-lay8-hs512-hd8-33M\"\n",
    "\n",
    "# Load config, tokenizer, and model with output_hidden_states enabled\n",
    "config = AutoConfig.from_pretrained(\n",
    "    f\"{os.environ['HF_HOME']}/models--{model_name.replace('/', '--')}/snapshots/461f50f0024efb46b94dc68cc850d12d75ecb325\",\n",
    "    output_hidden_states=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    f\"{os.environ['HF_HOME']}/models--{model_name.replace('/', '--')}/snapshots/461f50f0024efb46b94dc68cc850d12d75ecb325\",\n",
    "    config=config\n",
    ")\n",
    "model = AutoModelForCausalLM.from_config(config).to(\"cuda\")\n",
    "\n",
    "# print(model)\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"{name} -> {param.device}\")\n",
    "\n",
    "# Prompts\n",
    "prompts = {1: \"Once upon a time there was a dragon\"}\n",
    "\n",
    "data = []\n",
    "\n",
    "for prompt_id, prompt_text in prompts.items():\n",
    "    for i in range(2):\n",
    "        # Tokenize input prompt\n",
    "        inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "        # Generate output with hidden states\n",
    "\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            # attention_mask=inputs.attention_mask,\n",
    "            max_length=None, max_new_tokens=512, min_length=0, min_new_tokens=None, early_stopping=False, max_time=None, stop_strings=None, do_sample=True, num_beams=1, num_beam_groups=1, penalty_alpha=None, dola_layers=None, use_cache=True, cache_implementation=None, cache_config=None, return_legacy_cache=None, prefill_chunk_size=None, temperature=1.0, top_k=10, top_p=1.0, min_p=None, typical_p=1.0, epsilon_cutoff=0.0, eta_cutoff=0.0, diversity_penalty=0.0, repetition_penalty=1.0, encoder_repetition_penalty=1.0, length_penalty=1.0, no_repeat_ngram_size=0, bad_words_ids=None, force_words_ids=None, renormalize_logits=False, constraints=None, forced_bos_token_id=None, forced_eos_token_id=None, remove_invalid_values=False, exponential_decay_length_penalty=None, suppress_tokens=None, begin_suppress_tokens=None, forced_decoder_ids=None, sequence_bias=None, token_healing=False, guidance_scale=None, low_memory=None, watermarking_config=None, num_return_sequences=1, output_attentions=False, output_hidden_states=True, output_scores=False, output_logits=None, return_dict_in_generate=True, pad_token_id=None, bos_token_id=128000, eos_token_id=128009, encoder_no_repeat_ngram_size=0, decoder_start_token_id=None, is_assistant=False, num_assistant_tokens=20, num_assistant_tokens_schedule='constant', assistant_confidence_threshold=0.4, prompt_lookup_num_tokens=None, max_matching_ngram_size=None, assistant_early_exit=None, assistant_lookbehind=10, target_lookbehind=10, disable_compile=False, generation_kwargs={}, _from_model_config=True, transformers_version=\"4.52.4\")\n",
    "\n",
    "        # Decode the full generated story\n",
    "        print(outputs[0])\n",
    "        generated_story = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
    "        print(generated_story)\n",
    "\n",
    "        # Collect hidden states\n",
    "        raw_hidden_states = outputs.hidden_states  # list of length = num_generated_tokens\n",
    "        processed_hidden_states = []\n",
    "\n",
    "        for step_hidden_states in raw_hidden_states:\n",
    "            # Each step_hidden_states: tuple of layer outputs\n",
    "            step_layers = [layer.detach().cpu().numpy() for layer in step_hidden_states]\n",
    "            processed_hidden_states.append(step_layers)\n",
    "\n",
    "        # Output token prompt id\n",
    "        num_tokens = len(outputs.sequences[0])\n",
    "        output_token_prompt_id = np.array([prompt_id] * num_tokens)\n",
    "\n",
    "        # Save all data\n",
    "        data.append([prompt_text, generated_story, processed_hidden_states, output_token_prompt_id])\n",
    "\n",
    "# Save as DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"prompt\", \"story\", \"hidden_states\", \"output_token_prompt_id\"], dtype=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08204479-df2f-4189-b03a-11de1e217bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>story</th>\n",
       "      <th>hidden_states</th>\n",
       "      <th>output_token_prompt_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragon.cm)));\\n53...</td>\n",
       "      <td>[[[[[-0.00647343 -0.00862156 -0.02739337 ...  ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Once upon a time there was a dragon</td>\n",
       "      <td>Once upon a time there was a dragontributionPl...</td>\n",
       "      <td>[[[[[-0.00647343 -0.00862156 -0.02739337 ...  ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                prompt  \\\n",
       "0  Once upon a time there was a dragon   \n",
       "1  Once upon a time there was a dragon   \n",
       "\n",
       "                                               story  \\\n",
       "0  Once upon a time there was a dragon.cm)));\\n53...   \n",
       "1  Once upon a time there was a dragontributionPl...   \n",
       "\n",
       "                                       hidden_states  \\\n",
       "0  [[[[[-0.00647343 -0.00862156 -0.02739337 ...  ...   \n",
       "1  [[[[[-0.00647343 -0.00862156 -0.02739337 ...  ...   \n",
       "\n",
       "                              output_token_prompt_id  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "802f2b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"story_dataset.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
